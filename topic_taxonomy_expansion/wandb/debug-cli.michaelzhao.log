2025-02-12 22:20:34 INFO Running runs: []
2025-02-12 22:20:34 INFO Running runs: []
2025-02-12 22:20:34 INFO Agent received command: run
2025-02-12 22:20:34 INFO Agent starting run with config:
	alpha_multiplier: 2
	data_file: /n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv
	dropout: 0.4089435807296445
	learning_rate: 7.786717982258626e-05
	length_penalty: 3.1850376510436815
	model_name: facebook/bart-large-cnn
	num_train_epochs: 5
	output_dir: ./lora_bart_subtopics_sweep
	r: 8
	target_modules: q_proj,v_proj,k_proj
	warmup_steps: 100
2025-02-12 22:20:34 INFO About to run command: /usr/bin/env python sweep_bart.py --alpha_multiplier=2 --data_file=/n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv --dropout=0.4089435807296445 --learning_rate=7.786717982258626e-05 --length_penalty=3.1850376510436815 --model_name=facebook/bart-large-cnn --num_train_epochs=5 --output_dir=./lora_bart_subtopics_sweep --r=8 --target_modules=q_proj,v_proj,k_proj --warmup_steps=100
2025-02-12 22:20:34 INFO Agent received command: run
2025-02-12 22:20:34 INFO Agent starting run with config:
	alpha_multiplier: 2
	data_file: /n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv
	dropout: 0.5904962841453513
	learning_rate: 8.415450934294058e-05
	length_penalty: 3.1025591536586883
	model_name: facebook/bart-large-cnn
	num_train_epochs: 10
	output_dir: ./lora_bart_subtopics_sweep
	r: 16
	target_modules: q_proj,v_proj,k_proj,out_proj,lm_head
	warmup_steps: 100
2025-02-12 22:20:34 INFO About to run command: /usr/bin/env python sweep_bart.py --alpha_multiplier=2 --data_file=/n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv --dropout=0.5904962841453513 --learning_rate=8.415450934294058e-05 --length_penalty=3.1025591536586883 --model_name=facebook/bart-large-cnn --num_train_epochs=10 --output_dir=./lora_bart_subtopics_sweep --r=16 --target_modules=q_proj,v_proj,k_proj,out_proj,lm_head --warmup_steps=100
2025-02-12 22:20:39 INFO Running runs: ['2y3ewf74']
2025-02-12 22:20:39 INFO Running runs: ['qdbgqwy7']
2025-02-12 22:38:56 INFO Running runs: []
2025-02-12 22:38:56 INFO Running runs: []
2025-02-12 22:38:56 INFO Agent received command: run
2025-02-12 22:38:56 INFO Agent starting run with config:
	alpha_multiplier: 2
	data_file: /n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv
	dropout: 0.10368100849095728
	learning_rate: 7.157483319465206e-05
	length_penalty: 5.0967345621510995
	model_name: facebook/bart-large-cnn
	num_train_epochs: 10
	output_dir: ./lora_bart_subtopics_sweep
	r: 32
	target_modules: q_proj,v_proj
	warmup_steps: 500
2025-02-12 22:38:56 INFO About to run command: /usr/bin/env python sweep_bart.py --alpha_multiplier=2 --data_file=/n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv --dropout=0.10368100849095728 --learning_rate=7.157483319465206e-05 --length_penalty=5.0967345621510995 --model_name=facebook/bart-large-cnn --num_train_epochs=10 --output_dir=./lora_bart_subtopics_sweep --r=32 --target_modules=q_proj,v_proj --warmup_steps=500
2025-02-12 22:38:56 INFO Agent received command: run
2025-02-12 22:38:56 INFO Agent starting run with config:
	alpha_multiplier: 1
	data_file: /n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv
	dropout: 0.2325526057853522
	learning_rate: 5.882697412929134e-05
	length_penalty: 1.184454341243143
	model_name: facebook/bart-large-cnn
	num_train_epochs: 2
	output_dir: ./lora_bart_subtopics_sweep
	r: 8
	target_modules: q_proj,v_proj,k_proj
	warmup_steps: 100
2025-02-12 22:38:56 INFO About to run command: /usr/bin/env python sweep_bart.py --alpha_multiplier=1 --data_file=/n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv --dropout=0.2325526057853522 --learning_rate=5.882697412929134e-05 --length_penalty=1.184454341243143 --model_name=facebook/bart-large-cnn --num_train_epochs=2 --output_dir=./lora_bart_subtopics_sweep --r=8 --target_modules=q_proj,v_proj,k_proj --warmup_steps=100
2025-02-12 22:39:01 INFO Running runs: ['bdv1fdxc']
2025-02-12 22:39:01 INFO Running runs: ['kjrcm0l3']
2025-02-12 22:48:49 INFO Cleaning up finished run: kjrcm0l3
2025-02-12 22:48:49 INFO Agent received command: run
2025-02-12 22:48:49 INFO Agent starting run with config:
	alpha_multiplier: 2
	data_file: /n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv
	dropout: 0.678648311050776
	learning_rate: 4.1166061031652346e-05
	length_penalty: 8.508714087337351
	model_name: facebook/bart-large-cnn
	num_train_epochs: 10
	output_dir: ./lora_bart_subtopics_sweep
	r: 8
	target_modules: q_proj,v_proj,k_proj,out_proj
	warmup_steps: 500
2025-02-12 22:48:49 INFO About to run command: /usr/bin/env python sweep_bart.py --alpha_multiplier=2 --data_file=/n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv --dropout=0.678648311050776 --learning_rate=4.1166061031652346e-05 --length_penalty=8.508714087337351 --model_name=facebook/bart-large-cnn --num_train_epochs=10 --output_dir=./lora_bart_subtopics_sweep --r=8 --target_modules=q_proj,v_proj,k_proj,out_proj --warmup_steps=500
2025-02-12 22:48:54 INFO Running runs: ['rsykhefz']
2025-02-12 23:02:25 INFO Cleaning up finished run: bdv1fdxc
2025-02-12 23:02:25 INFO Agent received command: run
2025-02-12 23:02:25 INFO Agent starting run with config:
	alpha_multiplier: 1
	data_file: /n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv
	dropout: 0.5061540285349956
	learning_rate: 9.319296237150536e-05
	length_penalty: 6.178514712074925
	model_name: facebook/bart-large-cnn
	num_train_epochs: 4
	output_dir: ./lora_bart_subtopics_sweep
	r: 16
	target_modules: q_proj,v_proj,k_proj
	warmup_steps: 250
2025-02-12 23:02:25 INFO About to run command: /usr/bin/env python sweep_bart.py --alpha_multiplier=1 --data_file=/n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv --dropout=0.5061540285349956 --learning_rate=9.319296237150536e-05 --length_penalty=6.178514712074925 --model_name=facebook/bart-large-cnn --num_train_epochs=4 --output_dir=./lora_bart_subtopics_sweep --r=16 --target_modules=q_proj,v_proj,k_proj --warmup_steps=250
2025-02-12 23:02:30 INFO Running runs: ['hkdjyo2z']
2025-02-12 23:13:04 INFO Cleaning up finished run: hkdjyo2z
2025-02-12 23:13:04 INFO Agent received command: run
2025-02-12 23:13:04 INFO Agent starting run with config:
	alpha_multiplier: 1
	data_file: /n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv
	dropout: 0.25911102722079615
	learning_rate: 9.09772001360525e-05
	length_penalty: 6.917282454055097
	model_name: facebook/bart-large-cnn
	num_train_epochs: 5
	output_dir: ./lora_bart_subtopics_sweep
	r: 128
	target_modules: q_proj,v_proj,k_proj
	warmup_steps: 0
2025-02-12 23:13:04 INFO About to run command: /usr/bin/env python sweep_bart.py --alpha_multiplier=1 --data_file=/n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv --dropout=0.25911102722079615 --learning_rate=9.09772001360525e-05 --length_penalty=6.917282454055097 --model_name=facebook/bart-large-cnn --num_train_epochs=5 --output_dir=./lora_bart_subtopics_sweep --r=128 --target_modules=q_proj,v_proj,k_proj --warmup_steps=0
2025-02-12 23:13:09 INFO Running runs: ['x2iduvh2']
2025-02-12 23:13:24 INFO Cleaning up finished run: rsykhefz
2025-02-12 23:13:25 INFO Agent received command: run
2025-02-12 23:13:25 INFO Agent starting run with config:
	alpha_multiplier: 2
	data_file: /n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv
	dropout: 0.4226571060187128
	learning_rate: 9.459452545789064e-05
	length_penalty: 1.4959363508949186
	model_name: facebook/bart-large-cnn
	num_train_epochs: 10
	output_dir: ./lora_bart_subtopics_sweep
	r: 32
	target_modules: q_proj,v_proj,k_proj,out_proj,fc1,fc2
	warmup_steps: 0
2025-02-12 23:13:25 INFO About to run command: /usr/bin/env python sweep_bart.py --alpha_multiplier=2 --data_file=/n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv --dropout=0.4226571060187128 --learning_rate=9.459452545789064e-05 --length_penalty=1.4959363508949186 --model_name=facebook/bart-large-cnn --num_train_epochs=10 --output_dir=./lora_bart_subtopics_sweep --r=32 --target_modules=q_proj,v_proj,k_proj,out_proj,fc1,fc2 --warmup_steps=0
2025-02-12 23:13:30 INFO Running runs: ['wxq88sni']
2025-02-12 23:29:07 INFO Cleaning up finished run: x2iduvh2
2025-02-12 23:29:08 INFO Agent received command: run
2025-02-12 23:29:08 INFO Agent starting run with config:
	alpha_multiplier: 2
	data_file: /n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv
	dropout: 0.018662565794038157
	learning_rate: 2.7428810028300585e-05
	length_penalty: 2.4949937305419168
	model_name: facebook/bart-large-cnn
	num_train_epochs: 1
	output_dir: ./lora_bart_subtopics_sweep
	r: 64
	target_modules: q_proj,v_proj,k_proj
	warmup_steps: 500
2025-02-12 23:29:08 INFO About to run command: /usr/bin/env python sweep_bart.py --alpha_multiplier=2 --data_file=/n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv --dropout=0.018662565794038157 --learning_rate=2.7428810028300585e-05 --length_penalty=2.4949937305419168 --model_name=facebook/bart-large-cnn --num_train_epochs=1 --output_dir=./lora_bart_subtopics_sweep --r=64 --target_modules=q_proj,v_proj,k_proj --warmup_steps=500
2025-02-12 23:29:13 INFO Running runs: ['wm7zpii9']
2025-02-12 23:36:44 INFO Cleaning up finished run: wm7zpii9
2025-02-12 23:36:44 INFO Agent received command: run
2025-02-12 23:36:44 INFO Agent starting run with config:
	alpha_multiplier: 2
	data_file: /n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv
	dropout: 0.7036044633845133
	learning_rate: 1.0423479195462052e-05
	length_penalty: 3.9373733376153064
	model_name: facebook/bart-large-cnn
	num_train_epochs: 7
	output_dir: ./lora_bart_subtopics_sweep
	r: 128
	target_modules: q_proj,v_proj,k_proj,out_proj,fc1,fc2
	warmup_steps: 100
2025-02-12 23:36:44 INFO About to run command: /usr/bin/env python sweep_bart.py --alpha_multiplier=2 --data_file=/n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv --dropout=0.7036044633845133 --learning_rate=1.0423479195462052e-05 --length_penalty=3.9373733376153064 --model_name=facebook/bart-large-cnn --num_train_epochs=7 --output_dir=./lora_bart_subtopics_sweep --r=128 --target_modules=q_proj,v_proj,k_proj,out_proj,fc1,fc2 --warmup_steps=100
2025-02-12 23:36:49 INFO Running runs: ['fs27nsev']
2025-02-12 23:40:16 INFO Cleaning up finished run: wxq88sni
2025-02-12 23:40:17 INFO Agent received command: run
2025-02-12 23:40:17 INFO Agent starting run with config:
	alpha_multiplier: 2
	data_file: /n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv
	dropout: 0.489901415075691
	learning_rate: 3.9799102849008427e-05
	length_penalty: 8.670601856323797
	model_name: facebook/bart-large-cnn
	num_train_epochs: 6
	output_dir: ./lora_bart_subtopics_sweep
	r: 64
	target_modules: q_proj,v_proj,k_proj,out_proj,fc1,fc2
	warmup_steps: 0
2025-02-12 23:40:17 INFO About to run command: /usr/bin/env python sweep_bart.py --alpha_multiplier=2 --data_file=/n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv --dropout=0.489901415075691 --learning_rate=3.9799102849008427e-05 --length_penalty=8.670601856323797 --model_name=facebook/bart-large-cnn --num_train_epochs=6 --output_dir=./lora_bart_subtopics_sweep --r=64 --target_modules=q_proj,v_proj,k_proj,out_proj,fc1,fc2 --warmup_steps=0
2025-02-12 23:40:22 INFO Running runs: ['syeslo53']
2025-02-12 23:58:57 INFO Cleaning up finished run: fs27nsev
2025-02-12 23:59:19 INFO Agent received command: run
2025-02-12 23:59:19 INFO Agent starting run with config:
	alpha_multiplier: 2
	data_file: /n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv
	dropout: 0.5202729913776714
	learning_rate: 6.474124171250508e-05
	length_penalty: 6.867276568753819
	model_name: facebook/bart-large-cnn
	num_train_epochs: 4
	output_dir: ./lora_bart_subtopics_sweep
	r: 128
	target_modules: q_proj,v_proj,k_proj,out_proj
	warmup_steps: 0
2025-02-12 23:59:19 INFO About to run command: /usr/bin/env python sweep_bart.py --alpha_multiplier=2 --data_file=/n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv --dropout=0.5202729913776714 --learning_rate=6.474124171250508e-05 --length_penalty=6.867276568753819 --model_name=facebook/bart-large-cnn --num_train_epochs=4 --output_dir=./lora_bart_subtopics_sweep --r=128 --target_modules=q_proj,v_proj,k_proj,out_proj --warmup_steps=0
2025-02-12 23:59:24 INFO Running runs: ['1mpok026']
2025-02-12 23:59:48 INFO Cleaning up finished run: syeslo53
2025-02-12 23:59:55 INFO Agent received command: run
2025-02-12 23:59:55 INFO Agent starting run with config:
	alpha_multiplier: 2
	data_file: /n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv
	dropout: 0.051736578925739886
	learning_rate: 7.165295133575747e-05
	length_penalty: 8.104435133304296
	model_name: facebook/bart-large-cnn
	num_train_epochs: 9
	output_dir: ./lora_bart_subtopics_sweep
	r: 128
	target_modules: q_proj,v_proj,k_proj,out_proj,fc1,fc2
	warmup_steps: 100
2025-02-12 23:59:55 INFO About to run command: /usr/bin/env python sweep_bart.py --alpha_multiplier=2 --data_file=/n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv --dropout=0.051736578925739886 --learning_rate=7.165295133575747e-05 --length_penalty=8.104435133304296 --model_name=facebook/bart-large-cnn --num_train_epochs=9 --output_dir=./lora_bart_subtopics_sweep --r=128 --target_modules=q_proj,v_proj,k_proj,out_proj,fc1,fc2 --warmup_steps=100
2025-02-13 00:00:00 INFO Running runs: ['xsgemfox']
2025-02-13 00:16:54 INFO Cleaning up finished run: 1mpok026
2025-02-13 00:16:54 INFO Agent received command: run
2025-02-13 00:16:54 INFO Agent starting run with config:
	alpha_multiplier: 2
	data_file: /n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv
	dropout: 0.43605356808512846
	learning_rate: 4.3109248640282154e-05
	length_penalty: 7.505812763721259
	model_name: facebook/bart-large-cnn
	num_train_epochs: 1
	output_dir: ./lora_bart_subtopics_sweep
	r: 8
	target_modules: q_proj,v_proj,k_proj
	warmup_steps: 750
2025-02-13 00:16:54 INFO About to run command: /usr/bin/env python sweep_bart.py --alpha_multiplier=2 --data_file=/n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv --dropout=0.43605356808512846 --learning_rate=4.3109248640282154e-05 --length_penalty=7.505812763721259 --model_name=facebook/bart-large-cnn --num_train_epochs=1 --output_dir=./lora_bart_subtopics_sweep --r=8 --target_modules=q_proj,v_proj,k_proj --warmup_steps=750
2025-02-13 00:16:59 INFO Running runs: ['6jgq8tlh']
2025-02-13 00:24:05 INFO Cleaning up finished run: 6jgq8tlh
2025-02-13 00:24:05 INFO Agent received command: run
2025-02-13 00:24:05 INFO Agent starting run with config:
	alpha_multiplier: 1
	data_file: /n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv
	dropout: 0.6877785120182007
	learning_rate: 5.0704855007106816e-05
	length_penalty: 2.965376550380282
	model_name: facebook/bart-large-cnn
	num_train_epochs: 5
	output_dir: ./lora_bart_subtopics_sweep
	r: 64
	target_modules: q_proj,v_proj,k_proj,out_proj
	warmup_steps: 250
2025-02-13 00:24:05 INFO About to run command: /usr/bin/env python sweep_bart.py --alpha_multiplier=1 --data_file=/n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv --dropout=0.6877785120182007 --learning_rate=5.0704855007106816e-05 --length_penalty=2.965376550380282 --model_name=facebook/bart-large-cnn --num_train_epochs=5 --output_dir=./lora_bart_subtopics_sweep --r=64 --target_modules=q_proj,v_proj,k_proj,out_proj --warmup_steps=250
2025-02-13 00:24:10 INFO Running runs: ['auqsz2q6']
2025-02-13 00:24:50 INFO Cleaning up finished run: xsgemfox
2025-02-13 00:24:51 INFO Agent received command: run
2025-02-13 00:24:51 INFO Agent starting run with config:
	alpha_multiplier: 1
	data_file: /n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv
	dropout: 0.032076829554971466
	learning_rate: 7.361385563414905e-05
	length_penalty: 7.558239653160305
	model_name: facebook/bart-large-cnn
	num_train_epochs: 3
	output_dir: ./lora_bart_subtopics_sweep
	r: 64
	target_modules: q_proj,v_proj,k_proj,out_proj
	warmup_steps: 100
2025-02-13 00:24:51 INFO About to run command: /usr/bin/env python sweep_bart.py --alpha_multiplier=1 --data_file=/n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv --dropout=0.032076829554971466 --learning_rate=7.361385563414905e-05 --length_penalty=7.558239653160305 --model_name=facebook/bart-large-cnn --num_train_epochs=3 --output_dir=./lora_bart_subtopics_sweep --r=64 --target_modules=q_proj,v_proj,k_proj,out_proj --warmup_steps=100
2025-02-13 00:24:56 INFO Running runs: ['bdnyd4jk']
2025-02-13 00:38:01 INFO Cleaning up finished run: bdnyd4jk
2025-02-13 00:38:24 INFO Agent received command: run
2025-02-13 00:38:24 INFO Agent starting run with config:
	alpha_multiplier: 2
	data_file: /n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv
	dropout: 0.23883095602217205
	learning_rate: 9.967869706517728e-05
	length_penalty: 6.541060136933595
	model_name: facebook/bart-large-cnn
	num_train_epochs: 5
	output_dir: ./lora_bart_subtopics_sweep
	r: 128
	target_modules: q_proj,v_proj,k_proj
	warmup_steps: 1000
2025-02-13 00:38:24 INFO About to run command: /usr/bin/env python sweep_bart.py --alpha_multiplier=2 --data_file=/n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv --dropout=0.23883095602217205 --learning_rate=9.967869706517728e-05 --length_penalty=6.541060136933595 --model_name=facebook/bart-large-cnn --num_train_epochs=5 --output_dir=./lora_bart_subtopics_sweep --r=128 --target_modules=q_proj,v_proj,k_proj --warmup_steps=1000
2025-02-13 00:38:29 INFO Running runs: ['p33ffqmb']
2025-02-13 00:39:17 INFO Cleaning up finished run: auqsz2q6
2025-02-13 00:39:18 INFO Agent received command: run
2025-02-13 00:39:18 INFO Agent starting run with config:
	alpha_multiplier: 2
	data_file: /n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv
	dropout: 0.11009984769776492
	learning_rate: 3.291883940824448e-05
	length_penalty: 0.9744611059529829
	model_name: facebook/bart-large-cnn
	num_train_epochs: 2
	output_dir: ./lora_bart_subtopics_sweep
	r: 8
	target_modules: q_proj,v_proj
	warmup_steps: 0
2025-02-13 00:39:18 INFO About to run command: /usr/bin/env python sweep_bart.py --alpha_multiplier=2 --data_file=/n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv --dropout=0.11009984769776492 --learning_rate=3.291883940824448e-05 --length_penalty=0.9744611059529829 --model_name=facebook/bart-large-cnn --num_train_epochs=2 --output_dir=./lora_bart_subtopics_sweep --r=8 --target_modules=q_proj,v_proj --warmup_steps=0
2025-02-13 00:39:23 INFO Running runs: ['pdms8s2q']
2025-02-13 00:48:30 INFO Cleaning up finished run: pdms8s2q
2025-02-13 00:48:30 INFO Agent received command: run
2025-02-13 00:48:30 INFO Agent starting run with config:
	alpha_multiplier: 1
	data_file: /n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv
	dropout: 0.22295124673009217
	learning_rate: 9.123641787671409e-05
	length_penalty: 9.78077651805609
	model_name: facebook/bart-large-cnn
	num_train_epochs: 6
	output_dir: ./lora_bart_subtopics_sweep
	r: 32
	target_modules: q_proj,v_proj,k_proj,out_proj,fc1,fc2
	warmup_steps: 750
2025-02-13 00:48:30 INFO About to run command: /usr/bin/env python sweep_bart.py --alpha_multiplier=1 --data_file=/n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv --dropout=0.22295124673009217 --learning_rate=9.123641787671409e-05 --length_penalty=9.78077651805609 --model_name=facebook/bart-large-cnn --num_train_epochs=6 --output_dir=./lora_bart_subtopics_sweep --r=32 --target_modules=q_proj,v_proj,k_proj,out_proj,fc1,fc2 --warmup_steps=750
2025-02-13 00:48:35 INFO Running runs: ['5gv9nyni']
2025-02-13 00:53:31 INFO Cleaning up finished run: p33ffqmb
2025-02-13 00:53:31 INFO Agent received command: run
2025-02-13 00:53:31 INFO Agent starting run with config:
	alpha_multiplier: 1
	data_file: /n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv
	dropout: 0.6750984078511459
	learning_rate: 1.2203101828757244e-05
	length_penalty: 1.6799564318589566
	model_name: facebook/bart-large-cnn
	num_train_epochs: 5
	output_dir: ./lora_bart_subtopics_sweep
	r: 8
	target_modules: q_proj,v_proj,k_proj,out_proj,fc1,fc2
	warmup_steps: 1000
2025-02-13 00:53:31 INFO About to run command: /usr/bin/env python sweep_bart.py --alpha_multiplier=1 --data_file=/n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv --dropout=0.6750984078511459 --learning_rate=1.2203101828757244e-05 --length_penalty=1.6799564318589566 --model_name=facebook/bart-large-cnn --num_train_epochs=5 --output_dir=./lora_bart_subtopics_sweep --r=8 --target_modules=q_proj,v_proj,k_proj,out_proj,fc1,fc2 --warmup_steps=1000
2025-02-13 00:53:36 INFO Running runs: ['8hey6som']
2025-02-13 01:08:02 INFO Cleaning up finished run: 8hey6som
2025-02-13 01:08:03 INFO Agent received command: run
2025-02-13 01:08:03 INFO Agent starting run with config:
	alpha_multiplier: 1
	data_file: /n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv
	dropout: 0.7495435085424345
	learning_rate: 2.0544100239782825e-05
	length_penalty: 3.899852124526867
	model_name: facebook/bart-large-cnn
	num_train_epochs: 3
	output_dir: ./lora_bart_subtopics_sweep
	r: 64
	target_modules: q_proj,v_proj,k_proj,out_proj,fc1,fc2
	warmup_steps: 1000
2025-02-13 01:08:03 INFO About to run command: /usr/bin/env python sweep_bart.py --alpha_multiplier=1 --data_file=/n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv --dropout=0.7495435085424345 --learning_rate=2.0544100239782825e-05 --length_penalty=3.899852124526867 --model_name=facebook/bart-large-cnn --num_train_epochs=3 --output_dir=./lora_bart_subtopics_sweep --r=64 --target_modules=q_proj,v_proj,k_proj,out_proj,fc1,fc2 --warmup_steps=1000
2025-02-13 01:08:08 INFO Running runs: ['mlyr18xz']
2025-02-13 01:08:21 INFO Cleaning up finished run: 5gv9nyni
2025-02-13 01:08:22 INFO Agent received command: run
2025-02-13 01:08:22 INFO Agent starting run with config:
	alpha_multiplier: 1
	data_file: /n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv
	dropout: 0.5619566699812786
	learning_rate: 2.147857819239537e-05
	length_penalty: 7.827421226773481
	model_name: facebook/bart-large-cnn
	num_train_epochs: 10
	output_dir: ./lora_bart_subtopics_sweep
	r: 32
	target_modules: q_proj,v_proj
	warmup_steps: 250
2025-02-13 01:08:22 INFO About to run command: /usr/bin/env python sweep_bart.py --alpha_multiplier=1 --data_file=/n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv --dropout=0.5619566699812786 --learning_rate=2.147857819239537e-05 --length_penalty=7.827421226773481 --model_name=facebook/bart-large-cnn --num_train_epochs=10 --output_dir=./lora_bart_subtopics_sweep --r=32 --target_modules=q_proj,v_proj --warmup_steps=250
2025-02-13 01:08:27 INFO Running runs: ['lb1g8oyy']
2025-02-13 01:21:49 INFO Cleaning up finished run: mlyr18xz
2025-02-13 01:21:49 INFO Agent received command: run
2025-02-13 01:21:49 INFO Agent starting run with config:
	alpha_multiplier: 1
	data_file: /n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv
	dropout: 0.4660878230360386
	learning_rate: 9.88905667989308e-05
	length_penalty: 5.385618055320976
	model_name: facebook/bart-large-cnn
	num_train_epochs: 1
	output_dir: ./lora_bart_subtopics_sweep
	r: 16
	target_modules: q_proj,v_proj
	warmup_steps: 250
2025-02-13 01:21:49 INFO About to run command: /usr/bin/env python sweep_bart.py --alpha_multiplier=1 --data_file=/n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv --dropout=0.4660878230360386 --learning_rate=9.88905667989308e-05 --length_penalty=5.385618055320976 --model_name=facebook/bart-large-cnn --num_train_epochs=1 --output_dir=./lora_bart_subtopics_sweep --r=16 --target_modules=q_proj,v_proj --warmup_steps=250
2025-02-13 01:21:54 INFO Running runs: ['lvlxhmm6']
2025-02-13 01:26:46 INFO Cleaning up finished run: lb1g8oyy
2025-02-13 01:26:47 INFO Agent received command: run
2025-02-13 01:26:47 INFO Agent starting run with config:
	alpha_multiplier: 2
	data_file: /n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv
	dropout: 0.2124051965012856
	learning_rate: 2.8284003995123035e-05
	length_penalty: 4.312262724229581
	model_name: facebook/bart-large-cnn
	num_train_epochs: 8
	output_dir: ./lora_bart_subtopics_sweep
	r: 128
	target_modules: q_proj,v_proj,k_proj,out_proj
	warmup_steps: 750
2025-02-13 01:26:47 INFO About to run command: /usr/bin/env python sweep_bart.py --alpha_multiplier=2 --data_file=/n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv --dropout=0.2124051965012856 --learning_rate=2.8284003995123035e-05 --length_penalty=4.312262724229581 --model_name=facebook/bart-large-cnn --num_train_epochs=8 --output_dir=./lora_bart_subtopics_sweep --r=128 --target_modules=q_proj,v_proj,k_proj,out_proj --warmup_steps=750
2025-02-13 01:26:52 INFO Running runs: ['fwjxaagm']
2025-02-13 01:27:13 INFO Cleaning up finished run: lvlxhmm6
2025-02-13 01:27:14 INFO Agent received command: run
2025-02-13 01:27:14 INFO Agent starting run with config:
	alpha_multiplier: 2
	data_file: /n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv
	dropout: 0.33899904758648225
	learning_rate: 8.605739317007502e-05
	length_penalty: 3.373256094780462
	model_name: facebook/bart-large-cnn
	num_train_epochs: 5
	output_dir: ./lora_bart_subtopics_sweep
	r: 8
	target_modules: q_proj,v_proj,k_proj,out_proj
	warmup_steps: 100
2025-02-13 01:27:14 INFO About to run command: /usr/bin/env python sweep_bart.py --alpha_multiplier=2 --data_file=/n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv --dropout=0.33899904758648225 --learning_rate=8.605739317007502e-05 --length_penalty=3.373256094780462 --model_name=facebook/bart-large-cnn --num_train_epochs=5 --output_dir=./lora_bart_subtopics_sweep --r=8 --target_modules=q_proj,v_proj,k_proj,out_proj --warmup_steps=100
2025-02-13 01:27:19 INFO Running runs: ['jged3bz7']
2025-02-13 01:45:29 INFO Cleaning up finished run: jged3bz7
2025-02-13 01:45:29 INFO Agent received command: run
2025-02-13 01:45:29 INFO Agent starting run with config:
	alpha_multiplier: 2
	data_file: /n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv
	dropout: 0.4924878772238569
	learning_rate: 4.914472817315764e-05
	length_penalty: 6.616297821036347
	model_name: facebook/bart-large-cnn
	num_train_epochs: 1
	output_dir: ./lora_bart_subtopics_sweep
	r: 8
	target_modules: q_proj,v_proj,k_proj,out_proj,fc1,fc2
	warmup_steps: 1000
2025-02-13 01:45:29 INFO About to run command: /usr/bin/env python sweep_bart.py --alpha_multiplier=2 --data_file=/n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv --dropout=0.4924878772238569 --learning_rate=4.914472817315764e-05 --length_penalty=6.616297821036347 --model_name=facebook/bart-large-cnn --num_train_epochs=1 --output_dir=./lora_bart_subtopics_sweep --r=8 --target_modules=q_proj,v_proj,k_proj,out_proj,fc1,fc2 --warmup_steps=1000
2025-02-13 01:45:34 INFO Running runs: ['frvcuk2t']
2025-02-13 01:48:29 INFO Cleaning up finished run: fwjxaagm
2025-02-13 01:48:30 INFO Agent received command: run
2025-02-13 01:48:30 INFO Agent starting run with config:
	alpha_multiplier: 1
	data_file: /n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv
	dropout: 0.34227535310127827
	learning_rate: 6.443535530633893e-05
	length_penalty: 1.889517023661483
	model_name: facebook/bart-large-cnn
	num_train_epochs: 7
	output_dir: ./lora_bart_subtopics_sweep
	r: 64
	target_modules: q_proj,v_proj
	warmup_steps: 750
2025-02-13 01:48:30 INFO About to run command: /usr/bin/env python sweep_bart.py --alpha_multiplier=1 --data_file=/n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv --dropout=0.34227535310127827 --learning_rate=6.443535530633893e-05 --length_penalty=1.889517023661483 --model_name=facebook/bart-large-cnn --num_train_epochs=7 --output_dir=./lora_bart_subtopics_sweep --r=64 --target_modules=q_proj,v_proj --warmup_steps=750
2025-02-13 01:48:35 INFO Running runs: ['vg16yc6w']
2025-02-13 01:53:15 INFO Cleaning up finished run: frvcuk2t
2025-02-13 01:53:16 INFO Agent received command: run
2025-02-13 01:53:16 INFO Agent starting run with config:
	alpha_multiplier: 1
	data_file: /n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv
	dropout: 0.4752930687002208
	learning_rate: 7.195277718755585e-05
	length_penalty: 8.011553201432026
	model_name: facebook/bart-large-cnn
	num_train_epochs: 4
	output_dir: ./lora_bart_subtopics_sweep
	r: 16
	target_modules: q_proj,v_proj,k_proj,out_proj
	warmup_steps: 100
2025-02-13 01:53:16 INFO About to run command: /usr/bin/env python sweep_bart.py --alpha_multiplier=1 --data_file=/n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv --dropout=0.4752930687002208 --learning_rate=7.195277718755585e-05 --length_penalty=8.011553201432026 --model_name=facebook/bart-large-cnn --num_train_epochs=4 --output_dir=./lora_bart_subtopics_sweep --r=16 --target_modules=q_proj,v_proj,k_proj,out_proj --warmup_steps=100
2025-02-13 01:53:21 INFO Running runs: ['uphrkapb']
2025-02-13 02:05:33 INFO Cleaning up finished run: vg16yc6w
2025-02-13 02:05:34 INFO Agent received command: run
2025-02-13 02:05:34 INFO Agent starting run with config:
	alpha_multiplier: 1
	data_file: /n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv
	dropout: 0.1721324706606785
	learning_rate: 7.075474978008953e-06
	length_penalty: 6.423089519418314
	model_name: facebook/bart-large-cnn
	num_train_epochs: 1
	output_dir: ./lora_bart_subtopics_sweep
	r: 64
	target_modules: q_proj,v_proj,k_proj
	warmup_steps: 250
2025-02-13 02:05:34 INFO About to run command: /usr/bin/env python sweep_bart.py --alpha_multiplier=1 --data_file=/n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv --dropout=0.1721324706606785 --learning_rate=7.075474978008953e-06 --length_penalty=6.423089519418314 --model_name=facebook/bart-large-cnn --num_train_epochs=1 --output_dir=./lora_bart_subtopics_sweep --r=64 --target_modules=q_proj,v_proj,k_proj --warmup_steps=250
2025-02-13 02:05:39 INFO Running runs: ['kp4bywhh']
2025-02-13 02:06:01 INFO Cleaning up finished run: uphrkapb
2025-02-13 02:06:01 INFO Agent received command: run
2025-02-13 02:06:01 INFO Agent starting run with config:
	alpha_multiplier: 2
	data_file: /n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv
	dropout: 0.27788700890389917
	learning_rate: 9.076446595832077e-06
	length_penalty: 8.43729952788583
	model_name: facebook/bart-large-cnn
	num_train_epochs: 5
	output_dir: ./lora_bart_subtopics_sweep
	r: 64
	target_modules: q_proj,v_proj,k_proj,out_proj
	warmup_steps: 750
2025-02-13 02:06:01 INFO About to run command: /usr/bin/env python sweep_bart.py --alpha_multiplier=2 --data_file=/n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv --dropout=0.27788700890389917 --learning_rate=9.076446595832077e-06 --length_penalty=8.43729952788583 --model_name=facebook/bart-large-cnn --num_train_epochs=5 --output_dir=./lora_bart_subtopics_sweep --r=64 --target_modules=q_proj,v_proj,k_proj,out_proj --warmup_steps=750
2025-02-13 02:06:06 INFO Running runs: ['j308ns1n']
2025-02-13 02:14:05 INFO Cleaning up finished run: kp4bywhh
2025-02-13 02:14:06 INFO Agent received command: run
2025-02-13 02:14:06 INFO Agent starting run with config:
	alpha_multiplier: 2
	data_file: /n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv
	dropout: 0.1747391992714551
	learning_rate: 2.7620774965161247e-05
	length_penalty: 0.4519254492212821
	model_name: facebook/bart-large-cnn
	num_train_epochs: 2
	output_dir: ./lora_bart_subtopics_sweep
	r: 128
	target_modules: q_proj,v_proj
	warmup_steps: 750
2025-02-13 02:14:06 INFO About to run command: /usr/bin/env python sweep_bart.py --alpha_multiplier=2 --data_file=/n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv --dropout=0.1747391992714551 --learning_rate=2.7620774965161247e-05 --length_penalty=0.4519254492212821 --model_name=facebook/bart-large-cnn --num_train_epochs=2 --output_dir=./lora_bart_subtopics_sweep --r=128 --target_modules=q_proj,v_proj --warmup_steps=750
2025-02-13 02:14:11 INFO Running runs: ['69voo31q']
2025-02-13 02:17:05 INFO Cleaning up finished run: j308ns1n
2025-02-13 02:17:06 INFO Agent received command: run
2025-02-13 02:17:06 INFO Agent starting run with config:
	alpha_multiplier: 2
	data_file: /n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv
	dropout: 0.1955135311371608
	learning_rate: 6.612227093673773e-06
	length_penalty: 1.624610668915234
	model_name: facebook/bart-large-cnn
	num_train_epochs: 10
	output_dir: ./lora_bart_subtopics_sweep
	r: 64
	target_modules: q_proj,v_proj
	warmup_steps: 0
2025-02-13 02:17:06 INFO About to run command: /usr/bin/env python sweep_bart.py --alpha_multiplier=2 --data_file=/n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv --dropout=0.1955135311371608 --learning_rate=6.612227093673773e-06 --length_penalty=1.624610668915234 --model_name=facebook/bart-large-cnn --num_train_epochs=10 --output_dir=./lora_bart_subtopics_sweep --r=64 --target_modules=q_proj,v_proj --warmup_steps=0
2025-02-13 02:17:11 INFO Running runs: ['fsu48u18']
2025-02-13 02:20:51 INFO Cleaning up finished run: 69voo31q
2025-02-13 02:20:52 INFO Agent received command: run
2025-02-13 02:20:52 INFO Agent starting run with config:
	alpha_multiplier: 2
	data_file: /n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv
	dropout: 0.14702695425288806
	learning_rate: 2.984659357571304e-05
	length_penalty: 9.90827656377684
	model_name: facebook/bart-large-cnn
	num_train_epochs: 6
	output_dir: ./lora_bart_subtopics_sweep
	r: 64
	target_modules: q_proj,v_proj,k_proj,out_proj
	warmup_steps: 500
2025-02-13 02:20:52 INFO About to run command: /usr/bin/env python sweep_bart.py --alpha_multiplier=2 --data_file=/n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv --dropout=0.14702695425288806 --learning_rate=2.984659357571304e-05 --length_penalty=9.90827656377684 --model_name=facebook/bart-large-cnn --num_train_epochs=6 --output_dir=./lora_bart_subtopics_sweep --r=64 --target_modules=q_proj,v_proj,k_proj,out_proj --warmup_steps=500
2025-02-13 02:20:57 INFO Running runs: ['5n1c9dyj']
2025-02-13 02:36:51 INFO Cleaning up finished run: fsu48u18
2025-02-13 02:36:52 INFO Agent received command: run
2025-02-13 02:36:52 INFO Agent starting run with config:
	alpha_multiplier: 2
	data_file: /n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv
	dropout: 0.5593255994834044
	learning_rate: 2.826140901508288e-05
	length_penalty: 0.751626635833208
	model_name: facebook/bart-large-cnn
	num_train_epochs: 8
	output_dir: ./lora_bart_subtopics_sweep
	r: 8
	target_modules: q_proj,v_proj,k_proj
	warmup_steps: 0
2025-02-13 02:36:52 INFO About to run command: /usr/bin/env python sweep_bart.py --alpha_multiplier=2 --data_file=/n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv --dropout=0.5593255994834044 --learning_rate=2.826140901508288e-05 --length_penalty=0.751626635833208 --model_name=facebook/bart-large-cnn --num_train_epochs=8 --output_dir=./lora_bart_subtopics_sweep --r=8 --target_modules=q_proj,v_proj,k_proj --warmup_steps=0
2025-02-13 02:36:57 INFO Running runs: ['lbd0mr2u']
2025-02-13 02:41:18 INFO Cleaning up finished run: 5n1c9dyj
2025-02-13 02:41:19 INFO Agent received command: run
2025-02-13 02:41:19 INFO Agent starting run with config:
	alpha_multiplier: 2
	data_file: /n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv
	dropout: 0.7164686140888792
	learning_rate: 7.722170912010442e-05
	length_penalty: 3.770034053982878
	model_name: facebook/bart-large-cnn
	num_train_epochs: 2
	output_dir: ./lora_bart_subtopics_sweep
	r: 16
	target_modules: q_proj,v_proj,k_proj,out_proj
	warmup_steps: 250
2025-02-13 02:41:19 INFO About to run command: /usr/bin/env python sweep_bart.py --alpha_multiplier=2 --data_file=/n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv --dropout=0.7164686140888792 --learning_rate=7.722170912010442e-05 --length_penalty=3.770034053982878 --model_name=facebook/bart-large-cnn --num_train_epochs=2 --output_dir=./lora_bart_subtopics_sweep --r=16 --target_modules=q_proj,v_proj,k_proj,out_proj --warmup_steps=250
2025-02-13 02:41:24 INFO Running runs: ['6zttialg']
2025-02-13 02:51:43 INFO Cleaning up finished run: 6zttialg
2025-02-13 02:51:43 INFO Agent received command: run
2025-02-13 02:51:43 INFO Agent starting run with config:
	alpha_multiplier: 1
	data_file: /n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv
	dropout: 0.7026851091685086
	learning_rate: 9.17853077716058e-05
	length_penalty: 6.499651610477287
	model_name: facebook/bart-large-cnn
	num_train_epochs: 10
	output_dir: ./lora_bart_subtopics_sweep
	r: 8
	target_modules: q_proj,v_proj,k_proj,out_proj
	warmup_steps: 500
2025-02-13 02:51:43 INFO About to run command: /usr/bin/env python sweep_bart.py --alpha_multiplier=1 --data_file=/n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv --dropout=0.7026851091685086 --learning_rate=9.17853077716058e-05 --length_penalty=6.499651610477287 --model_name=facebook/bart-large-cnn --num_train_epochs=10 --output_dir=./lora_bart_subtopics_sweep --r=8 --target_modules=q_proj,v_proj,k_proj,out_proj --warmup_steps=500
2025-02-13 02:51:48 INFO Running runs: ['yim5yves']
2025-02-13 02:52:24 INFO Cleaning up finished run: lbd0mr2u
2025-02-13 02:52:25 INFO Agent received command: run
2025-02-13 02:52:25 INFO Agent starting run with config:
	alpha_multiplier: 2
	data_file: /n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv
	dropout: 0.7405680661281676
	learning_rate: 3.2536500333035394e-05
	length_penalty: 4.512316993146306
	model_name: facebook/bart-large-cnn
	num_train_epochs: 2
	output_dir: ./lora_bart_subtopics_sweep
	r: 32
	target_modules: q_proj,v_proj,k_proj
	warmup_steps: 100
2025-02-13 02:52:25 INFO About to run command: /usr/bin/env python sweep_bart.py --alpha_multiplier=2 --data_file=/n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv --dropout=0.7405680661281676 --learning_rate=3.2536500333035394e-05 --length_penalty=4.512316993146306 --model_name=facebook/bart-large-cnn --num_train_epochs=2 --output_dir=./lora_bart_subtopics_sweep --r=32 --target_modules=q_proj,v_proj,k_proj --warmup_steps=100
2025-02-13 02:52:30 INFO Running runs: ['1d4abewz']
2025-02-13 03:00:57 INFO Cleaning up finished run: 1d4abewz
2025-02-13 03:00:57 INFO Agent received command: run
2025-02-13 03:00:57 INFO Agent starting run with config:
	alpha_multiplier: 1
	data_file: /n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv
	dropout: 0.0789450619432559
	learning_rate: 3.866088055813584e-05
	length_penalty: 3.089764747681516
	model_name: facebook/bart-large-cnn
	num_train_epochs: 8
	output_dir: ./lora_bart_subtopics_sweep
	r: 64
	target_modules: q_proj,v_proj,k_proj
	warmup_steps: 250
2025-02-13 03:00:57 INFO About to run command: /usr/bin/env python sweep_bart.py --alpha_multiplier=1 --data_file=/n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv --dropout=0.0789450619432559 --learning_rate=3.866088055813584e-05 --length_penalty=3.089764747681516 --model_name=facebook/bart-large-cnn --num_train_epochs=8 --output_dir=./lora_bart_subtopics_sweep --r=64 --target_modules=q_proj,v_proj,k_proj --warmup_steps=250
2025-02-13 03:01:02 INFO Running runs: ['gdz1ip1l']
2025-02-13 03:18:46 INFO Cleaning up finished run: yim5yves
2025-02-13 03:18:47 INFO Agent received command: run
2025-02-13 03:18:47 INFO Agent starting run with config:
	alpha_multiplier: 1
	data_file: /n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv
	dropout: 0.00696747298534719
	learning_rate: 5.881775596043889e-05
	length_penalty: 6.823348125006801
	model_name: facebook/bart-large-cnn
	num_train_epochs: 7
	output_dir: ./lora_bart_subtopics_sweep
	r: 32
	target_modules: q_proj,v_proj,k_proj,out_proj,fc1,fc2
	warmup_steps: 100
2025-02-13 03:18:47 INFO About to run command: /usr/bin/env python sweep_bart.py --alpha_multiplier=1 --data_file=/n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv --dropout=0.00696747298534719 --learning_rate=5.881775596043889e-05 --length_penalty=6.823348125006801 --model_name=facebook/bart-large-cnn --num_train_epochs=7 --output_dir=./lora_bart_subtopics_sweep --r=32 --target_modules=q_proj,v_proj,k_proj,out_proj,fc1,fc2 --warmup_steps=100
2025-02-13 03:18:52 INFO Running runs: ['5evdcsto']
2025-02-13 03:19:16 INFO Cleaning up finished run: gdz1ip1l
2025-02-13 03:19:17 INFO Agent received command: run
2025-02-13 03:19:17 INFO Agent starting run with config:
	alpha_multiplier: 2
	data_file: /n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv
	dropout: 0.5542009120130503
	learning_rate: 6.022687167350994e-05
	length_penalty: 0.9736098610082132
	model_name: facebook/bart-large-cnn
	num_train_epochs: 4
	output_dir: ./lora_bart_subtopics_sweep
	r: 32
	target_modules: q_proj,v_proj,k_proj,out_proj,fc1,fc2
	warmup_steps: 750
2025-02-13 03:19:17 INFO About to run command: /usr/bin/env python sweep_bart.py --alpha_multiplier=2 --data_file=/n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv --dropout=0.5542009120130503 --learning_rate=6.022687167350994e-05 --length_penalty=0.9736098610082132 --model_name=facebook/bart-large-cnn --num_train_epochs=4 --output_dir=./lora_bart_subtopics_sweep --r=32 --target_modules=q_proj,v_proj,k_proj,out_proj,fc1,fc2 --warmup_steps=750
2025-02-13 03:19:22 INFO Running runs: ['mdc2r96f']
2025-02-13 03:33:43 INFO Cleaning up finished run: mdc2r96f
2025-02-13 03:33:44 INFO Agent received command: run
2025-02-13 03:33:44 INFO Agent starting run with config:
	alpha_multiplier: 1
	data_file: /n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv
	dropout: 0.5385186913880274
	learning_rate: 2.3111884315066554e-05
	length_penalty: 1.3286496779097725
	model_name: facebook/bart-large-cnn
	num_train_epochs: 3
	output_dir: ./lora_bart_subtopics_sweep
	r: 128
	target_modules: q_proj,v_proj,k_proj,out_proj,fc1,fc2
	warmup_steps: 500
2025-02-13 03:33:44 INFO About to run command: /usr/bin/env python sweep_bart.py --alpha_multiplier=1 --data_file=/n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv --dropout=0.5385186913880274 --learning_rate=2.3111884315066554e-05 --length_penalty=1.3286496779097725 --model_name=facebook/bart-large-cnn --num_train_epochs=3 --output_dir=./lora_bart_subtopics_sweep --r=128 --target_modules=q_proj,v_proj,k_proj,out_proj,fc1,fc2 --warmup_steps=500
2025-02-13 03:33:49 INFO Running runs: ['si9nof8a']
2025-02-13 03:40:04 INFO Cleaning up finished run: 5evdcsto
2025-02-13 03:40:04 INFO Agent received command: run
2025-02-13 03:40:04 INFO Agent starting run with config:
	alpha_multiplier: 2
	data_file: /n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv
	dropout: 0.3448602372406857
	learning_rate: 2.6838377305924462e-05
	length_penalty: 7.913206989853072
	model_name: facebook/bart-large-cnn
	num_train_epochs: 4
	output_dir: ./lora_bart_subtopics_sweep
	r: 128
	target_modules: q_proj,v_proj,k_proj,out_proj,fc1,fc2
	warmup_steps: 100
2025-02-13 03:40:04 INFO About to run command: /usr/bin/env python sweep_bart.py --alpha_multiplier=2 --data_file=/n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv --dropout=0.3448602372406857 --learning_rate=2.6838377305924462e-05 --length_penalty=7.913206989853072 --model_name=facebook/bart-large-cnn --num_train_epochs=4 --output_dir=./lora_bart_subtopics_sweep --r=128 --target_modules=q_proj,v_proj,k_proj,out_proj,fc1,fc2 --warmup_steps=100
2025-02-13 03:40:09 INFO Running runs: ['zjtzfpoy']
2025-02-13 03:43:13 INFO Cleaning up finished run: si9nof8a
2025-02-13 03:43:14 INFO Agent received command: run
2025-02-13 03:43:14 INFO Agent starting run with config:
	alpha_multiplier: 1
	data_file: /n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv
	dropout: 0.527331444440582
	learning_rate: 7.730941794369612e-05
	length_penalty: 7.217819216559688
	model_name: facebook/bart-large-cnn
	num_train_epochs: 4
	output_dir: ./lora_bart_subtopics_sweep
	r: 128
	target_modules: q_proj,v_proj,k_proj
	warmup_steps: 0
2025-02-13 03:43:14 INFO About to run command: /usr/bin/env python sweep_bart.py --alpha_multiplier=1 --data_file=/n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv --dropout=0.527331444440582 --learning_rate=7.730941794369612e-05 --length_penalty=7.217819216559688 --model_name=facebook/bart-large-cnn --num_train_epochs=4 --output_dir=./lora_bart_subtopics_sweep --r=128 --target_modules=q_proj,v_proj,k_proj --warmup_steps=0
2025-02-13 03:43:19 INFO Running runs: ['zwasbbzt']
2025-02-13 03:55:36 INFO Cleaning up finished run: zjtzfpoy
2025-02-13 03:55:37 INFO Agent received command: run
2025-02-13 03:55:37 INFO Agent starting run with config:
	alpha_multiplier: 1
	data_file: /n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv
	dropout: 0.7951110734749816
	learning_rate: 5.566276887344448e-06
	length_penalty: 0.14118601225266425
	model_name: facebook/bart-large-cnn
	num_train_epochs: 9
	output_dir: ./lora_bart_subtopics_sweep
	r: 16
	target_modules: q_proj,v_proj,k_proj
	warmup_steps: 750
2025-02-13 03:55:37 INFO About to run command: /usr/bin/env python sweep_bart.py --alpha_multiplier=1 --data_file=/n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv --dropout=0.7951110734749816 --learning_rate=5.566276887344448e-06 --length_penalty=0.14118601225266425 --model_name=facebook/bart-large-cnn --num_train_epochs=9 --output_dir=./lora_bart_subtopics_sweep --r=16 --target_modules=q_proj,v_proj,k_proj --warmup_steps=750
2025-02-13 03:55:42 INFO Running runs: ['l974kfv2']
2025-02-13 03:55:54 INFO Cleaning up finished run: zwasbbzt
2025-02-13 03:55:54 INFO Agent received command: run
2025-02-13 03:55:54 INFO Agent starting run with config:
	alpha_multiplier: 1
	data_file: /n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv
	dropout: 0.09584712414049967
	learning_rate: 8.792405803842913e-05
	length_penalty: 7.740808912938969
	model_name: facebook/bart-large-cnn
	num_train_epochs: 8
	output_dir: ./lora_bart_subtopics_sweep
	r: 8
	target_modules: q_proj,v_proj
	warmup_steps: 500
2025-02-13 03:55:54 INFO About to run command: /usr/bin/env python sweep_bart.py --alpha_multiplier=1 --data_file=/n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv --dropout=0.09584712414049967 --learning_rate=8.792405803842913e-05 --length_penalty=7.740808912938969 --model_name=facebook/bart-large-cnn --num_train_epochs=8 --output_dir=./lora_bart_subtopics_sweep --r=8 --target_modules=q_proj,v_proj --warmup_steps=500
2025-02-13 03:55:59 INFO Running runs: ['lfefhp26']
2025-02-13 04:15:40 INFO Cleaning up finished run: lfefhp26
2025-02-13 04:15:40 INFO Agent received command: run
2025-02-13 04:15:40 INFO Agent starting run with config:
	alpha_multiplier: 1
	data_file: /n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv
	dropout: 0.0718643927395994
	learning_rate: 2.9343337866334513e-05
	length_penalty: 4.371725226888382
	model_name: facebook/bart-large-cnn
	num_train_epochs: 6
	output_dir: ./lora_bart_subtopics_sweep
	r: 64
	target_modules: q_proj,v_proj,k_proj,out_proj
	warmup_steps: 500
2025-02-13 04:15:40 INFO About to run command: /usr/bin/env python sweep_bart.py --alpha_multiplier=1 --data_file=/n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv --dropout=0.0718643927395994 --learning_rate=2.9343337866334513e-05 --length_penalty=4.371725226888382 --model_name=facebook/bart-large-cnn --num_train_epochs=6 --output_dir=./lora_bart_subtopics_sweep --r=64 --target_modules=q_proj,v_proj,k_proj,out_proj --warmup_steps=500
2025-02-13 04:15:45 INFO Running runs: ['3bnev7ge']
2025-02-13 04:16:13 INFO Cleaning up finished run: l974kfv2
2025-02-13 04:16:14 INFO Agent received command: run
2025-02-13 04:16:14 INFO Agent starting run with config:
	alpha_multiplier: 2
	data_file: /n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv
	dropout: 0.04048557428075333
	learning_rate: 4.4087366813787305e-05
	length_penalty: 5.218634580378349
	model_name: facebook/bart-large-cnn
	num_train_epochs: 7
	output_dir: ./lora_bart_subtopics_sweep
	r: 16
	target_modules: q_proj,v_proj
	warmup_steps: 750
2025-02-13 04:16:14 INFO About to run command: /usr/bin/env python sweep_bart.py --alpha_multiplier=2 --data_file=/n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv --dropout=0.04048557428075333 --learning_rate=4.4087366813787305e-05 --length_penalty=5.218634580378349 --model_name=facebook/bart-large-cnn --num_train_epochs=7 --output_dir=./lora_bart_subtopics_sweep --r=16 --target_modules=q_proj,v_proj --warmup_steps=750
2025-02-13 04:16:19 INFO Running runs: ['jf06pfq3']
2025-02-13 04:34:29 INFO Cleaning up finished run: jf06pfq3
2025-02-13 04:34:29 INFO Agent received command: run
2025-02-13 04:34:29 INFO Agent starting run with config:
	alpha_multiplier: 1
	data_file: /n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv
	dropout: 0.6048845120546729
	learning_rate: 9.12011380228968e-05
	length_penalty: 3.490736319677329
	model_name: facebook/bart-large-cnn
	num_train_epochs: 5
	output_dir: ./lora_bart_subtopics_sweep
	r: 64
	target_modules: q_proj,v_proj,k_proj,out_proj,fc1,fc2
	warmup_steps: 500
2025-02-13 04:34:29 INFO About to run command: /usr/bin/env python sweep_bart.py --alpha_multiplier=1 --data_file=/n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv --dropout=0.6048845120546729 --learning_rate=9.12011380228968e-05 --length_penalty=3.490736319677329 --model_name=facebook/bart-large-cnn --num_train_epochs=5 --output_dir=./lora_bart_subtopics_sweep --r=64 --target_modules=q_proj,v_proj,k_proj,out_proj,fc1,fc2 --warmup_steps=500
2025-02-13 04:34:34 INFO Running runs: ['jyeegt15']
2025-02-13 04:35:10 INFO Cleaning up finished run: 3bnev7ge
2025-02-13 04:35:11 INFO Agent received command: run
2025-02-13 04:35:11 INFO Agent starting run with config:
	alpha_multiplier: 1
	data_file: /n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv
	dropout: 0.3981505870297226
	learning_rate: 6.522541646285045e-05
	length_penalty: 7.792765601814901
	model_name: facebook/bart-large-cnn
	num_train_epochs: 5
	output_dir: ./lora_bart_subtopics_sweep
	r: 8
	target_modules: q_proj,v_proj
	warmup_steps: 250
2025-02-13 04:35:11 INFO About to run command: /usr/bin/env python sweep_bart.py --alpha_multiplier=1 --data_file=/n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv --dropout=0.3981505870297226 --learning_rate=6.522541646285045e-05 --length_penalty=7.792765601814901 --model_name=facebook/bart-large-cnn --num_train_epochs=5 --output_dir=./lora_bart_subtopics_sweep --r=8 --target_modules=q_proj,v_proj --warmup_steps=250
2025-02-13 04:35:16 INFO Running runs: ['h8lsnk8b']
2025-02-13 04:48:21 INFO Cleaning up finished run: h8lsnk8b
2025-02-13 04:48:22 INFO Agent received command: run
2025-02-13 04:48:22 INFO Agent starting run with config:
	alpha_multiplier: 1
	data_file: /n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv
	dropout: 0.4016064155130268
	learning_rate: 2.3253559956383578e-05
	length_penalty: 7.053466366222327
	model_name: facebook/bart-large-cnn
	num_train_epochs: 10
	output_dir: ./lora_bart_subtopics_sweep
	r: 64
	target_modules: q_proj,v_proj,k_proj
	warmup_steps: 750
2025-02-13 04:48:22 INFO About to run command: /usr/bin/env python sweep_bart.py --alpha_multiplier=1 --data_file=/n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv --dropout=0.4016064155130268 --learning_rate=2.3253559956383578e-05 --length_penalty=7.053466366222327 --model_name=facebook/bart-large-cnn --num_train_epochs=10 --output_dir=./lora_bart_subtopics_sweep --r=64 --target_modules=q_proj,v_proj,k_proj --warmup_steps=750
2025-02-13 04:48:27 INFO Running runs: ['6r1z8bxe']
2025-02-13 04:52:49 INFO Cleaning up finished run: jyeegt15
2025-02-13 04:52:50 INFO Agent received command: run
2025-02-13 04:52:50 INFO Agent starting run with config:
	alpha_multiplier: 1
	data_file: /n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv
	dropout: 0.5105538922023807
	learning_rate: 2.2649995181134016e-05
	length_penalty: 3.4930918576811933
	model_name: facebook/bart-large-cnn
	num_train_epochs: 8
	output_dir: ./lora_bart_subtopics_sweep
	r: 8
	target_modules: q_proj,v_proj,k_proj,out_proj
	warmup_steps: 1000
2025-02-13 04:52:50 INFO About to run command: /usr/bin/env python sweep_bart.py --alpha_multiplier=1 --data_file=/n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv --dropout=0.5105538922023807 --learning_rate=2.2649995181134016e-05 --length_penalty=3.4930918576811933 --model_name=facebook/bart-large-cnn --num_train_epochs=8 --output_dir=./lora_bart_subtopics_sweep --r=8 --target_modules=q_proj,v_proj,k_proj,out_proj --warmup_steps=1000
2025-02-13 04:52:55 INFO Running runs: ['ryo9356x']
2025-02-13 05:11:25 INFO Cleaning up finished run: 6r1z8bxe
2025-02-13 05:11:26 INFO Agent received command: run
2025-02-13 05:11:26 INFO Agent starting run with config:
	alpha_multiplier: 1
	data_file: /n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv
	dropout: 0.4773770302132168
	learning_rate: 1.3584892307988038e-05
	length_penalty: 3.722985860642192
	model_name: facebook/bart-large-cnn
	num_train_epochs: 4
	output_dir: ./lora_bart_subtopics_sweep
	r: 16
	target_modules: q_proj,v_proj
	warmup_steps: 250
2025-02-13 05:11:26 INFO About to run command: /usr/bin/env python sweep_bart.py --alpha_multiplier=1 --data_file=/n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv --dropout=0.4773770302132168 --learning_rate=1.3584892307988038e-05 --length_penalty=3.722985860642192 --model_name=facebook/bart-large-cnn --num_train_epochs=4 --output_dir=./lora_bart_subtopics_sweep --r=16 --target_modules=q_proj,v_proj --warmup_steps=250
2025-02-13 05:11:31 INFO Running runs: ['q56vhhtp']
2025-02-13 05:11:50 INFO Cleaning up finished run: ryo9356x
2025-02-13 05:11:51 INFO Agent received command: run
2025-02-13 05:11:51 INFO Agent starting run with config:
	alpha_multiplier: 2
	data_file: /n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv
	dropout: 0.6649052467479384
	learning_rate: 5.708242655494694e-05
	length_penalty: 5.858424776419016
	model_name: facebook/bart-large-cnn
	num_train_epochs: 4
	output_dir: ./lora_bart_subtopics_sweep
	r: 32
	target_modules: q_proj,v_proj,k_proj
	warmup_steps: 1000
2025-02-13 05:11:51 INFO About to run command: /usr/bin/env python sweep_bart.py --alpha_multiplier=2 --data_file=/n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv --dropout=0.6649052467479384 --learning_rate=5.708242655494694e-05 --length_penalty=5.858424776419016 --model_name=facebook/bart-large-cnn --num_train_epochs=4 --output_dir=./lora_bart_subtopics_sweep --r=32 --target_modules=q_proj,v_proj,k_proj --warmup_steps=1000
2025-02-13 05:11:56 INFO Running runs: ['9f2ywcta']
2025-02-13 05:24:01 INFO Cleaning up finished run: q56vhhtp
2025-02-13 05:24:01 INFO Agent received command: run
2025-02-13 05:24:01 INFO Agent starting run with config:
	alpha_multiplier: 2
	data_file: /n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv
	dropout: 0.4572841640597847
	learning_rate: 3.040883517009316e-05
	length_penalty: 4.31240755986342
	model_name: facebook/bart-large-cnn
	num_train_epochs: 3
	output_dir: ./lora_bart_subtopics_sweep
	r: 64
	target_modules: q_proj,v_proj,k_proj
	warmup_steps: 250
2025-02-13 05:24:01 INFO About to run command: /usr/bin/env python sweep_bart.py --alpha_multiplier=2 --data_file=/n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv --dropout=0.4572841640597847 --learning_rate=3.040883517009316e-05 --length_penalty=4.31240755986342 --model_name=facebook/bart-large-cnn --num_train_epochs=3 --output_dir=./lora_bart_subtopics_sweep --r=64 --target_modules=q_proj,v_proj,k_proj --warmup_steps=250
2025-02-13 05:24:05 INFO Cleaning up finished run: 9f2ywcta
2025-02-13 05:24:06 INFO Agent received command: run
2025-02-13 05:24:06 INFO Agent starting run with config:
	alpha_multiplier: 1
	data_file: /n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv
	dropout: 0.4834741233033806
	learning_rate: 5.100903513820392e-05
	length_penalty: 7.466040368334193
	model_name: facebook/bart-large-cnn
	num_train_epochs: 7
	output_dir: ./lora_bart_subtopics_sweep
	r: 32
	target_modules: q_proj,v_proj,k_proj,out_proj
	warmup_steps: 250
2025-02-13 05:24:06 INFO About to run command: /usr/bin/env python sweep_bart.py --alpha_multiplier=1 --data_file=/n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv --dropout=0.4834741233033806 --learning_rate=5.100903513820392e-05 --length_penalty=7.466040368334193 --model_name=facebook/bart-large-cnn --num_train_epochs=7 --output_dir=./lora_bart_subtopics_sweep --r=32 --target_modules=q_proj,v_proj,k_proj,out_proj --warmup_steps=250
2025-02-13 05:24:06 INFO Running runs: ['1lxlk38v']
2025-02-13 05:24:11 INFO Running runs: ['t3q63f1k']
2025-02-13 05:35:00 INFO Cleaning up finished run: 1lxlk38v
2025-02-13 05:35:01 INFO Agent received command: run
2025-02-13 05:35:01 INFO Agent starting run with config:
	alpha_multiplier: 1
	data_file: /n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv
	dropout: 0.32504753320393287
	learning_rate: 7.299696931651505e-05
	length_penalty: 0.3653141491273249
	model_name: facebook/bart-large-cnn
	num_train_epochs: 8
	output_dir: ./lora_bart_subtopics_sweep
	r: 64
	target_modules: q_proj,v_proj,k_proj,out_proj,fc1,fc2
	warmup_steps: 500
2025-02-13 05:35:01 INFO About to run command: /usr/bin/env python sweep_bart.py --alpha_multiplier=1 --data_file=/n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv --dropout=0.32504753320393287 --learning_rate=7.299696931651505e-05 --length_penalty=0.3653141491273249 --model_name=facebook/bart-large-cnn --num_train_epochs=8 --output_dir=./lora_bart_subtopics_sweep --r=64 --target_modules=q_proj,v_proj,k_proj,out_proj,fc1,fc2 --warmup_steps=500
2025-02-13 05:35:06 INFO Running runs: ['emlnzltw']
2025-02-13 05:44:39 INFO Cleaning up finished run: t3q63f1k
2025-02-13 05:44:40 INFO Agent received command: run
2025-02-13 05:44:40 INFO Agent starting run with config:
	alpha_multiplier: 2
	data_file: /n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv
	dropout: 0.08894530224163635
	learning_rate: 2.870625771405135e-05
	length_penalty: 0.846348236484511
	model_name: facebook/bart-large-cnn
	num_train_epochs: 10
	output_dir: ./lora_bart_subtopics_sweep
	r: 128
	target_modules: q_proj,v_proj,k_proj
	warmup_steps: 750
2025-02-13 05:44:40 INFO About to run command: /usr/bin/env python sweep_bart.py --alpha_multiplier=2 --data_file=/n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv --dropout=0.08894530224163635 --learning_rate=2.870625771405135e-05 --length_penalty=0.846348236484511 --model_name=facebook/bart-large-cnn --num_train_epochs=10 --output_dir=./lora_bart_subtopics_sweep --r=128 --target_modules=q_proj,v_proj,k_proj --warmup_steps=750
2025-02-13 05:44:45 INFO Running runs: ['ynf47ita']
2025-02-13 06:00:26 INFO Cleaning up finished run: emlnzltw
2025-02-13 06:00:27 INFO Agent received command: run
2025-02-13 06:00:27 INFO Agent starting run with config:
	alpha_multiplier: 2
	data_file: /n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv
	dropout: 0.5294667003379896
	learning_rate: 6.860680452301991e-05
	length_penalty: 7.87261491748588
	model_name: facebook/bart-large-cnn
	num_train_epochs: 1
	output_dir: ./lora_bart_subtopics_sweep
	r: 16
	target_modules: q_proj,v_proj,k_proj
	warmup_steps: 100
2025-02-13 06:00:27 INFO About to run command: /usr/bin/env python sweep_bart.py --alpha_multiplier=2 --data_file=/n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv --dropout=0.5294667003379896 --learning_rate=6.860680452301991e-05 --length_penalty=7.87261491748588 --model_name=facebook/bart-large-cnn --num_train_epochs=1 --output_dir=./lora_bart_subtopics_sweep --r=16 --target_modules=q_proj,v_proj,k_proj --warmup_steps=100
2025-02-13 06:00:32 INFO Running runs: ['0r5ko5kc']
2025-02-13 06:06:02 INFO Cleaning up finished run: ynf47ita
2025-02-13 06:06:02 INFO Agent received command: run
2025-02-13 06:06:02 INFO Agent starting run with config:
	alpha_multiplier: 2
	data_file: /n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv
	dropout: 0.5879344866147174
	learning_rate: 9.657118364579022e-05
	length_penalty: 9.982879151413131
	model_name: facebook/bart-large-cnn
	num_train_epochs: 9
	output_dir: ./lora_bart_subtopics_sweep
	r: 8
	target_modules: q_proj,v_proj,k_proj,out_proj,fc1,fc2
	warmup_steps: 1000
2025-02-13 06:06:02 INFO About to run command: /usr/bin/env python sweep_bart.py --alpha_multiplier=2 --data_file=/n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv --dropout=0.5879344866147174 --learning_rate=9.657118364579022e-05 --length_penalty=9.982879151413131 --model_name=facebook/bart-large-cnn --num_train_epochs=9 --output_dir=./lora_bart_subtopics_sweep --r=8 --target_modules=q_proj,v_proj,k_proj,out_proj,fc1,fc2 --warmup_steps=1000
2025-02-13 06:06:07 INFO Running runs: ['x4gi7lut']
2025-02-13 06:06:11 INFO Cleaning up finished run: 0r5ko5kc
2025-02-13 06:06:12 INFO Agent received command: run
2025-02-13 06:06:12 INFO Agent starting run with config:
	alpha_multiplier: 1
	data_file: /n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv
	dropout: 0.7342567884468886
	learning_rate: 7.891361068445248e-06
	length_penalty: 2.3333574000928836
	model_name: facebook/bart-large-cnn
	num_train_epochs: 10
	output_dir: ./lora_bart_subtopics_sweep
	r: 128
	target_modules: q_proj,v_proj,k_proj,out_proj
	warmup_steps: 0
2025-02-13 06:06:12 INFO About to run command: /usr/bin/env python sweep_bart.py --alpha_multiplier=1 --data_file=/n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv --dropout=0.7342567884468886 --learning_rate=7.891361068445248e-06 --length_penalty=2.3333574000928836 --model_name=facebook/bart-large-cnn --num_train_epochs=10 --output_dir=./lora_bart_subtopics_sweep --r=128 --target_modules=q_proj,v_proj,k_proj,out_proj --warmup_steps=0
2025-02-13 06:06:17 INFO Running runs: ['zs1gjfpi']
2025-02-13 06:31:07 INFO Cleaning up finished run: zs1gjfpi
2025-02-13 06:31:08 INFO Agent received command: run
2025-02-13 06:31:08 INFO Agent starting run with config:
	alpha_multiplier: 2
	data_file: /n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv
	dropout: 0.4270170524066644
	learning_rate: 4.990098964021203e-05
	length_penalty: 3.4667945565877156
	model_name: facebook/bart-large-cnn
	num_train_epochs: 7
	output_dir: ./lora_bart_subtopics_sweep
	r: 8
	target_modules: q_proj,v_proj
	warmup_steps: 100
2025-02-13 06:31:08 INFO About to run command: /usr/bin/env python sweep_bart.py --alpha_multiplier=2 --data_file=/n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv --dropout=0.4270170524066644 --learning_rate=4.990098964021203e-05 --length_penalty=3.4667945565877156 --model_name=facebook/bart-large-cnn --num_train_epochs=7 --output_dir=./lora_bart_subtopics_sweep --r=8 --target_modules=q_proj,v_proj --warmup_steps=100
2025-02-13 06:31:13 INFO Running runs: ['vgqse8m5']
2025-02-13 06:34:35 INFO Cleaning up finished run: x4gi7lut
2025-02-13 06:34:35 INFO Agent received command: run
2025-02-13 06:34:35 INFO Agent starting run with config:
	alpha_multiplier: 2
	data_file: /n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv
	dropout: 0.1147652738835868
	learning_rate: 2.4239555400712576e-05
	length_penalty: 6.477173063714075
	model_name: facebook/bart-large-cnn
	num_train_epochs: 10
	output_dir: ./lora_bart_subtopics_sweep
	r: 64
	target_modules: q_proj,v_proj
	warmup_steps: 100
2025-02-13 06:34:36 INFO About to run command: /usr/bin/env python sweep_bart.py --alpha_multiplier=2 --data_file=/n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv --dropout=0.1147652738835868 --learning_rate=2.4239555400712576e-05 --length_penalty=6.477173063714075 --model_name=facebook/bart-large-cnn --num_train_epochs=10 --output_dir=./lora_bart_subtopics_sweep --r=64 --target_modules=q_proj,v_proj --warmup_steps=100
2025-02-13 06:34:41 INFO Running runs: ['iab0a0sm']
2025-02-13 06:47:56 INFO Cleaning up finished run: vgqse8m5
2025-02-13 06:47:57 INFO Agent received command: run
2025-02-13 06:47:57 INFO Agent starting run with config:
	alpha_multiplier: 2
	data_file: /n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv
	dropout: 0.7174308667815964
	learning_rate: 7.590109850621965e-05
	length_penalty: 0.3604227230724055
	model_name: facebook/bart-large-cnn
	num_train_epochs: 8
	output_dir: ./lora_bart_subtopics_sweep
	r: 16
	target_modules: q_proj,v_proj,k_proj,out_proj
	warmup_steps: 100
2025-02-13 06:47:57 INFO About to run command: /usr/bin/env python sweep_bart.py --alpha_multiplier=2 --data_file=/n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv --dropout=0.7174308667815964 --learning_rate=7.590109850621965e-05 --length_penalty=0.3604227230724055 --model_name=facebook/bart-large-cnn --num_train_epochs=8 --output_dir=./lora_bart_subtopics_sweep --r=16 --target_modules=q_proj,v_proj,k_proj,out_proj --warmup_steps=100
2025-02-13 06:48:02 INFO Running runs: ['8gl4pi9k']
2025-02-13 06:56:54 INFO Cleaning up finished run: iab0a0sm
2025-02-13 06:56:54 INFO Agent received command: run
2025-02-13 06:56:54 INFO Agent starting run with config:
	alpha_multiplier: 2
	data_file: /n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv
	dropout: 0.7532114914827235
	learning_rate: 5.736568488878264e-05
	length_penalty: 2.201356989510149
	model_name: facebook/bart-large-cnn
	num_train_epochs: 5
	output_dir: ./lora_bart_subtopics_sweep
	r: 8
	target_modules: q_proj,v_proj
	warmup_steps: 500
2025-02-13 06:56:54 INFO About to run command: /usr/bin/env python sweep_bart.py --alpha_multiplier=2 --data_file=/n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv --dropout=0.7532114914827235 --learning_rate=5.736568488878264e-05 --length_penalty=2.201356989510149 --model_name=facebook/bart-large-cnn --num_train_epochs=5 --output_dir=./lora_bart_subtopics_sweep --r=8 --target_modules=q_proj,v_proj --warmup_steps=500
2025-02-13 06:56:59 INFO Running runs: ['hr5tg1zd']
2025-02-13 07:08:54 INFO Cleaning up finished run: hr5tg1zd
2025-02-13 07:08:54 INFO Agent received command: run
2025-02-13 07:08:54 INFO Agent starting run with config:
	alpha_multiplier: 1
	data_file: /n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv
	dropout: 0.6958789375070039
	learning_rate: 8.597198746473993e-05
	length_penalty: 5.961473075972512
	model_name: facebook/bart-large-cnn
	num_train_epochs: 6
	output_dir: ./lora_bart_subtopics_sweep
	r: 64
	target_modules: q_proj,v_proj,k_proj
	warmup_steps: 1000
2025-02-13 07:08:54 INFO About to run command: /usr/bin/env python sweep_bart.py --alpha_multiplier=1 --data_file=/n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv --dropout=0.6958789375070039 --learning_rate=8.597198746473993e-05 --length_penalty=5.961473075972512 --model_name=facebook/bart-large-cnn --num_train_epochs=6 --output_dir=./lora_bart_subtopics_sweep --r=64 --target_modules=q_proj,v_proj,k_proj --warmup_steps=1000
2025-02-13 07:08:59 INFO Running runs: ['5brgo5oc']
2025-02-13 07:09:15 INFO Cleaning up finished run: 8gl4pi9k
2025-02-13 07:09:16 INFO Agent received command: run
2025-02-13 07:09:16 INFO Agent starting run with config:
	alpha_multiplier: 1
	data_file: /n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv
	dropout: 0.7819703825962736
	learning_rate: 4.4276454316241915e-05
	length_penalty: 4.059275633782669
	model_name: facebook/bart-large-cnn
	num_train_epochs: 4
	output_dir: ./lora_bart_subtopics_sweep
	r: 128
	target_modules: q_proj,v_proj,k_proj
	warmup_steps: 1000
2025-02-13 07:09:16 INFO About to run command: /usr/bin/env python sweep_bart.py --alpha_multiplier=1 --data_file=/n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv --dropout=0.7819703825962736 --learning_rate=4.4276454316241915e-05 --length_penalty=4.059275633782669 --model_name=facebook/bart-large-cnn --num_train_epochs=4 --output_dir=./lora_bart_subtopics_sweep --r=128 --target_modules=q_proj,v_proj,k_proj --warmup_steps=1000
2025-02-13 07:09:21 INFO Running runs: ['lxj4zhlw']
2025-02-13 07:22:32 INFO Cleaning up finished run: lxj4zhlw
2025-02-13 07:22:32 INFO Agent received command: run
2025-02-13 07:22:32 INFO Agent starting run with config:
	alpha_multiplier: 2
	data_file: /n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv
	dropout: 0.14925914630391332
	learning_rate: 5.3965332172428184e-05
	length_penalty: 3.974105599723754
	model_name: facebook/bart-large-cnn
	num_train_epochs: 3
	output_dir: ./lora_bart_subtopics_sweep
	r: 128
	target_modules: q_proj,v_proj
	warmup_steps: 500
2025-02-13 07:22:32 INFO About to run command: /usr/bin/env python sweep_bart.py --alpha_multiplier=2 --data_file=/n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv --dropout=0.14925914630391332 --learning_rate=5.3965332172428184e-05 --length_penalty=3.974105599723754 --model_name=facebook/bart-large-cnn --num_train_epochs=3 --output_dir=./lora_bart_subtopics_sweep --r=128 --target_modules=q_proj,v_proj --warmup_steps=500
2025-02-13 07:22:37 INFO Running runs: ['ydw8e17z']
2025-02-13 07:26:23 INFO Cleaning up finished run: 5brgo5oc
2025-02-13 07:26:24 INFO Agent received command: run
2025-02-13 07:26:24 INFO Agent starting run with config:
	alpha_multiplier: 1
	data_file: /n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv
	dropout: 0.5429743216910646
	learning_rate: 3.10440378720692e-05
	length_penalty: 0.4209538940797386
	model_name: facebook/bart-large-cnn
	num_train_epochs: 2
	output_dir: ./lora_bart_subtopics_sweep
	r: 32
	target_modules: q_proj,v_proj,k_proj,out_proj
	warmup_steps: 1000
2025-02-13 07:26:24 INFO About to run command: /usr/bin/env python sweep_bart.py --alpha_multiplier=1 --data_file=/n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv --dropout=0.5429743216910646 --learning_rate=3.10440378720692e-05 --length_penalty=0.4209538940797386 --model_name=facebook/bart-large-cnn --num_train_epochs=2 --output_dir=./lora_bart_subtopics_sweep --r=32 --target_modules=q_proj,v_proj,k_proj,out_proj --warmup_steps=1000
2025-02-13 07:26:29 INFO Running runs: ['yilzqu31']
2025-02-13 07:31:44 INFO Cleaning up finished run: ydw8e17z
2025-02-13 07:31:45 INFO Agent received command: run
2025-02-13 07:31:45 INFO Agent starting run with config:
	alpha_multiplier: 1
	data_file: /n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv
	dropout: 0.594227657604751
	learning_rate: 3.863431211009056e-05
	length_penalty: 3.031027994231088
	model_name: facebook/bart-large-cnn
	num_train_epochs: 9
	output_dir: ./lora_bart_subtopics_sweep
	r: 128
	target_modules: q_proj,v_proj,k_proj,out_proj
	warmup_steps: 500
2025-02-13 07:31:45 INFO About to run command: /usr/bin/env python sweep_bart.py --alpha_multiplier=1 --data_file=/n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv --dropout=0.594227657604751 --learning_rate=3.863431211009056e-05 --length_penalty=3.031027994231088 --model_name=facebook/bart-large-cnn --num_train_epochs=9 --output_dir=./lora_bart_subtopics_sweep --r=128 --target_modules=q_proj,v_proj,k_proj,out_proj --warmup_steps=500
2025-02-13 07:31:50 INFO Running runs: ['fy18us7v']
2025-02-13 07:33:34 INFO Cleaning up finished run: yilzqu31
2025-02-13 07:33:35 INFO Agent received command: run
2025-02-13 07:33:35 INFO Agent starting run with config:
	alpha_multiplier: 1
	data_file: /n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv
	dropout: 0.1126329791594075
	learning_rate: 4.560091946245605e-05
	length_penalty: 4.633967879912473
	model_name: facebook/bart-large-cnn
	num_train_epochs: 4
	output_dir: ./lora_bart_subtopics_sweep
	r: 8
	target_modules: q_proj,v_proj,k_proj,out_proj,fc1,fc2
	warmup_steps: 750
2025-02-13 07:33:35 INFO About to run command: /usr/bin/env python sweep_bart.py --alpha_multiplier=1 --data_file=/n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv --dropout=0.1126329791594075 --learning_rate=4.560091946245605e-05 --length_penalty=4.633967879912473 --model_name=facebook/bart-large-cnn --num_train_epochs=4 --output_dir=./lora_bart_subtopics_sweep --r=8 --target_modules=q_proj,v_proj,k_proj,out_proj,fc1,fc2 --warmup_steps=750
2025-02-13 07:33:40 INFO Running runs: ['vprac1uk']
