2025-02-11 13:12:07,415 - WARNING - Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
2025-02-11 13:12:07,418 - INFO - Device: cuda:0
2025-02-11 13:12:07,767 - INFO - Device: cuda:1
2025-02-11 13:12:07,846 - INFO - Dataset split: 2753 training samples, 689 validation samples.
2025-02-11 13:12:07,993 - INFO - Load pretrained SentenceTransformer: /n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/models
2025-02-11 13:12:08,041 - INFO - Dataset split: 2753 training samples, 689 validation samples.
2025-02-11 13:12:08,190 - INFO - Load pretrained SentenceTransformer: /n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/models
2025-02-11 13:13:27,393 - INFO - [MEMORY] After graph construction: Memory Used: 32.75 GB; [GPU 0] Allocated: 29981.80 MB, Reserved: 35208.00 MB
2025-02-11 13:13:44,722 - INFO - [MEMORY] After model loading: Memory Used: 33.02 GB; [GPU 0] Allocated: 38729.22 MB, Reserved: 38808.00 MB
2025-02-11 13:13:53,043 - INFO - 
[INFO] Starting Epoch 1
2025-02-11 13:13:53,043 - INFO - 
[INFO] Starting Epoch 1
2025-02-11 13:23:26,751 - INFO - Epoch 1: Average Training Loss = 5.7312
2025-02-11 13:23:49,076 - INFO - ------------------------
----- TRAIN EPOCH 1 -----
Train Target Phrase Tokens: tensor([   1, 6765, 4908, 4920,    2,    2], device='cuda:0')
Train Target Phrase: border security policy
Generated Phrase: vehicle economic finance abortion safety government government government government government government diplom9 creditsdown n immigration cuts immigrationies account medicalendmentdownreachzte shut mental cuts military sanctipart response subs supported
Train Loss: 2.0857999324798584
Train Sim Loss: 1.0281659364700317
Train Gen Loss: 2.0857999324798584
Generated Tokens: tensor([[    1,     1,     1,     1,     1,  8114,  6638, 15978, 22907,  6661,
          3058,  3058,  3058,  3058,  3058,  3058, 13527, 28774, 21762,  3254,
           307, 21715, 15981, 21715,   497,  2708,  5714, 18920,  3254, 18932,
         14798,  6409,  8057, 15981,  5469, 24309, 26653,  2899, 11994,  6615],
        [    1,     1,     1,     1,  2784,   960,  8995, 23755,  9278, 18321,
          1760,  1760,  1760, 13942,  2058, 12779, 10582, 12745,   380,  3905,
         21607,  8432,  2235, 24843, 24024,  5088,  3082,   837,  3564, 11092,
          8317,  3905, 27243, 17826, 17575,  1862,  7876, 21419,   287,  4779],
        [    1,     1,     1,     1,     1,   356,  8114,   288, 10582,  3254,
           697, 21349, 22815,   492, 28479,  1665,   308,  3947,  4986, 28713,
         28713,  1829,  8432, 10318, 15788, 17035,  2007,  2708,  1089,  1760,
          1760,   521, 28713, 28713, 28713, 28713,   875,  2708,  4920,  4920],
        [    1,     1,     1,     1,  2389, 14478,   960,  2372, 15882, 11843,
           798,   798,  1760,  1760,  1760, 17035,   313,  4340,  1382,  1342,
          7151, 17548, 16451,  4875,  5362, 11843, 16055,   454, 27950,  1705,
          1339,  7709,  4908,  8057, 10948, 20447,   332,  8147,  1002, 21250],
        [    1,     1,     1,     1,  8825, 14218, 14218, 14218, 14218, 14218,
         14218, 14218,   298, 28041,   875, 21523,  2426,  3058,  3058,  3058,
         10953,  6424, 13053,  2899, 16214,  7778,  9615, 16609, 26084,  9890,
          7782,  8271, 28727, 20533, 28723,  8147, 24843,  1760,  4337,   297],
        [    1,     1,     1,  2235, 20288,  1370,  1308, 22851,  6666,  8812,
          1558,  9915, 26843, 19410,  3914, 22907, 15885,   294,   282,  3058,
          3058, 12106,  1760,  7876,  2708,  8114,  7511, 10864,  1760,   837,
         22907, 16128, 10864,   312, 13654,  7645,  2437,  8657, 15240,  1760],
        [    1,     1,     1, 28330, 17273,  3335,   313,  8147,  8147, 10074,
          8147,  3332,  6730, 25797,  2405, 24277,  8147,  9606,  8147,  3254,
          7694, 14071, 13775,   454,  4986,   805,   520,  7034,   454,   282,
           281,  5088,  1479,   302,  8808,  4908,  4875,  4139,  1303, 10582],
        [    1,     1,     1,     1,  2045,   360, 28231, 12131, 12131, 12131,
         12131, 12131, 12131, 12131,   358,  1759, 12436,  2196, 12923, 28740,
          5411,  1342, 25741, 12106,  6765,  6765,  4007,  3254,  1220,  2007,
          6765, 16497,  1759, 17273,  3153,  5573, 15885,  1877,  5469, 15240]],
       device='cuda:0')
Total gradient norm: 6.9557
------------------------
2025-02-11 13:23:49,077 - INFO - [MEMORY] After epoch 1: Memory Used: 36.71 GB; [GPU 0] Allocated: 61465.32 MB, Reserved: 66450.00 MB
2025-02-11 13:23:49,077 - INFO - Epoch 1: Average Training Loss = 5.7332
2025-02-11 13:28:17,423 - INFO - Epoch 1: Average Validation Loss = 2.5257
2025-02-11 13:29:03,791 - INFO - ------------------------
----- VALIDATION EPOCH 1 -----
Validation Target Phrase Tokens: tensor([    1,   285,  8282,  3051,  1097, 15885], device='cuda:0')
Validation Target Phrase: ftc merger regulations
Generated Phrase: seasons investigation reduction localnosti impact impact athlet regulation regulation regulation regulation regulation regulation regulation regulation regulation regulationemsighting programs businessayer f emissions concernsicaprevent billonel concernsare public concerns
Validation Loss: 1.4424962997436523
Validation Sim Loss: 1.0196051597595215
Validation Gen Loss: 1.4424962997436523
Validation Generated Tokens: tensor([[    1,     1,     1,     1,     1, 15238, 11597, 13388,  1862, 21805,
          5088,  5088, 14587, 22470, 22470, 22470, 22470, 22470, 22470, 22470,
         22470, 22470, 22470,  7940,   454,   288,  7034,  1955,  2386,   285,
         25111, 10864,  1286, 21129,  4875, 12006, 10864,   492,   798, 10864],
        [    1,     1,     1,     1,  1308,  9680,  1759, 28723, 28723, 28723,
         28723,   312,   313,   313,   313, 16055,  9861,  9861,  9861,  9861,
          9861,  9861,  1203,   408, 15240,  9637, 19046, 15219,   288, 28733,
         22907, 18371,  2528,  4495,  4495,  2036, 10582,  9861,  2369, 28733],
        [    1,     1,     1,     1,     1,   798,   798,   798,  2528, 12025,
          6661,  6661,  6661, 20288, 10165,  5362,  8465,  5712,  1063,  6661,
          8943,  6661,  6582,  6409,  4382,  4382,  4382,  4382,  4382,  4382,
          4382,  4382, 28723, 20135, 10864,  7101, 14513, 27613,  4382,  4262],
        [    1,     1,     1,     1, 19046,  1002,  4139, 10864, 10864, 10864,
         10864, 10864, 10864, 11881, 10864,   798, 28705,  4908,  2130,  2007,
          6966, 22470, 22470, 28740, 23767,  2764,  5267,   313,  2899, 28231,
         15801,   287,  5815,  4920, 11611, 22470, 14218, 28733,   354,   354],
        [    1,     1,     1,     1,     1, 10651,   309, 21593, 25426,  8326,
         24935,  1002,  8432,   521,  1002, 11344,  9680, 15885, 28774,  3227,
          4908,  4908,  4908,  4908,  4908,  4908,  8147, 21715,   313,  3058,
          9981,   305,   691, 17273,  4920,  4920,  4920,  4920,  4920, 28714],
        [    1,     1,     1,     1,     1,  6253, 16055, 16055, 16055,  4920,
          4920,  4920,  4920,  4920,  4920,  4920,  4920,   492,   308,  2899,
         15885,  5408, 10879,  5408,  1656,   312,   380, 10864, 10864, 10864,
         10864, 10864, 28733,  9981,   307, 28774, 17940, 16402, 15981,  1820],
        [    1,     1,     1,     1,     1,  3014, 19270,  4908,  4908,  4908,
          4908,  4908,  4908,  4908,  4908,  5679,  2899,  6812,   285,  3058,
           381, 15349, 18164,   353, 23767,  4875,  5362,  7034, 12826,   313,
           354,   837,  1308,  4885, 24880, 24146, 21066, 28723, 28723, 28723],
        [    1,     1,     1,     1, 28186,  6259,  2764, 15885, 15885,  5593,
          1605,  8462, 28712,  7380,   798,   285,   281,  1286, 15276,  2528,
         28723,  1871, 17463, 12985,  9861,  9861,  9861,  9861,  2528,  3058,
           697,  2708, 28716,   380,  9861,  9861,  9861,  9861,  9861,  9968]],
       device='cuda:0')
------------------------
2025-02-11 13:29:03,792 - INFO - [MEMORY] After epoch 1: Memory Used: 37.60 GB; [GPU 0] Allocated: 61465.40 MB, Reserved: 66216.00 MB
2025-02-11 13:29:03,792 - INFO - Epoch 1: Average Validation Loss = 2.3948
2025-02-11 13:29:07,889 - INFO - 
[INFO] Starting Epoch 2
2025-02-11 13:29:07,889 - INFO - 
[INFO] Starting Epoch 2
2025-02-11 13:30:40,633 - INFO - Epoch 2: Average Training Loss = 4.4931
2025-02-11 13:31:02,343 - INFO - ------------------------
----- TRAIN EPOCH 2 -----
Train Target Phrase Tokens: tensor([    1, 17035,  9549,     2,     2,     2,     2,     2],
       device='cuda:0')
Train Target Phrase: voting decisions
Generated Phrase: bund algo attacked ironinedpk numericalindentlive dx cer describesanje alternateitary facachersawaitgoruso timestampscriptsrf smoothiani anything logo gioctera mergeddrivenuggest highestsafe pull functions bal bras rules
Train Loss: 11.469958305358887
Train Sim Loss: 1.0227432250976562
Train Gen Loss: 11.469958305358887
Generated Tokens: tensor([[    1, 22978, 25682, 15198,  8075,  1311, 16270, 18125, 10388, 17064,
         18733,  6942, 13966, 27858, 24597, 11969,  3252, 26120, 13513,  4553,
         14103, 18207, 23931, 12624,  7898, 17151,  2424, 16388, 27491, 20328,
         22750, 27369, 16939,  7881,  7248,  3300,  5572,  4549, 20493,  5879],
        [    1, 21854,  3952,    56,   821, 22320, 23589, 14324, 28639, 21406,
         10060,  5718, 19088, 17959, 28340,  4996, 19871, 19203,  2831, 13298,
          6129,   590, 19900, 24100, 14729,  1723, 17468,  6828,  9064, 15379,
         13648,   921,  4563,  5544, 19687,  8558,  9752, 18560,  9015, 17978],
        [    1, 11323, 25341, 28677, 16297, 10200,  7515,  7802, 13150, 20621,
          1842, 19436, 17930, 20707,  2224, 14446,   751, 16931, 25499,  2134,
         26688, 27427, 13447,  9921, 28349,  3936, 19201, 10765, 19424, 19626,
           115, 24654, 21294,  9469, 17474, 13395, 12622, 13284, 24056,  1942],
        [    1, 25004, 27242, 22651, 15387, 11076, 13002, 16971,  6206, 14737,
         19706, 19781, 12570, 13443,  9198,  9136, 19347, 12134,   792, 20742,
         19256,  6134,  8790, 18167, 11264, 28285, 25000, 14045, 22292, 15249,
         19252, 21557,  2662, 25242, 18782,  5231, 21413, 18532,  5011, 11451],
        [    1,  4584, 14062,  4509,  7680,  1362, 10303, 12244, 13739, 10323,
          7381, 21649,  1898, 13913,  5513, 26404, 21892,  5397, 10844,  2669,
         12079, 20727, 23735,  2478,  1579, 24370,  2514,  7938, 14196, 11271,
         27801,  2376, 13350, 19680, 21171, 27666,  4814,  5749,  4755, 20767],
        [    1, 13952, 20813,  3365, 27949,  2510, 16626,  5635,  7285, 26355,
         18731, 22999, 14796,  1048, 22426, 15262,  9095, 16584, 26312, 18689,
          4289,  7140, 15019, 22347, 24726,  2939,  5055, 31145,  6992,  7938,
          4061, 19246, 12317,  5224, 11533, 12735,  9504, 10863, 27053, 27769],
        [    1, 13785,  2521, 15387, 19396, 20626, 27356,  3925, 22880,  9892,
          2033, 10586,  7349, 24983, 18785, 13160, 13398, 27139,  3292,  6062,
           907, 21876, 17418,  6615, 10599, 17045, 13175,  2243, 26970, 21635,
          6212, 23592,  2020, 28154,  8584,  4808, 24535, 15852, 13296, 10311],
        [    1,   835, 11303,  4418,  7691, 20968,   598,  1150, 12039, 20747,
          1732,  1428, 13327, 26682, 15094, 21426, 28061, 26133, 17014, 20212,
         26181, 23608,  1460, 24589,  9255,  1465, 10837, 27400, 10727, 13074,
          9338, 28698,  8005, 19931, 18894, 14817, 11046,  4879,  5767, 15832]],
       device='cuda:0')
Total gradient norm: 10.0000
------------------------
2025-02-11 13:31:02,344 - INFO - [MEMORY] After epoch 2: Memory Used: 37.71 GB; [GPU 0] Allocated: 61467.28 MB, Reserved: 66410.00 MB
2025-02-11 13:31:02,344 - INFO - Epoch 2: Average Training Loss = 4.4736
