#!/usr/bin/env python
"""
Merge Taxonomy

This script post-processes the generated taxonomies by merging them with the original training data.
It processes three different taxonomy files (standard, HLDA, and BERTopic) and creates datasets
with appropriate target labels for downstream tasks.

The script:
1. Loads each taxonomy file (step_4.csv, hlda_taxonomy.csv, bertopic_taxonomy.csv)
2. Creates mappings from document indices to taxonomy information
3. Merges these mappings with the original training data
4. Determines appropriate target labels based on taxonomy structure
5. Outputs the merged datasets with target labels

Input:
- step_4.csv: Standard taxonomy generated by clustering_2.py
- hlda_taxonomy.csv: Alternative taxonomy generated by hlda.py
- bertopic_taxonomy.csv: Alternative taxonomy generated by bertopic_trial.py
- step_1.csv: Original training data

Output:
- taxonomy_data.csv: Merged dataset with standard taxonomy
- taxonomy_data_hlda.csv: Merged dataset with HLDA taxonomy
- taxonomy_data_bertopic.csv: Merged dataset with BERTopic taxonomy
"""

import pandas as pd

def process_taxonomy(file, suffix):
    """
    Process a taxonomy file and merge it with the original training data.
    
    Args:
        file (str): Path to the taxonomy file
        suffix (str): Suffix to add to the output file name
        
    Returns:
        None, but writes the merged dataset to CSV files
    """
    print(f"Processing {file}...")
    
    # Read the taxonomy data
    taxonomy_df = pd.read_csv(file)

    # Read the training data
    print("Loading original training data...")
    training_df = pd.read_csv('step_1.csv')

    # Create a mapping dictionary from source_indices to taxonomy information
    print("Creating taxonomy mapping...")
    taxonomy_mapping = {}
    for _, row in taxonomy_df.iterrows():
        indices = [int(i.strip()) for i in row['source_indices'].split(';')]
        for index in indices:
            taxonomy_mapping[index] = {
                'matching_idx': index,
                'policy_area': row['policy_area'],
                'subtopic_1': row['subtopic_1'],
                'subtopic_2': row['subtopic_2']
            }

    # Merge taxonomy_mapping dict into training_df on idx key
    print("Merging taxonomy with training data...")
    final_df = training_df.merge(
        pd.DataFrame.from_dict(taxonomy_mapping, orient='index'),
        left_on=['matching_idx', 'policy_area'],
        right_on=['matching_idx', 'policy_area'],
        how='left'
    )

    # Define target column logic - use the most specific non-Misc subtopic
    def determine_target(row):
        """
        Determine the target label based on taxonomy hierarchy.
        Uses the most specific non-Misc subtopic available.
        
        Args:
            row (pandas.Series): A row from the merged dataframe
            
        Returns:
            str: The selected target label
        """
        if row['subtopic_2'] and row['subtopic_2'] != 'Misc.':
            return row['subtopic_2']
        # Commented out to match original logic
        # elif row['subtopic_1'] != 'Misc.':
        #     return row['subtopic_1']
        return ""

    final_df['target'] = final_df.apply(determine_target, axis=1)

    # Sort final_df by index for consistency
    final_df = final_df.sort_values(by='matching_idx')

    # Save the merged dataset to both locations (local and lab directory)
    output_path = f'taxonomy_data{suffix}.csv'
    lab_output_path = f'/n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/taxonomy_data{suffix}.csv'
    
    final_df.to_csv(lab_output_path, index=False)
    final_df.to_csv(output_path, index=False)
    print(f"Merged dataset saved to {output_path} and {lab_output_path}")

def main():
    """
    Main function to process all taxonomy files.
    """
    taxonomy_files = [
        ('step_4.csv', ''),               # Standard taxonomy
        ('hlda_taxonomy.csv', '_hlda'),   # HLDA taxonomy
        ('bertopic_taxonomy.csv', '_bertopic')  # BERTopic taxonomy
    ]
    
    for file, suffix in taxonomy_files:
        process_taxonomy(file, suffix)
        print(f"Completed processing {file}\n")
    
    print("All taxonomy files processed successfully!")

if __name__ == "__main__":
    main()
