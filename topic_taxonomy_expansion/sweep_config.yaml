program: sweep_bart.py
method: bayes
metric:
  name: final_eval.eval_loss
  goal: minimize
parameters:
  r:
    distribution: categorical
    values: [8, 16, 32, 64, 128]
  alpha_multiplier:
    distribution: categorical
    values: [1, 2]
  target_modules:
    distribution: categorical
    values: ["q_proj,v_proj", "q_proj,v_proj,k_proj", "q_proj,v_proj,k_proj,out_proj", "q_proj,v_proj,k_proj,out_proj,fc1,fc2"]
  learning_rate:
    distribution: uniform
    min: 1e-6
    max: 1e-4
  num_train_epochs:
    distribution: int_uniform
    min: 1
    max: 10
  warmup_steps:
    distribution: categorical
    values: [0, 100, 250, 500, 750, 1000]
  length_penalty:
    distribution: uniform
    min: 0.0
    max: 10.0
  dropout:
    distribution: uniform
    min: 0.0
    max: 0.8
  data_file:
    value: "/n/holylabs/LABS/arielpro_lab/Lab/michaelzhao/new_training_data.csv"
  model_name:
    value: "facebook/bart-large-cnn"
  output_dir:
    value: "./lora_bart_subtopics_sweep"
