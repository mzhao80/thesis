#!/usr/bin/env python
"""
Taxonomy Visualization

This script creates hierarchical visualizations of the generated taxonomies using Graphviz.
It generates three separate visualizations for different taxonomy approaches:
1. Standard taxonomy (from step_4.csv)
2. HLDA taxonomy (from hlda_taxonomy.csv)
3. BERTopic taxonomy (from bertopic_taxonomy.csv)

Each visualization shows the hierarchy of topics and subtopics, along with statistics about
the number of documents in each node and the percentage of the total corpus they represent.

Input:
- step_4.csv: Standard taxonomy generated by clustering_2.py
- hlda_taxonomy.csv: Alternative taxonomy generated by hlda.py
- bertopic_taxonomy.csv: Alternative taxonomy generated by bertopic_trial.py

Output:
- taxonomy_tree.pdf: Visualization of the standard taxonomy
- taxonomy_tree_hlda.pdf: Visualization of the HLDA taxonomy
- taxonomy_tree_bertopic.pdf: Visualization of the BERTopic taxonomy
"""

import pandas as pd
from graphviz import Digraph

def visualize_taxonomy(df_path, output_name):
    """
    Creates a hierarchical visualization of a taxonomy.
    
    Args:
        df_path (str): Path to the CSV file containing the taxonomy
        output_name (str): Name for the output visualization file (without extension)
        
    Returns:
        None, but saves a PDF visualization
    """
    print(f"Visualizing taxonomy from {df_path}...")
    df = pd.read_csv(df_path)
    
    # Create a new directed graph
    dot = Digraph(comment="Taxonomy Tree", format="pdf")

    # Set resolution parameters based on which tree we're generating
    if "hlda" in df_path or "bertopic" in df_path:
        # Higher resolution and larger size for the more complex trees
        dot.attr(rankdir="LR", dpi="1200", size="60,50")
        dot.graph_attr.update(ratio='expand')
        # Additional parameters that might help with readability
        dot.graph_attr.update(nodesep='0.5', ranksep='2.0')
        
        # Node styling for better readability in complex trees
        dot.node_attr.update(fontsize='14', width='0.6', height='0.4', margin='0.1')
        dot.edge_attr.update(penwidth='0.8')
    else:
        # Standard settings for the simpler tree (step_4)
        dot.attr(rankdir="LR", dpi="900", size="50,40")
        dot.graph_attr.update(ratio='expand')

    # Dictionaries to store unique nodes and their counts
    policy_nodes = {}       # Maps policy area to node ID
    subtopic1_nodes = {}    # Maps (policy_area, subtopic_1) to node ID
    subtopic2_nodes = {}    # Maps (policy_area, subtopic_1, subtopic_2) to node ID
    
    # Dictionaries to store document counts
    policy_counts = {}      # Maps policy area to document count
    subtopic1_counts = {}   # Maps (policy_area, subtopic_1) to document count
    subtopic2_counts = {}   # Maps (policy_area, subtopic_1, subtopic_2) to document count
    
    # Node counter
    i = 0
    j = 0
    
    # Store length information for percentage calculations
    lengths = {}

    # First pass: Calculate all counts
    print("Calculating document counts...")
    for _, row in df.iterrows():
        policy_area = row["policy_area"]
        subtopic_1 = row["subtopic_1"]
        subtopic_2 = row["subtopic_2"]
        cluster_length = row["cluster_length"]
        
        # Update policy area counts
        policy_counts[policy_area] = policy_counts.get(policy_area, 0) + cluster_length
        
        # Update subtopic1 counts
        key_subtopic1 = (policy_area, subtopic_1)
        subtopic1_counts[key_subtopic1] = subtopic1_counts.get(key_subtopic1, 0) + cluster_length
        
        # Update subtopic2 counts if not Misc.
        if subtopic_1 != "Misc.":
            key_subtopic2 = (policy_area, subtopic_1, subtopic_2)
            subtopic2_counts[key_subtopic2] = subtopic2_counts.get(key_subtopic2, 0) + cluster_length

    # Sort policies by count (descending)
    sorted_policies = sorted(policy_counts.items(), key=lambda x: x[1], reverse=True)

    # Create nodes in sorted order (most common first)
    print("Creating visualization nodes...")
    for policy_area, count in sorted_policies:
        policy_node_id = f"policy_{len(policy_nodes)}"
        policy_nodes[policy_area] = policy_node_id
        lengths[policy_area] = count
        # Add node with percentage info
        dot.node(policy_node_id, policy_area + f" ({count}, {count*100/df['cluster_length'].sum():.2f}%)")
        
        # Sort subtopic1 nodes for this policy
        subtopic1_for_policy = [(key, count) for key, count in subtopic1_counts.items() if key[0] == policy_area]
        sorted_subtopic1 = sorted(subtopic1_for_policy, key=lambda x: x[1], reverse=True)
        
        for (_, subtopic_1), subtopic1_count in sorted_subtopic1:
            key_subtopic1 = (policy_area, subtopic_1)
            subtopic1_node_id = f"subtopic1_{j}"
            j += 1
            subtopic1_nodes[key_subtopic1] = subtopic1_node_id
            lengths[key_subtopic1] = subtopic1_count
            # Add node with percentage info (percent of parent)
            dot.node(subtopic1_node_id, str(subtopic_1) + f" ({subtopic1_count}, {subtopic1_count*100/lengths[policy_area]:.2f}%)")
            dot.edge(policy_node_id, subtopic1_node_id)
            
            if subtopic_1 != "Misc.":
                # Sort subtopic2 nodes for this subtopic1
                subtopic2_for_subtopic1 = [(key, count) for key, count in subtopic2_counts.items() 
                                        if key[0] == policy_area and key[1] == subtopic_1]
                sorted_subtopic2 = sorted(subtopic2_for_subtopic1, key=lambda x: x[1], reverse=True)
                
                for (_, _, subtopic_2), subtopic2_count in sorted_subtopic2:
                    key_subtopic2 = (policy_area, subtopic_1, subtopic_2)
                    subtopic2_node_id = f"subtopic2_{j}"
                    j += 1
                    subtopic2_nodes[key_subtopic2] = subtopic2_node_id
                    lengths[key_subtopic2] = subtopic2_count
                    # Add node with percentage info (percent of parent)
                    dot.node(subtopic2_node_id, subtopic_2 + f" ({subtopic2_count}, {subtopic2_count*100/lengths[key_subtopic1]:.2f}%)")
                    dot.edge(subtopic1_node_id, subtopic2_node_id)

    # Create the root node and connect to all policy areas
    parent_node = dot.node("parent", "Parent Node" + f" ({df['cluster_length'].sum()}, 100%)")
    for policy_area, _ in sorted_policies:
        dot.edge("parent", policy_nodes[policy_area])

    # Render and save the visualization
    print(f"Saving visualization to {output_name}.pdf...")
    dot.render(output_name, view=False)
    print(f"Visualization complete: {output_name}.pdf")

def main():
    """
    Main function to visualize all three taxonomies.
    """
    # Source files and output names
    taxonomy_files = [
        ("hlda_taxonomy.csv", "taxonomy_tree_hlda"),
        ("bertopic_taxonomy.csv", "taxonomy_tree_bertopic"),
        ("step_4.csv", "taxonomy_tree")
    ]
    
    for df_path, output in taxonomy_files:
        visualize_taxonomy(df_path, output)
    
    print("All visualizations completed!")

if __name__ == "__main__":
    main()
