Create sweep with ID: qlqcrkng
Sweep URL: https://wandb.ai/michaelzhao-harvard-university/wiki-larger-new/sweeps/qlqcrkng
Starting training with config: {'batch_size': 16, 'epochs': 50, 'l2_reg': 1.2373655300660294e-05, 'lr': 7.456143256565723e-06, 'n_layers_freeze': 2, 'patience': 15}
Let's use 1 GPUs!
Preparing data....
Training data....
# of train examples: 13477
max len: 512, max len wiki: 1
Val data....
# of val examples: 2062
max len: 512, max len wiki: 1
Test data....
# of test examples: 3006
max len: 512, max len wiki: 1
Done

Initializing model....
******************************Epoch: 1******************************
Batch: 1/843	Loss:1.114
Batch: 85/843	Loss:1.168
Batch: 169/843	Loss:1.252
Batch: 253/843	Loss:1.016
Batch: 337/843	Loss:0.986
Batch: 421/843	Loss:0.780
Batch: 505/843	Loss:0.722
Batch: 589/843	Loss:0.583
Batch: 673/843	Loss:0.726
Batch: 757/843	Loss:0.651
Batch: 841/843	Loss:0.733
Batch: 843/843	Loss:0.772
Epoch: 1	Train Loss: 0.884	Val F1: 0.689
Best Epoch: 1	Best Epoch Val F1: 0.689

******************************Epoch: 2******************************
Batch: 1/843	Loss:0.799
Batch: 85/843	Loss:0.908
Batch: 169/843	Loss:0.813
Batch: 253/843	Loss:0.556
Batch: 337/843	Loss:0.842
Batch: 421/843	Loss:0.840
Batch: 505/843	Loss:0.685
Batch: 589/843	Loss:0.944
Batch: 673/843	Loss:0.697
Batch: 757/843	Loss:0.661
Batch: 841/843	Loss:0.691
Batch: 843/843	Loss:0.544
Epoch: 2	Train Loss: 0.636	Val F1: 0.674
Best Epoch: 1	Best Epoch Val F1: 0.689

******************************Epoch: 3******************************
Batch: 1/843	Loss:0.507
Batch: 85/843	Loss:0.573
Batch: 169/843	Loss:0.494
Batch: 253/843	Loss:0.414
Batch: 337/843	Loss:0.521
Batch: 421/843	Loss:0.676
Batch: 505/843	Loss:0.394
Batch: 589/843	Loss:0.647
Batch: 673/843	Loss:0.329
Batch: 757/843	Loss:0.725
Batch: 841/843	Loss:0.448
Batch: 843/843	Loss:0.144
Epoch: 3	Train Loss: 0.560	Val F1: 0.722
Best Epoch: 3	Best Epoch Val F1: 0.722

******************************Epoch: 4******************************
Batch: 1/843	Loss:0.377
Batch: 85/843	Loss:0.568
Batch: 169/843	Loss:0.548
Batch: 253/843	Loss:0.578
Batch: 337/843	Loss:0.324
Batch: 421/843	Loss:0.554
Batch: 505/843	Loss:0.483
Batch: 589/843	Loss:0.352
Batch: 673/843	Loss:0.549
Batch: 757/843	Loss:0.410
Batch: 841/843	Loss:0.242
Batch: 843/843	Loss:1.036
Epoch: 4	Train Loss: 0.487	Val F1: 0.684
Best Epoch: 3	Best Epoch Val F1: 0.722

******************************Epoch: 5******************************
Batch: 1/843	Loss:0.590
Batch: 85/843	Loss:0.413
Batch: 169/843	Loss:0.517
Batch: 253/843	Loss:0.220
Batch: 337/843	Loss:0.746
Batch: 421/843	Loss:0.510
Batch: 505/843	Loss:0.531
Batch: 589/843	Loss:0.407
Batch: 673/843	Loss:0.341
Batch: 757/843	Loss:0.389
Batch: 841/843	Loss:0.319
Batch: 843/843	Loss:0.640
Epoch: 5	Train Loss: 0.434	Val F1: 0.691
Best Epoch: 3	Best Epoch Val F1: 0.722

******************************Epoch: 6******************************
Batch: 1/843	Loss:0.259
Batch: 85/843	Loss:0.403
Batch: 169/843	Loss:0.386
Batch: 253/843	Loss:0.474
Batch: 337/843	Loss:0.476
Batch: 421/843	Loss:0.263
Batch: 505/843	Loss:0.336
Batch: 589/843	Loss:0.283
Batch: 673/843	Loss:0.379
Batch: 757/843	Loss:0.350
Batch: 841/843	Loss:0.425
Batch: 843/843	Loss:0.133
Epoch: 6	Train Loss: 0.401	Val F1: 0.716
Best Epoch: 3	Best Epoch Val F1: 0.722

******************************Epoch: 7******************************
Batch: 1/843	Loss:0.312
Batch: 85/843	Loss:0.163
Batch: 169/843	Loss:0.371
Batch: 253/843	Loss:0.227
Batch: 337/843	Loss:0.873
Batch: 421/843	Loss:0.152
Batch: 505/843	Loss:0.269
Batch: 589/843	Loss:0.202
Batch: 673/843	Loss:0.581
Batch: 757/843	Loss:0.416
Batch: 841/843	Loss:0.382
Batch: 843/843	Loss:0.200
Epoch: 7	Train Loss: 0.368	Val F1: 0.710
Best Epoch: 3	Best Epoch Val F1: 0.722

******************************Epoch: 8******************************
Batch: 1/843	Loss:0.257
Batch: 85/843	Loss:0.417
Batch: 169/843	Loss:0.102
Batch: 253/843	Loss:0.441
Batch: 337/843	Loss:0.274
Batch: 421/843	Loss:0.502
Batch: 505/843	Loss:0.435
Batch: 589/843	Loss:0.453
Batch: 673/843	Loss:0.203
Batch: 757/843	Loss:0.323
Batch: 841/843	Loss:0.301
Batch: 843/843	Loss:0.396
Epoch: 8	Train Loss: 0.332	Val F1: 0.676
Best Epoch: 3	Best Epoch Val F1: 0.722

******************************Epoch: 9******************************
Batch: 1/843	Loss:0.690
Batch: 85/843	Loss:0.211
Batch: 169/843	Loss:0.573
Batch: 253/843	Loss:0.385
Batch: 337/843	Loss:0.147
Batch: 421/843	Loss:0.339
Batch: 505/843	Loss:0.285
Batch: 589/843	Loss:0.366
Batch: 673/843	Loss:0.386
Batch: 757/843	Loss:0.136
Batch: 841/843	Loss:0.348
Batch: 843/843	Loss:0.213
Epoch: 9	Train Loss: 0.308	Val F1: 0.709
Best Epoch: 3	Best Epoch Val F1: 0.722

******************************Epoch: 10******************************
Batch: 1/843	Loss:0.486
Batch: 85/843	Loss:0.355
Batch: 169/843	Loss:0.365
Batch: 253/843	Loss:0.131
Batch: 337/843	Loss:0.144
Batch: 421/843	Loss:0.177
Batch: 505/843	Loss:0.383
Batch: 589/843	Loss:0.196
Batch: 673/843	Loss:0.059
Batch: 757/843	Loss:0.281
Batch: 841/843	Loss:0.068
Batch: 843/843	Loss:0.124
Epoch: 10	Train Loss: 0.285	Val F1: 0.713
Best Epoch: 3	Best Epoch Val F1: 0.722

******************************Epoch: 11******************************
Batch: 1/843	Loss:0.307
Batch: 85/843	Loss:0.519
Batch: 169/843	Loss:0.202
Batch: 253/843	Loss:0.222
Batch: 337/843	Loss:0.182
Batch: 421/843	Loss:0.261
Batch: 505/843	Loss:0.479
Batch: 589/843	Loss:0.079
Batch: 673/843	Loss:0.574
Batch: 757/843	Loss:0.149
Batch: 841/843	Loss:0.212
Batch: 843/843	Loss:0.065
Epoch: 11	Train Loss: 0.256	Val F1: 0.688
Best Epoch: 3	Best Epoch Val F1: 0.722

******************************Epoch: 12******************************
Batch: 1/843	Loss:0.246
Batch: 85/843	Loss:0.136
Batch: 169/843	Loss:0.380
Batch: 253/843	Loss:0.447
Batch: 337/843	Loss:0.096
Batch: 421/843	Loss:0.265
Batch: 505/843	Loss:0.140
Batch: 589/843	Loss:0.135
Batch: 673/843	Loss:0.118
Batch: 757/843	Loss:0.241
Batch: 841/843	Loss:0.111
Batch: 843/843	Loss:0.056
Epoch: 12	Train Loss: 0.241	Val F1: 0.704
Best Epoch: 3	Best Epoch Val F1: 0.722

******************************Epoch: 13******************************
Batch: 1/843	Loss:0.478
Batch: 85/843	Loss:0.225
Batch: 169/843	Loss:0.202
Batch: 253/843	Loss:0.115
Batch: 337/843	Loss:0.083
Batch: 421/843	Loss:0.108
Batch: 505/843	Loss:0.110
Batch: 589/843	Loss:0.288
Batch: 673/843	Loss:0.265
Batch: 757/843	Loss:0.363
Batch: 841/843	Loss:0.354
Batch: 843/843	Loss:0.104
Epoch: 13	Train Loss: 0.221	Val F1: 0.694
Best Epoch: 3	Best Epoch Val F1: 0.722

******************************Epoch: 14******************************
Batch: 1/843	Loss:0.378
Batch: 85/843	Loss:0.102
Batch: 169/843	Loss:0.157
Batch: 253/843	Loss:0.116
Batch: 337/843	Loss:0.279
Batch: 421/843	Loss:0.185
Batch: 505/843	Loss:0.118
Batch: 589/843	Loss:0.037
Batch: 673/843	Loss:0.204
Batch: 757/843	Loss:0.098
Batch: 841/843	Loss:0.554
Batch: 843/843	Loss:0.017
Epoch: 14	Train Loss: 0.202	Val F1: 0.710
Best Epoch: 3	Best Epoch Val F1: 0.722

******************************Epoch: 15******************************
Batch: 1/843	Loss:0.071
Batch: 85/843	Loss:0.120
Batch: 169/843	Loss:0.207
Batch: 253/843	Loss:0.184
Batch: 337/843	Loss:0.192
Batch: 421/843	Loss:0.064
Batch: 505/843	Loss:0.208
Batch: 589/843	Loss:0.071
Batch: 673/843	Loss:0.260
Batch: 757/843	Loss:0.256
Batch: 841/843	Loss:0.477
Batch: 843/843	Loss:0.011
Epoch: 15	Train Loss: 0.196	Val F1: 0.689
Best Epoch: 3	Best Epoch Val F1: 0.722

******************************Epoch: 16******************************
Batch: 1/843	Loss:0.241
Batch: 85/843	Loss:0.063
Batch: 169/843	Loss:0.222
Batch: 253/843	Loss:0.300
Batch: 337/843	Loss:0.401
Batch: 421/843	Loss:0.114
Batch: 505/843	Loss:0.033
Batch: 589/843	Loss:0.215
Batch: 673/843	Loss:0.076
Batch: 757/843	Loss:0.113
Batch: 841/843	Loss:0.207
Batch: 843/843	Loss:0.048
Epoch: 16	Train Loss: 0.181	Val F1: 0.706
Best Epoch: 3	Best Epoch Val F1: 0.722

******************************Epoch: 17******************************
Batch: 1/843	Loss:0.096
Batch: 85/843	Loss:0.251
Batch: 169/843	Loss:0.279
Batch: 253/843	Loss:0.094
Batch: 337/843	Loss:0.077
Batch: 421/843	Loss:0.072
Batch: 505/843	Loss:0.312
Batch: 589/843	Loss:0.032
Batch: 673/843	Loss:0.146
Batch: 757/843	Loss:0.328
Batch: 841/843	Loss:0.051
Batch: 843/843	Loss:0.016
Epoch: 17	Train Loss: 0.171	Val F1: 0.708
Best Epoch: 3	Best Epoch Val F1: 0.722

******************************Epoch: 18******************************
Batch: 1/843	Loss:0.254
Batch: 85/843	Loss:0.062
Batch: 169/843	Loss:0.172
Batch: 253/843	Loss:0.100
Batch: 337/843	Loss:0.219
Batch: 421/843	Loss:0.127
Batch: 505/843	Loss:0.075
Batch: 589/843	Loss:0.062
Batch: 673/843	Loss:0.050
Batch: 757/843	Loss:0.113
Batch: 841/843	Loss:0.138
Batch: 843/843	Loss:0.096
Epoch: 18	Train Loss: 0.160	Val F1: 0.718
Best Epoch: 3	Best Epoch Val F1: 0.722

Saving the best checkpoint....
Inference...
Test F1: 0.741	Test F1_Few: 0.750	Test F1_Zero: 0.732
Starting training with config: {'batch_size': 8, 'epochs': 75, 'l2_reg': 9.855220272319236e-05, 'lr': 1.1293150480024109e-05, 'n_layers_freeze': 3, 'patience': 15}
Let's use 1 GPUs!
Preparing data....
Training data....
# of train examples: 13477
max len: 512, max len wiki: 1
Val data....
# of val examples: 2062
max len: 512, max len wiki: 1
Test data....
# of test examples: 3006
max len: 512, max len wiki: 1
Done

Initializing model....
******************************Epoch: 1******************************
Batch: 1/1685	Loss:1.082
Batch: 169/1685	Loss:1.143
Batch: 337/1685	Loss:1.118
Batch: 505/1685	Loss:0.758
Batch: 673/1685	Loss:0.531
Batch: 841/1685	Loss:0.627
Batch: 1009/1685	Loss:0.575
Batch: 1177/1685	Loss:0.466
Batch: 1345/1685	Loss:0.820
Batch: 1513/1685	Loss:0.679
Batch: 1681/1685	Loss:0.866
Batch: 1685/1685	Loss:0.775
Epoch: 1	Train Loss: 0.804	Val F1: 0.647
Best Epoch: 1	Best Epoch Val F1: 0.647

******************************Epoch: 2******************************
Batch: 1/1685	Loss:0.463
Batch: 169/1685	Loss:1.266
Batch: 337/1685	Loss:0.933
Batch: 505/1685	Loss:0.414
Batch: 673/1685	Loss:0.468
Batch: 841/1685	Loss:1.041
Batch: 1009/1685	Loss:0.397
Batch: 1177/1685	Loss:0.509
Batch: 1345/1685	Loss:0.492
Batch: 1513/1685	Loss:0.812
Batch: 1681/1685	Loss:0.373
Batch: 1685/1685	Loss:0.492
Epoch: 2	Train Loss: 0.604	Val F1: 0.688
Best Epoch: 2	Best Epoch Val F1: 0.688

******************************Epoch: 3******************************
Batch: 1/1685	Loss:0.450
Batch: 169/1685	Loss:0.593
Batch: 337/1685	Loss:0.539
Batch: 505/1685	Loss:0.268
Batch: 673/1685	Loss:0.415
Batch: 841/1685	Loss:1.135
Batch: 1009/1685	Loss:0.402
Batch: 1177/1685	Loss:0.449
Batch: 1345/1685	Loss:0.149
Batch: 1513/1685	Loss:0.661
Batch: 1681/1685	Loss:0.426
Batch: 1685/1685	Loss:0.795
Epoch: 3	Train Loss: 0.519	Val F1: 0.714
Best Epoch: 3	Best Epoch Val F1: 0.714

******************************Epoch: 4******************************
Batch: 1/1685	Loss:0.273
Batch: 169/1685	Loss:0.834
Batch: 337/1685	Loss:0.473
Batch: 505/1685	Loss:0.769
Batch: 673/1685	Loss:0.386
Batch: 841/1685	Loss:0.520
Batch: 1009/1685	Loss:0.522
Batch: 1177/1685	Loss:0.583
Batch: 1345/1685	Loss:0.640
Batch: 1513/1685	Loss:0.189
Batch: 1681/1685	Loss:0.216
Batch: 1685/1685	Loss:1.715
Epoch: 4	Train Loss: 0.443	Val F1: 0.682
Best Epoch: 3	Best Epoch Val F1: 0.714

******************************Epoch: 5******************************
Batch: 1/1685	Loss:0.613
Batch: 169/1685	Loss:0.324
Batch: 337/1685	Loss:0.609
Batch: 505/1685	Loss:0.126
Batch: 673/1685	Loss:0.400
Batch: 841/1685	Loss:0.357
Batch: 1009/1685	Loss:0.384
Batch: 1177/1685	Loss:0.563
Batch: 1345/1685	Loss:0.399
Batch: 1513/1685	Loss:0.341
Batch: 1681/1685	Loss:0.405
Batch: 1685/1685	Loss:0.437
Epoch: 5	Train Loss: 0.393	Val F1: 0.684
Best Epoch: 3	Best Epoch Val F1: 0.714

******************************Epoch: 6******************************
Batch: 1/1685	Loss:0.147
Batch: 169/1685	Loss:0.099
Batch: 337/1685	Loss:0.070
Batch: 505/1685	Loss:0.575
Batch: 673/1685	Loss:0.273
Batch: 841/1685	Loss:0.363
Batch: 1009/1685	Loss:0.226
Batch: 1177/1685	Loss:0.264
Batch: 1345/1685	Loss:0.414
Batch: 1513/1685	Loss:0.262
Batch: 1681/1685	Loss:0.156
Batch: 1685/1685	Loss:0.032
Epoch: 6	Train Loss: 0.346	Val F1: 0.715
Best Epoch: 6	Best Epoch Val F1: 0.715

******************************Epoch: 7******************************
Batch: 1/1685	Loss:0.312
Batch: 169/1685	Loss:0.191
Batch: 337/1685	Loss:0.089
Batch: 505/1685	Loss:0.186
Batch: 673/1685	Loss:0.330
Batch: 841/1685	Loss:0.341
Batch: 1009/1685	Loss:0.177
Batch: 1177/1685	Loss:0.178
Batch: 1345/1685	Loss:0.291
Batch: 1513/1685	Loss:0.532
Batch: 1681/1685	Loss:0.135
Batch: 1685/1685	Loss:0.151
Epoch: 7	Train Loss: 0.308	Val F1: 0.686
Best Epoch: 6	Best Epoch Val F1: 0.715

******************************Epoch: 8******************************
Batch: 1/1685	Loss:0.171
Batch: 169/1685	Loss:0.472
Batch: 337/1685	Loss:0.039
Batch: 505/1685	Loss:0.579
Batch: 673/1685	Loss:0.329
Batch: 841/1685	Loss:0.323
Batch: 1009/1685	Loss:0.697
Batch: 1177/1685	Loss:0.486
Batch: 1345/1685	Loss:0.081
Batch: 1513/1685	Loss:0.363
Batch: 1681/1685	Loss:0.423
Batch: 1685/1685	Loss:0.115
Epoch: 8	Train Loss: 0.276	Val F1: 0.669
Best Epoch: 6	Best Epoch Val F1: 0.715

******************************Epoch: 9******************************
Batch: 1/1685	Loss:0.325
Batch: 169/1685	Loss:0.207
Batch: 337/1685	Loss:0.719
Batch: 505/1685	Loss:0.480
Batch: 673/1685	Loss:0.084
Batch: 841/1685	Loss:0.501
Batch: 1009/1685	Loss:0.231
Batch: 1177/1685	Loss:0.493
Batch: 1345/1685	Loss:0.426
Batch: 1513/1685	Loss:0.203
Batch: 1681/1685	Loss:0.053
Batch: 1685/1685	Loss:0.256
Epoch: 9	Train Loss: 0.242	Val F1: 0.713
Best Epoch: 6	Best Epoch Val F1: 0.715

******************************Epoch: 10******************************
Batch: 1/1685	Loss:0.371
Batch: 169/1685	Loss:0.296
Batch: 337/1685	Loss:0.252
Batch: 505/1685	Loss:0.135
Batch: 673/1685	Loss:0.022
Batch: 841/1685	Loss:0.199
Batch: 1009/1685	Loss:0.392
Batch: 1177/1685	Loss:0.379
Batch: 1345/1685	Loss:0.018
Batch: 1513/1685	Loss:0.125
Batch: 1681/1685	Loss:0.047
Batch: 1685/1685	Loss:0.065
Epoch: 10	Train Loss: 0.221	Val F1: 0.710
Best Epoch: 6	Best Epoch Val F1: 0.715

******************************Epoch: 11******************************
Batch: 1/1685	Loss:0.214
Batch: 169/1685	Loss:0.460
Batch: 337/1685	Loss:0.302
Batch: 505/1685	Loss:0.025
Batch: 673/1685	Loss:0.124
Batch: 841/1685	Loss:0.383
Batch: 1009/1685	Loss:0.408
Batch: 1177/1685	Loss:0.091
Batch: 1345/1685	Loss:0.517
Batch: 1513/1685	Loss:0.041
Batch: 1681/1685	Loss:0.052
Batch: 1685/1685	Loss:0.025
Epoch: 11	Train Loss: 0.203	Val F1: 0.707
Best Epoch: 6	Best Epoch Val F1: 0.715

******************************Epoch: 12******************************
Batch: 1/1685	Loss:0.317
Batch: 169/1685	Loss:0.048
Batch: 337/1685	Loss:0.184
Batch: 505/1685	Loss:0.283
Batch: 673/1685	Loss:0.116
Batch: 841/1685	Loss:0.478
Batch: 1009/1685	Loss:0.458
Batch: 1177/1685	Loss:0.146
Batch: 1345/1685	Loss:0.012
Batch: 1513/1685	Loss:0.025
Batch: 1681/1685	Loss:0.034
Batch: 1685/1685	Loss:0.001
Epoch: 12	Train Loss: 0.188	Val F1: 0.710
Best Epoch: 6	Best Epoch Val F1: 0.715

******************************Epoch: 13******************************
Batch: 1/1685	Loss:0.193
Batch: 169/1685	Loss:0.013
Batch: 337/1685	Loss:0.342
Batch: 505/1685	Loss:0.111
Batch: 673/1685	Loss:0.040
Batch: 841/1685	Loss:0.073
Batch: 1009/1685	Loss:0.117
Batch: 1177/1685	Loss:0.131
Batch: 1345/1685	Loss:0.270
Batch: 1513/1685	Loss:0.509
Batch: 1681/1685	Loss:0.271
Batch: 1685/1685	Loss:0.089
Epoch: 13	Train Loss: 0.174	Val F1: 0.714
Best Epoch: 6	Best Epoch Val F1: 0.715

******************************Epoch: 14******************************
Batch: 1/1685	Loss:0.426
Batch: 169/1685	Loss:0.017
Batch: 337/1685	Loss:0.056
Batch: 505/1685	Loss:0.072
Batch: 673/1685	Loss:0.314
Batch: 841/1685	Loss:0.255
Batch: 1009/1685	Loss:0.258
Batch: 1177/1685	Loss:0.058
Batch: 1345/1685	Loss:0.094
Batch: 1513/1685	Loss:0.077
Batch: 1681/1685	Loss:0.458
Batch: 1685/1685	Loss:0.019
Epoch: 14	Train Loss: 0.160	Val F1: 0.707
Best Epoch: 6	Best Epoch Val F1: 0.715

******************************Epoch: 15******************************
Batch: 1/1685	Loss:0.013
Batch: 169/1685	Loss:0.006
Batch: 337/1685	Loss:0.033
Batch: 505/1685	Loss:0.059
Batch: 673/1685	Loss:0.019
Batch: 841/1685	Loss:0.020
Batch: 1009/1685	Loss:0.013
Batch: 1177/1685	Loss:0.117
Batch: 1345/1685	Loss:0.214
Batch: 1513/1685	Loss:0.026
Batch: 1681/1685	Loss:0.225
Batch: 1685/1685	Loss:0.001
Epoch: 15	Train Loss: 0.149	Val F1: 0.707
Best Epoch: 6	Best Epoch Val F1: 0.715

******************************Epoch: 16******************************
Batch: 1/1685	Loss:0.119
Batch: 169/1685	Loss:0.169
Batch: 337/1685	Loss:0.283
Batch: 505/1685	Loss:0.235
Batch: 673/1685	Loss:0.347
Batch: 841/1685	Loss:0.083
Batch: 1009/1685	Loss:0.168
Batch: 1177/1685	Loss:0.010
Batch: 1345/1685	Loss:0.057
Batch: 1513/1685	Loss:0.090
Batch: 1681/1685	Loss:0.045
Batch: 1685/1685	Loss:0.049
Epoch: 16	Train Loss: 0.148	Val F1: 0.700
Best Epoch: 6	Best Epoch Val F1: 0.715

******************************Epoch: 17******************************
Batch: 1/1685	Loss:0.079
Batch: 169/1685	Loss:0.090
Batch: 337/1685	Loss:0.028
Batch: 505/1685	Loss:0.163
Batch: 673/1685	Loss:0.061
Batch: 841/1685	Loss:0.026
Batch: 1009/1685	Loss:0.102
Batch: 1177/1685	Loss:0.023
Batch: 1345/1685	Loss:0.179
Batch: 1513/1685	Loss:0.473
Batch: 1681/1685	Loss:0.094
Batch: 1685/1685	Loss:0.009
Epoch: 17	Train Loss: 0.141	Val F1: 0.700
Best Epoch: 6	Best Epoch Val F1: 0.715

******************************Epoch: 18******************************
Batch: 1/1685	Loss:0.007
Batch: 169/1685	Loss:0.031
Batch: 337/1685	Loss:0.114
Batch: 505/1685	Loss:0.026
Batch: 673/1685	Loss:0.098
Batch: 841/1685	Loss:0.146
Batch: 1009/1685	Loss:0.010
Batch: 1177/1685	Loss:0.154
Batch: 1345/1685	Loss:0.048
Batch: 1513/1685	Loss:0.044
Batch: 1681/1685	Loss:0.144
Batch: 1685/1685	Loss:0.148
Epoch: 18	Train Loss: 0.136	Val F1: 0.716
Best Epoch: 18	Best Epoch Val F1: 0.716

******************************Epoch: 19******************************
Batch: 1/1685	Loss:0.317
Batch: 169/1685	Loss:0.001
Batch: 337/1685	Loss:0.219
Batch: 505/1685	Loss:0.075
Batch: 673/1685	Loss:0.161
Batch: 841/1685	Loss:0.056
Batch: 1009/1685	Loss:0.135
Batch: 1177/1685	Loss:0.092
Batch: 1345/1685	Loss:0.023
Batch: 1513/1685	Loss:0.191
Batch: 1681/1685	Loss:0.003
Batch: 1685/1685	Loss:0.205
Epoch: 19	Train Loss: 0.131	Val F1: 0.709
Best Epoch: 18	Best Epoch Val F1: 0.716

******************************Epoch: 20******************************
Batch: 1/1685	Loss:0.013
Batch: 169/1685	Loss:0.837
Batch: 337/1685	Loss:0.108
Batch: 505/1685	Loss:0.058
Batch: 673/1685	Loss:0.306
Batch: 841/1685	Loss:0.032
Batch: 1009/1685	Loss:0.144
Batch: 1177/1685	Loss:0.212
Batch: 1345/1685	Loss:0.015
Batch: 1513/1685	Loss:0.044
Batch: 1681/1685	Loss:0.018
Batch: 1685/1685	Loss:0.079
Epoch: 20	Train Loss: 0.118	Val F1: 0.714
Best Epoch: 18	Best Epoch Val F1: 0.716

******************************Epoch: 21******************************
Batch: 1/1685	Loss:0.067
Batch: 169/1685	Loss:0.080
Batch: 337/1685	Loss:0.022
Batch: 505/1685	Loss:0.064
Batch: 673/1685	Loss:0.087
Batch: 841/1685	Loss:0.061
Batch: 1009/1685	Loss:0.061
Batch: 1177/1685	Loss:0.072
Batch: 1345/1685	Loss:0.019
Batch: 1513/1685	Loss:0.069
Batch: 1681/1685	Loss:0.040
Batch: 1685/1685	Loss:0.242
Epoch: 21	Train Loss: 0.119	Val F1: 0.708
Best Epoch: 18	Best Epoch Val F1: 0.716

******************************Epoch: 22******************************
Batch: 1/1685	Loss:0.027
Batch: 169/1685	Loss:0.263
Batch: 337/1685	Loss:0.070
Batch: 505/1685	Loss:0.008
Batch: 673/1685	Loss:0.218
Batch: 841/1685	Loss:0.035
Batch: 1009/1685	Loss:0.483
Batch: 1177/1685	Loss:0.155
Batch: 1345/1685	Loss:0.122
Batch: 1513/1685	Loss:0.040
Batch: 1681/1685	Loss:0.082
Batch: 1685/1685	Loss:0.150
Epoch: 22	Train Loss: 0.119	Val F1: 0.701
Best Epoch: 18	Best Epoch Val F1: 0.716

******************************Epoch: 23******************************
Batch: 1/1685	Loss:0.192
Batch: 169/1685	Loss:0.009
Batch: 337/1685	Loss:0.284
Batch: 505/1685	Loss:0.005
Batch: 673/1685	Loss:0.010
Batch: 841/1685	Loss:0.021
Batch: 1009/1685	Loss:0.007
Batch: 1177/1685	Loss:0.089
Batch: 1345/1685	Loss:0.004
Batch: 1513/1685	Loss:0.072
Batch: 1681/1685	Loss:0.057
Batch: 1685/1685	Loss:0.076
Epoch: 23	Train Loss: 0.118	Val F1: 0.707
Best Epoch: 18	Best Epoch Val F1: 0.716

******************************Epoch: 24******************************
Batch: 1/1685	Loss:0.105
Batch: 169/1685	Loss:0.002
Batch: 337/1685	Loss:0.004
Batch: 505/1685	Loss:0.046
Batch: 673/1685	Loss:0.029
Batch: 841/1685	Loss:0.233
Batch: 1009/1685	Loss:0.061
Batch: 1177/1685	Loss:0.051
Batch: 1345/1685	Loss:0.172
Batch: 1513/1685	Loss:0.033
Batch: 1681/1685	Loss:0.001
Batch: 1685/1685	Loss:0.020
Epoch: 24	Train Loss: 0.109	Val F1: 0.707
Best Epoch: 18	Best Epoch Val F1: 0.716

******************************Epoch: 25******************************
Batch: 1/1685	Loss:0.092
Batch: 169/1685	Loss:0.001
Batch: 337/1685	Loss:0.031
Batch: 505/1685	Loss:0.135
Batch: 673/1685	Loss:0.164
Batch: 841/1685	Loss:0.043
Batch: 1009/1685	Loss:0.022
Batch: 1177/1685	Loss:0.001
Batch: 1345/1685	Loss:0.027
Batch: 1513/1685	Loss:0.038
Batch: 1681/1685	Loss:0.149
Batch: 1685/1685	Loss:0.027
Epoch: 25	Train Loss: 0.107	Val F1: 0.716
Best Epoch: 18	Best Epoch Val F1: 0.716

******************************Epoch: 26******************************
Batch: 1/1685	Loss:0.039
Batch: 169/1685	Loss:0.189
Batch: 337/1685	Loss:0.236
Batch: 505/1685	Loss:0.341
Batch: 673/1685	Loss:0.105
Batch: 841/1685	Loss:0.184
Batch: 1009/1685	Loss:0.065
Batch: 1177/1685	Loss:0.339
Batch: 1345/1685	Loss:0.127
Batch: 1513/1685	Loss:0.199
Batch: 1681/1685	Loss:0.139
Batch: 1685/1685	Loss:0.001
Epoch: 26	Train Loss: 0.107	Val F1: 0.705
Best Epoch: 18	Best Epoch Val F1: 0.716

******************************Epoch: 27******************************
Batch: 1/1685	Loss:0.084
Batch: 169/1685	Loss:0.001
Batch: 337/1685	Loss:0.274
Batch: 505/1685	Loss:0.276
Batch: 673/1685	Loss:0.146
Batch: 841/1685	Loss:0.172
Batch: 1009/1685	Loss:0.183
Batch: 1177/1685	Loss:0.184
Batch: 1345/1685	Loss:0.071
Batch: 1513/1685	Loss:0.086
Batch: 1681/1685	Loss:0.002
Batch: 1685/1685	Loss:0.358
Epoch: 27	Train Loss: 0.097	Val F1: 0.703
Best Epoch: 18	Best Epoch Val F1: 0.716

******************************Epoch: 28******************************
Batch: 1/1685	Loss:0.002
Batch: 169/1685	Loss:0.101
Batch: 337/1685	Loss:0.002
Batch: 505/1685	Loss:0.000
Batch: 673/1685	Loss:0.013
Batch: 841/1685	Loss:0.002
Batch: 1009/1685	Loss:0.017
Batch: 1177/1685	Loss:0.003
Batch: 1345/1685	Loss:0.032
Batch: 1513/1685	Loss:0.001
Batch: 1681/1685	Loss:0.107
Batch: 1685/1685	Loss:0.227
Epoch: 28	Train Loss: 0.102	Val F1: 0.696
Best Epoch: 18	Best Epoch Val F1: 0.716

******************************Epoch: 29******************************
Batch: 1/1685	Loss:0.001
Batch: 169/1685	Loss:0.005
Batch: 337/1685	Loss:0.080
Batch: 505/1685	Loss:0.002
Batch: 673/1685	Loss:0.147
Batch: 841/1685	Loss:0.107
Batch: 1009/1685	Loss:0.808
Batch: 1177/1685	Loss:0.123
Batch: 1345/1685	Loss:0.013
Batch: 1513/1685	Loss:0.066
Batch: 1681/1685	Loss:0.302
Batch: 1685/1685	Loss:0.102
Epoch: 29	Train Loss: 0.097	Val F1: 0.706
Best Epoch: 18	Best Epoch Val F1: 0.716

******************************Epoch: 30******************************
Batch: 1/1685	Loss:0.001
Batch: 169/1685	Loss:0.005
Batch: 337/1685	Loss:0.098
Batch: 505/1685	Loss:0.004
Batch: 673/1685	Loss:0.012
Batch: 841/1685	Loss:0.010
Batch: 1009/1685	Loss:0.069
Batch: 1177/1685	Loss:0.207
Batch: 1345/1685	Loss:0.215
Batch: 1513/1685	Loss:0.029
Batch: 1681/1685	Loss:0.077
Batch: 1685/1685	Loss:0.001
Epoch: 30	Train Loss: 0.098	Val F1: 0.694
Best Epoch: 18	Best Epoch Val F1: 0.716

******************************Epoch: 31******************************
Batch: 1/1685	Loss:0.226
Batch: 169/1685	Loss:0.007
Batch: 337/1685	Loss:0.003
Batch: 505/1685	Loss:0.001
Batch: 673/1685	Loss:0.162
Batch: 841/1685	Loss:0.102
Batch: 1009/1685	Loss:0.043
Batch: 1177/1685	Loss:0.009
Batch: 1345/1685	Loss:0.005
Batch: 1513/1685	Loss:0.215
Batch: 1681/1685	Loss:0.087
Batch: 1685/1685	Loss:0.404
Epoch: 31	Train Loss: 0.096	Val F1: 0.705
Best Epoch: 18	Best Epoch Val F1: 0.716

******************************Epoch: 32******************************
Batch: 1/1685	Loss:0.011
Batch: 169/1685	Loss:0.092
Batch: 337/1685	Loss:0.217
Batch: 505/1685	Loss:0.011
Batch: 673/1685	Loss:0.116
Batch: 841/1685	Loss:0.001
Batch: 1009/1685	Loss:0.128
Batch: 1177/1685	Loss:0.085
Batch: 1345/1685	Loss:0.003
Batch: 1513/1685	Loss:0.156
Batch: 1681/1685	Loss:0.041
Batch: 1685/1685	Loss:0.329
Epoch: 32	Train Loss: 0.092	Val F1: 0.706
Best Epoch: 18	Best Epoch Val F1: 0.716

******************************Epoch: 33******************************
Batch: 1/1685	Loss:0.245
Batch: 169/1685	Loss:0.130
Batch: 337/1685	Loss:0.011
Batch: 505/1685	Loss:0.000
Batch: 673/1685	Loss:0.636
Batch: 841/1685	Loss:0.001
Batch: 1009/1685	Loss:0.004
Batch: 1177/1685	Loss:0.151
Batch: 1345/1685	Loss:0.001
Batch: 1513/1685	Loss:0.029
Batch: 1681/1685	Loss:0.003
Batch: 1685/1685	Loss:0.272
Epoch: 33	Train Loss: 0.092	Val F1: 0.698
Best Epoch: 18	Best Epoch Val F1: 0.716

Saving the best checkpoint....
Inference...
Test F1: 0.721	Test F1_Few: 0.734	Test F1_Zero: 0.707
Starting training with config: {'batch_size': 64, 'epochs': 50, 'l2_reg': 8.017995133791759e-05, 'lr': 1.6812007465377086e-05, 'n_layers_freeze': 0, 'patience': 15}
Let's use 1 GPUs!
Preparing data....
Training data....
# of train examples: 13477
max len: 512, max len wiki: 1
Val data....
# of val examples: 2062
max len: 512, max len wiki: 1
Test data....
# of test examples: 3006
max len: 512, max len wiki: 1
Done

Initializing model....
******************************Epoch: 1******************************
Batch: 1/211	Loss:1.300
Batch: 22/211	Loss:1.033
Batch: 43/211	Loss:1.146
Batch: 64/211	Loss:1.005
Batch: 85/211	Loss:1.067
Batch: 106/211	Loss:1.018
Batch: 127/211	Loss:1.034
Batch: 148/211	Loss:1.045
Batch: 169/211	Loss:0.957
Batch: 190/211	Loss:0.832
Batch: 211/211	Loss:0.864
Epoch: 1	Train Loss: 0.999	Val F1: 0.669
Best Epoch: 1	Best Epoch Val F1: 0.669

******************************Epoch: 2******************************
Batch: 1/211	Loss:0.836
Batch: 22/211	Loss:0.820
Batch: 43/211	Loss:0.784
Batch: 64/211	Loss:0.637
Batch: 85/211	Loss:0.713
Batch: 106/211	Loss:0.833
Batch: 127/211	Loss:0.703
Batch: 148/211	Loss:0.623
Batch: 169/211	Loss:0.677
Batch: 190/211	Loss:0.549
Batch: 211/211	Loss:0.516
Epoch: 2	Train Loss: 0.645	Val F1: 0.721
Best Epoch: 2	Best Epoch Val F1: 0.721

******************************Epoch: 3******************************
Batch: 1/211	Loss:0.561
Batch: 22/211	Loss:0.487
Batch: 43/211	Loss:0.491
Batch: 64/211	Loss:0.460
Batch: 85/211	Loss:0.420
Batch: 106/211	Loss:0.493
Batch: 127/211	Loss:0.351
Batch: 148/211	Loss:0.594
Batch: 169/211	Loss:0.594
Batch: 190/211	Loss:0.459
Batch: 211/211	Loss:0.406
Epoch: 3	Train Loss: 0.506	Val F1: 0.724
Best Epoch: 3	Best Epoch Val F1: 0.724

******************************Epoch: 4******************************
Batch: 1/211	Loss:0.378
Batch: 22/211	Loss:0.452
Batch: 43/211	Loss:0.397
Batch: 64/211	Loss:0.342
Batch: 85/211	Loss:0.397
Batch: 106/211	Loss:0.364
Batch: 127/211	Loss:0.429
Batch: 148/211	Loss:0.454
Batch: 169/211	Loss:0.455
Batch: 190/211	Loss:0.443
Batch: 211/211	Loss:0.392
Epoch: 4	Train Loss: 0.433	Val F1: 0.647
Best Epoch: 3	Best Epoch Val F1: 0.724

******************************Epoch: 5******************************
Batch: 1/211	Loss:0.496
Batch: 22/211	Loss:0.338
Batch: 43/211	Loss:0.269
Batch: 64/211	Loss:0.405
Batch: 85/211	Loss:0.450
Batch: 106/211	Loss:0.288
Batch: 127/211	Loss:0.269
Batch: 148/211	Loss:0.367
Batch: 169/211	Loss:0.339
Batch: 190/211	Loss:0.431
Batch: 211/211	Loss:0.428
Epoch: 5	Train Loss: 0.374	Val F1: 0.697
Best Epoch: 3	Best Epoch Val F1: 0.724

******************************Epoch: 6******************************
Batch: 1/211	Loss:0.251
Batch: 22/211	Loss:0.238
Batch: 43/211	Loss:0.314
Batch: 64/211	Loss:0.273
Batch: 85/211	Loss:0.288
Batch: 106/211	Loss:0.455
Batch: 127/211	Loss:0.337
Batch: 148/211	Loss:0.327
Batch: 169/211	Loss:0.376
Batch: 190/211	Loss:0.335
Batch: 211/211	Loss:0.267
Epoch: 6	Train Loss: 0.331	Val F1: 0.715
Best Epoch: 3	Best Epoch Val F1: 0.724

******************************Epoch: 7******************************
Batch: 1/211	Loss:0.314
Batch: 22/211	Loss:0.223
Batch: 43/211	Loss:0.271
Batch: 64/211	Loss:0.297
Batch: 85/211	Loss:0.460
Batch: 106/211	Loss:0.333
Batch: 127/211	Loss:0.409
Batch: 148/211	Loss:0.424
Batch: 169/211	Loss:0.324
Batch: 190/211	Loss:0.380
Batch: 211/211	Loss:0.420
Epoch: 7	Train Loss: 0.292	Val F1: 0.712
Best Epoch: 3	Best Epoch Val F1: 0.724

******************************Epoch: 8******************************
Batch: 1/211	Loss:0.205
Batch: 22/211	Loss:0.223
Batch: 43/211	Loss:0.172
Batch: 64/211	Loss:0.319
Batch: 85/211	Loss:0.231
Batch: 106/211	Loss:0.145
Batch: 127/211	Loss:0.257
Batch: 148/211	Loss:0.299
Batch: 169/211	Loss:0.330
Batch: 190/211	Loss:0.300
Batch: 211/211	Loss:0.297
Epoch: 8	Train Loss: 0.262	Val F1: 0.714
Best Epoch: 3	Best Epoch Val F1: 0.724

******************************Epoch: 9******************************
Batch: 1/211	Loss:0.228
Batch: 22/211	Loss:0.239
Batch: 43/211	Loss:0.319
Batch: 64/211	Loss:0.283
Batch: 85/211	Loss:0.251
Batch: 106/211	Loss:0.151
Batch: 127/211	Loss:0.174
Batch: 148/211	Loss:0.226
Batch: 169/211	Loss:0.243
Batch: 190/211	Loss:0.235
Batch: 211/211	Loss:0.135
Epoch: 9	Train Loss: 0.230	Val F1: 0.714
Best Epoch: 3	Best Epoch Val F1: 0.724

******************************Epoch: 10******************************
Batch: 1/211	Loss:0.127
Batch: 22/211	Loss:0.167
Batch: 43/211	Loss:0.220
Batch: 64/211	Loss:0.090
Batch: 85/211	Loss:0.196
Batch: 106/211	Loss:0.141
Batch: 127/211	Loss:0.286
Batch: 148/211	Loss:0.143
Batch: 169/211	Loss:0.167
Batch: 190/211	Loss:0.234
Batch: 211/211	Loss:0.159
Epoch: 10	Train Loss: 0.204	Val F1: 0.726
Best Epoch: 10	Best Epoch Val F1: 0.726

******************************Epoch: 11******************************
Batch: 1/211	Loss:0.141
Batch: 22/211	Loss:0.205
Batch: 43/211	Loss:0.101
Batch: 64/211	Loss:0.222
Batch: 85/211	Loss:0.137
Batch: 106/211	Loss:0.156
Batch: 127/211	Loss:0.208
Batch: 148/211	Loss:0.152
Batch: 169/211	Loss:0.252
Batch: 190/211	Loss:0.133
Batch: 211/211	Loss:0.163
Epoch: 11	Train Loss: 0.184	Val F1: 0.711
Best Epoch: 10	Best Epoch Val F1: 0.726

******************************Epoch: 12******************************
Batch: 1/211	Loss:0.093
Batch: 22/211	Loss:0.165
Batch: 43/211	Loss:0.160
Batch: 64/211	Loss:0.201
Batch: 85/211	Loss:0.141
Batch: 106/211	Loss:0.191
Batch: 127/211	Loss:0.161
Batch: 148/211	Loss:0.255
Batch: 169/211	Loss:0.086
Batch: 190/211	Loss:0.106
Batch: 211/211	Loss:0.111
Epoch: 12	Train Loss: 0.170	Val F1: 0.708
Best Epoch: 10	Best Epoch Val F1: 0.726

******************************Epoch: 13******************************
Batch: 1/211	Loss:0.206
Batch: 22/211	Loss:0.193
Batch: 43/211	Loss:0.117
Batch: 64/211	Loss:0.171
Batch: 85/211	Loss:0.103
Batch: 106/211	Loss:0.119
Batch: 127/211	Loss:0.145
Batch: 148/211	Loss:0.261
Batch: 169/211	Loss:0.154
Batch: 190/211	Loss:0.250
Batch: 211/211	Loss:0.200
Epoch: 13	Train Loss: 0.153	Val F1: 0.709
Best Epoch: 10	Best Epoch Val F1: 0.726

******************************Epoch: 14******************************
Batch: 1/211	Loss:0.177
Batch: 22/211	Loss:0.179
Batch: 43/211	Loss:0.142
Batch: 64/211	Loss:0.125
Batch: 85/211	Loss:0.083
Batch: 106/211	Loss:0.130
Batch: 127/211	Loss:0.130
Batch: 148/211	Loss:0.107
Batch: 169/211	Loss:0.150
Batch: 190/211	Loss:0.128
Batch: 211/211	Loss:0.196
Epoch: 14	Train Loss: 0.143	Val F1: 0.708
Best Epoch: 10	Best Epoch Val F1: 0.726

******************************Epoch: 15******************************
Batch: 1/211	Loss:0.054
Batch: 22/211	Loss:0.053
Batch: 43/211	Loss:0.052
Batch: 64/211	Loss:0.179
Batch: 85/211	Loss:0.078
Batch: 106/211	Loss:0.054
Batch: 127/211	Loss:0.233
Batch: 148/211	Loss:0.191
Batch: 169/211	Loss:0.149
Batch: 190/211	Loss:0.143
Batch: 211/211	Loss:0.230
Epoch: 15	Train Loss: 0.133	Val F1: 0.710
Best Epoch: 10	Best Epoch Val F1: 0.726

******************************Epoch: 16******************************
Batch: 1/211	Loss:0.116
Batch: 22/211	Loss:0.186
Batch: 43/211	Loss:0.107
Batch: 64/211	Loss:0.027
Batch: 85/211	Loss:0.077
Batch: 106/211	Loss:0.127
Batch: 127/211	Loss:0.094
Batch: 148/211	Loss:0.073
Batch: 169/211	Loss:0.047
Batch: 190/211	Loss:0.172
Batch: 211/211	Loss:0.173
Epoch: 16	Train Loss: 0.129	Val F1: 0.699
Best Epoch: 10	Best Epoch Val F1: 0.726

******************************Epoch: 17******************************
Batch: 1/211	Loss:0.057
Batch: 22/211	Loss:0.121
Batch: 43/211	Loss:0.099
Batch: 64/211	Loss:0.059
Batch: 85/211	Loss:0.112
Batch: 106/211	Loss:0.072
Batch: 127/211	Loss:0.153
Batch: 148/211	Loss:0.035
Batch: 169/211	Loss:0.116
Batch: 190/211	Loss:0.201
Batch: 211/211	Loss:0.038
Epoch: 17	Train Loss: 0.117	Val F1: 0.708
Best Epoch: 10	Best Epoch Val F1: 0.726

******************************Epoch: 18******************************
Batch: 1/211	Loss:0.177
Batch: 22/211	Loss:0.061
Batch: 43/211	Loss:0.046
Batch: 64/211	Loss:0.164
Batch: 85/211	Loss:0.125
Batch: 106/211	Loss:0.145
Batch: 127/211	Loss:0.181
Batch: 148/211	Loss:0.158
Batch: 169/211	Loss:0.088
Batch: 190/211	Loss:0.067
Batch: 211/211	Loss:0.280
Epoch: 18	Train Loss: 0.118	Val F1: 0.708
Best Epoch: 10	Best Epoch Val F1: 0.726

******************************Epoch: 19******************************
Batch: 1/211	Loss:0.058
Batch: 22/211	Loss:0.170
Batch: 43/211	Loss:0.200
Batch: 64/211	Loss:0.187
Batch: 85/211	Loss:0.080
Batch: 106/211	Loss:0.082
Batch: 127/211	Loss:0.146
Batch: 148/211	Loss:0.107
Batch: 169/211	Loss:0.214
Batch: 190/211	Loss:0.128
Batch: 211/211	Loss:0.029
Epoch: 19	Train Loss: 0.117	Val F1: 0.704
Best Epoch: 10	Best Epoch Val F1: 0.726

******************************Epoch: 20******************************
Batch: 1/211	Loss:0.059
Batch: 22/211	Loss:0.164
Batch: 43/211	Loss:0.052
Batch: 64/211	Loss:0.059
Batch: 85/211	Loss:0.129
Batch: 106/211	Loss:0.056
Batch: 127/211	Loss:0.061
Batch: 148/211	Loss:0.120
Batch: 169/211	Loss:0.065
Batch: 190/211	Loss:0.162
Batch: 211/211	Loss:0.096
Epoch: 20	Train Loss: 0.110	Val F1: 0.688
Best Epoch: 10	Best Epoch Val F1: 0.726

******************************Epoch: 21******************************
Batch: 1/211	Loss:0.081
Batch: 22/211	Loss:0.132
Batch: 43/211	Loss:0.037
Batch: 64/211	Loss:0.066
Batch: 85/211	Loss:0.046
Batch: 106/211	Loss:0.110
Batch: 127/211	Loss:0.141
Batch: 148/211	Loss:0.068
Batch: 169/211	Loss:0.126
Batch: 190/211	Loss:0.147
Batch: 211/211	Loss:0.126
Epoch: 21	Train Loss: 0.104	Val F1: 0.703
Best Epoch: 10	Best Epoch Val F1: 0.726

******************************Epoch: 22******************************
Batch: 1/211	Loss:0.042
Batch: 22/211	Loss:0.121
Batch: 43/211	Loss:0.132
Batch: 64/211	Loss:0.066
Batch: 85/211	Loss:0.108
Batch: 106/211	Loss:0.075
Batch: 127/211	Loss:0.144
Batch: 148/211	Loss:0.105
Batch: 169/211	Loss:0.090
Batch: 190/211	Loss:0.055
Batch: 211/211	Loss:0.146
Epoch: 22	Train Loss: 0.100	Val F1: 0.704
Best Epoch: 10	Best Epoch Val F1: 0.726

******************************Epoch: 23******************************
Batch: 1/211	Loss:0.123
Batch: 22/211	Loss:0.042
Batch: 43/211	Loss:0.109
Batch: 64/211	Loss:0.051
Batch: 85/211	Loss:0.055
Batch: 106/211	Loss:0.069
Batch: 127/211	Loss:0.122
Batch: 148/211	Loss:0.108
Batch: 169/211	Loss:0.151
Batch: 190/211	Loss:0.116
Batch: 211/211	Loss:0.146
Epoch: 23	Train Loss: 0.099	Val F1: 0.700
Best Epoch: 10	Best Epoch Val F1: 0.726

******************************Epoch: 24******************************
Batch: 1/211	Loss:0.065
Batch: 22/211	Loss:0.018
Batch: 43/211	Loss:0.116
Batch: 64/211	Loss:0.167
Batch: 85/211	Loss:0.060
Batch: 106/211	Loss:0.078
Batch: 127/211	Loss:0.096
Batch: 148/211	Loss:0.140
Batch: 169/211	Loss:0.068
Batch: 190/211	Loss:0.084
Batch: 211/211	Loss:0.097
Epoch: 24	Train Loss: 0.101	Val F1: 0.699
Best Epoch: 10	Best Epoch Val F1: 0.726

******************************Epoch: 25******************************
Batch: 1/211	Loss:0.074
Batch: 22/211	Loss:0.162
Batch: 43/211	Loss:0.171
Batch: 64/211	Loss:0.130
Batch: 85/211	Loss:0.196
Batch: 106/211	Loss:0.108
Batch: 127/211	Loss:0.048
Batch: 148/211	Loss:0.090
Batch: 169/211	Loss:0.054
Batch: 190/211	Loss:0.064
Batch: 211/211	Loss:0.126
Epoch: 25	Train Loss: 0.099	Val F1: 0.699
Best Epoch: 10	Best Epoch Val F1: 0.726

Saving the best checkpoint....
Inference...
Test F1: 0.743	Test F1_Few: 0.756	Test F1_Zero: 0.729
Starting training with config: {'batch_size': 4, 'epochs': 75, 'l2_reg': 7.713770593384155e-05, 'lr': 1.970334596557772e-05, 'n_layers_freeze': 3, 'patience': 5}
Let's use 1 GPUs!
Preparing data....
Training data....
# of train examples: 13477
max len: 512, max len wiki: 1
Val data....
# of val examples: 2062
max len: 512, max len wiki: 1
Test data....
# of test examples: 3006
max len: 512, max len wiki: 1
Done

Initializing model....
******************************Epoch: 1******************************
Batch: 1/3370	Loss:1.322
Batch: 338/3370	Loss:1.272
Batch: 675/3370	Loss:0.939
Batch: 1012/3370	Loss:0.665
Batch: 1349/3370	Loss:0.866
Batch: 1686/3370	Loss:1.645
Batch: 2023/3370	Loss:0.169
Batch: 2360/3370	Loss:1.543
Batch: 2697/3370	Loss:0.682
Batch: 3034/3370	Loss:0.569
Batch: 3370/3370	Loss:1.551
Epoch: 1	Train Loss: 0.768	Val F1: 0.688
Best Epoch: 1	Best Epoch Val F1: 0.688

******************************Epoch: 2******************************
Batch: 1/3370	Loss:0.506
Batch: 338/3370	Loss:0.862
Batch: 675/3370	Loss:0.470
Batch: 1012/3370	Loss:0.561
Batch: 1349/3370	Loss:0.473
Batch: 1686/3370	Loss:0.314
Batch: 2023/3370	Loss:0.571
Batch: 2360/3370	Loss:0.520
Batch: 2697/3370	Loss:0.544
Batch: 3034/3370	Loss:0.366
Batch: 3370/3370	Loss:0.010
Epoch: 2	Train Loss: 0.568	Val F1: 0.704
Best Epoch: 2	Best Epoch Val F1: 0.704

******************************Epoch: 3******************************
Batch: 1/3370	Loss:0.138
Batch: 338/3370	Loss:0.765
Batch: 675/3370	Loss:0.445
Batch: 1012/3370	Loss:0.479
Batch: 1349/3370	Loss:0.393
Batch: 1686/3370	Loss:1.113
Batch: 2023/3370	Loss:0.467
Batch: 2360/3370	Loss:0.383
Batch: 2697/3370	Loss:0.107
Batch: 3034/3370	Loss:0.175
Batch: 3370/3370	Loss:0.328
Epoch: 3	Train Loss: 0.478	Val F1: 0.694
Best Epoch: 2	Best Epoch Val F1: 0.704

******************************Epoch: 4******************************
Batch: 1/3370	Loss:0.197
Batch: 338/3370	Loss:0.372
Batch: 675/3370	Loss:0.163
Batch: 1012/3370	Loss:0.578
Batch: 1349/3370	Loss:0.330
Batch: 1686/3370	Loss:0.295
Batch: 2023/3370	Loss:0.446
Batch: 2360/3370	Loss:0.361
Batch: 2697/3370	Loss:0.795
Batch: 3034/3370	Loss:0.337
Batch: 3370/3370	Loss:0.000
Epoch: 4	Train Loss: 0.415	Val F1: 0.673
Best Epoch: 2	Best Epoch Val F1: 0.704

******************************Epoch: 5******************************
Batch: 1/3370	Loss:0.645
Batch: 338/3370	Loss:0.703
Batch: 675/3370	Loss:0.431
Batch: 1012/3370	Loss:0.187
Batch: 1349/3370	Loss:0.010
Batch: 1686/3370	Loss:0.095
Batch: 2023/3370	Loss:0.135
Batch: 2360/3370	Loss:0.111
Batch: 2697/3370	Loss:0.636
Batch: 3034/3370	Loss:0.385
Batch: 3370/3370	Loss:1.302
Epoch: 5	Train Loss: 0.382	Val F1: 0.680
Best Epoch: 2	Best Epoch Val F1: 0.704

******************************Epoch: 6******************************
Batch: 1/3370	Loss:0.068
Batch: 338/3370	Loss:0.061
Batch: 675/3370	Loss:0.324
Batch: 1012/3370	Loss:0.102
Batch: 1349/3370	Loss:0.141
Batch: 1686/3370	Loss:0.426
Batch: 2023/3370	Loss:0.044
Batch: 2360/3370	Loss:0.369
Batch: 2697/3370	Loss:0.193
Batch: 3034/3370	Loss:0.821
Batch: 3370/3370	Loss:0.000
Epoch: 6	Train Loss: 0.342	Val F1: 0.691
Best Epoch: 2	Best Epoch Val F1: 0.704

******************************Epoch: 7******************************
Batch: 1/3370	Loss:0.072
Batch: 338/3370	Loss:0.132
Batch: 675/3370	Loss:0.247
Batch: 1012/3370	Loss:0.035
Batch: 1349/3370	Loss:0.034
Batch: 1686/3370	Loss:1.213
Batch: 2023/3370	Loss:0.610
Batch: 2360/3370	Loss:0.139
Batch: 2697/3370	Loss:0.326
Batch: 3034/3370	Loss:0.279
Batch: 3370/3370	Loss:0.005
Epoch: 7	Train Loss: 0.315	Val F1: 0.691
Best Epoch: 2	Best Epoch Val F1: 0.704

Saving the best checkpoint....
Inference...
Test F1: 0.739	Test F1_Few: 0.748	Test F1_Zero: 0.728
Starting training with config: {'batch_size': 32, 'epochs': 50, 'l2_reg': 4.632929921117104e-05, 'lr': 3.699609113886629e-05, 'n_layers_freeze': 4, 'patience': 15}
Let's use 1 GPUs!
Preparing data....
Training data....
# of train examples: 13477
max len: 512, max len wiki: 1
Val data....
# of val examples: 2062
max len: 512, max len wiki: 1
Test data....
# of test examples: 3006
max len: 512, max len wiki: 1
Done

Initializing model....
******************************Epoch: 1******************************
Batch: 1/422	Loss:1.244
Batch: 43/422	Loss:1.091
Batch: 85/422	Loss:1.145
Batch: 127/422	Loss:1.068
Batch: 169/422	Loss:1.056
Batch: 211/422	Loss:0.953
Batch: 253/422	Loss:0.503
Batch: 295/422	Loss:0.896
Batch: 337/422	Loss:0.782
Batch: 379/422	Loss:0.563
Batch: 421/422	Loss:0.698
Batch: 422/422	Loss:0.901
Epoch: 1	Train Loss: 0.905	Val F1: 0.658
Best Epoch: 1	Best Epoch Val F1: 0.658

******************************Epoch: 2******************************
Batch: 1/422	Loss:0.638
Batch: 43/422	Loss:0.845
Batch: 85/422	Loss:0.579
Batch: 127/422	Loss:0.634
Batch: 169/422	Loss:0.634
Batch: 211/422	Loss:0.782
Batch: 253/422	Loss:0.567
Batch: 295/422	Loss:0.612
Batch: 337/422	Loss:0.690
Batch: 379/422	Loss:0.489
Batch: 421/422	Loss:0.503
Batch: 422/422	Loss:0.356
Epoch: 2	Train Loss: 0.588	Val F1: 0.706
Best Epoch: 2	Best Epoch Val F1: 0.706

******************************Epoch: 3******************************
Batch: 1/422	Loss:0.499
Batch: 43/422	Loss:0.611
Batch: 85/422	Loss:0.592
Batch: 127/422	Loss:0.560
Batch: 169/422	Loss:0.418
Batch: 211/422	Loss:0.637
Batch: 253/422	Loss:0.466
Batch: 295/422	Loss:0.705
Batch: 337/422	Loss:0.398
Batch: 379/422	Loss:0.555
Batch: 421/422	Loss:0.405
Batch: 422/422	Loss:0.247
Epoch: 3	Train Loss: 0.487	Val F1: 0.753
Best Epoch: 3	Best Epoch Val F1: 0.753

******************************Epoch: 4******************************
Batch: 1/422	Loss:0.359
Batch: 43/422	Loss:0.509
Batch: 85/422	Loss:0.434
Batch: 127/422	Loss:0.405
Batch: 169/422	Loss:0.489
Batch: 211/422	Loss:0.452
Batch: 253/422	Loss:0.378
Batch: 295/422	Loss:0.272
Batch: 337/422	Loss:0.485
Batch: 379/422	Loss:0.478
Batch: 421/422	Loss:0.299
Batch: 422/422	Loss:0.804
Epoch: 4	Train Loss: 0.417	Val F1: 0.698
Best Epoch: 3	Best Epoch Val F1: 0.753

******************************Epoch: 5******************************
Batch: 1/422	Loss:0.350
Batch: 43/422	Loss:0.269
Batch: 85/422	Loss:0.311
Batch: 127/422	Loss:0.284
Batch: 169/422	Loss:0.514
Batch: 211/422	Loss:0.443
Batch: 253/422	Loss:0.251
Batch: 295/422	Loss:0.341
Batch: 337/422	Loss:0.324
Batch: 379/422	Loss:0.264
Batch: 421/422	Loss:0.428
Batch: 422/422	Loss:0.540
Epoch: 5	Train Loss: 0.367	Val F1: 0.694
Best Epoch: 3	Best Epoch Val F1: 0.753

******************************Epoch: 6******************************
Batch: 1/422	Loss:0.228
Batch: 43/422	Loss:0.316
Batch: 85/422	Loss:0.383
Batch: 127/422	Loss:0.304
Batch: 169/422	Loss:0.374
Batch: 211/422	Loss:0.402
Batch: 253/422	Loss:0.198
Batch: 295/422	Loss:0.336
Batch: 337/422	Loss:0.457
Batch: 379/422	Loss:0.309
Batch: 421/422	Loss:0.236
Batch: 422/422	Loss:0.112
Epoch: 6	Train Loss: 0.320	Val F1: 0.717
Best Epoch: 3	Best Epoch Val F1: 0.753

******************************Epoch: 7******************************
Batch: 1/422	Loss:0.267
Batch: 43/422	Loss:0.238
Batch: 85/422	Loss:0.346
Batch: 127/422	Loss:0.241
Batch: 169/422	Loss:0.787
Batch: 211/422	Loss:0.500
Batch: 253/422	Loss:0.361
Batch: 295/422	Loss:0.338
Batch: 337/422	Loss:0.499
Batch: 379/422	Loss:0.479
Batch: 421/422	Loss:0.444
Batch: 422/422	Loss:0.257
Epoch: 7	Train Loss: 0.287	Val F1: 0.714
Best Epoch: 3	Best Epoch Val F1: 0.753

******************************Epoch: 8******************************
Batch: 1/422	Loss:0.211
Batch: 43/422	Loss:0.358
Batch: 85/422	Loss:0.148
Batch: 127/422	Loss:0.305
Batch: 169/422	Loss:0.239
Batch: 211/422	Loss:0.151
Batch: 253/422	Loss:0.464
Batch: 295/422	Loss:0.219
Batch: 337/422	Loss:0.204
Batch: 379/422	Loss:0.150
Batch: 421/422	Loss:0.520
Batch: 422/422	Loss:0.142
Epoch: 8	Train Loss: 0.249	Val F1: 0.695
Best Epoch: 3	Best Epoch Val F1: 0.753

******************************Epoch: 9******************************
Batch: 1/422	Loss:0.309
Batch: 43/422	Loss:0.183
Batch: 85/422	Loss:0.217
Batch: 127/422	Loss:0.300
Batch: 169/422	Loss:0.139
Batch: 211/422	Loss:0.273
Batch: 253/422	Loss:0.275
Batch: 295/422	Loss:0.296
Batch: 337/422	Loss:0.175
Batch: 379/422	Loss:0.158
Batch: 421/422	Loss:0.131
Batch: 422/422	Loss:0.433
Epoch: 9	Train Loss: 0.226	Val F1: 0.713
Best Epoch: 3	Best Epoch Val F1: 0.753

******************************Epoch: 10******************************
Batch: 1/422	Loss:0.195
Batch: 43/422	Loss:0.281
Batch: 85/422	Loss:0.156
Batch: 127/422	Loss:0.044
Batch: 169/422	Loss:0.085
Batch: 211/422	Loss:0.160
Batch: 253/422	Loss:0.243
Batch: 295/422	Loss:0.152
Batch: 337/422	Loss:0.075
Batch: 379/422	Loss:0.250
Batch: 421/422	Loss:0.143
Batch: 422/422	Loss:0.128
Epoch: 10	Train Loss: 0.205	Val F1: 0.721
Best Epoch: 3	Best Epoch Val F1: 0.753

******************************Epoch: 11******************************
Batch: 1/422	Loss:0.144
Batch: 43/422	Loss:0.238
Batch: 85/422	Loss:0.116
Batch: 127/422	Loss:0.341
Batch: 169/422	Loss:0.190
Batch: 211/422	Loss:0.095
Batch: 253/422	Loss:0.269
Batch: 295/422	Loss:0.095
Batch: 337/422	Loss:0.343
Batch: 379/422	Loss:0.039
Batch: 421/422	Loss:0.162
Batch: 422/422	Loss:0.057
Epoch: 11	Train Loss: 0.184	Val F1: 0.703
Best Epoch: 3	Best Epoch Val F1: 0.753

******************************Epoch: 12******************************
Batch: 1/422	Loss:0.201
Batch: 43/422	Loss:0.083
Batch: 85/422	Loss:0.100
Batch: 127/422	Loss:0.230
Batch: 169/422	Loss:0.121
Batch: 211/422	Loss:0.187
Batch: 253/422	Loss:0.233
Batch: 295/422	Loss:0.106
Batch: 337/422	Loss:0.081
Batch: 379/422	Loss:0.197
Batch: 421/422	Loss:0.255
Batch: 422/422	Loss:0.001
Epoch: 12	Train Loss: 0.170	Val F1: 0.717
Best Epoch: 3	Best Epoch Val F1: 0.753

******************************Epoch: 13******************************
Batch: 1/422	Loss:0.170
Batch: 43/422	Loss:0.137
Batch: 85/422	Loss:0.150
Batch: 127/422	Loss:0.088
Batch: 169/422	Loss:0.082
Batch: 211/422	Loss:0.141
Batch: 253/422	Loss:0.160
Batch: 295/422	Loss:0.213
Batch: 337/422	Loss:0.182
Batch: 379/422	Loss:0.340
Batch: 421/422	Loss:0.085
Batch: 422/422	Loss:0.041
Epoch: 13	Train Loss: 0.157	Val F1: 0.710
Best Epoch: 3	Best Epoch Val F1: 0.753

******************************Epoch: 14******************************
Batch: 1/422	Loss:0.085
Batch: 43/422	Loss:0.132
Batch: 85/422	Loss:0.108
Batch: 127/422	Loss:0.143
Batch: 169/422	Loss:0.072
Batch: 211/422	Loss:0.081
Batch: 253/422	Loss:0.074
Batch: 295/422	Loss:0.053
Batch: 337/422	Loss:0.228
Batch: 379/422	Loss:0.189
Batch: 421/422	Loss:0.165
Batch: 422/422	Loss:0.030
Epoch: 14	Train Loss: 0.151	Val F1: 0.703
Best Epoch: 3	Best Epoch Val F1: 0.753

******************************Epoch: 15******************************
Batch: 1/422	Loss:0.074
Batch: 43/422	Loss:0.066
Batch: 85/422	Loss:0.067
Batch: 127/422	Loss:0.169
Batch: 169/422	Loss:0.094
Batch: 211/422	Loss:0.030
Batch: 253/422	Loss:0.208
Batch: 295/422	Loss:0.107
Batch: 337/422	Loss:0.115
Batch: 379/422	Loss:0.169
Batch: 421/422	Loss:0.146
Batch: 422/422	Loss:0.029
Epoch: 15	Train Loss: 0.139	Val F1: 0.719
Best Epoch: 3	Best Epoch Val F1: 0.753

******************************Epoch: 16******************************
Batch: 1/422	Loss:0.061
Batch: 43/422	Loss:0.126
Batch: 85/422	Loss:0.127
Batch: 127/422	Loss:0.119
Batch: 169/422	Loss:0.194
Batch: 211/422	Loss:0.050
Batch: 253/422	Loss:0.106
Batch: 295/422	Loss:0.062
Batch: 337/422	Loss:0.078
Batch: 379/422	Loss:0.245
Batch: 421/422	Loss:0.283
Batch: 422/422	Loss:0.152
Epoch: 16	Train Loss: 0.138	Val F1: 0.696
Best Epoch: 3	Best Epoch Val F1: 0.753

******************************Epoch: 17******************************
Batch: 1/422	Loss:0.041
Batch: 43/422	Loss:0.190
Batch: 85/422	Loss:0.069
Batch: 127/422	Loss:0.087
Batch: 169/422	Loss:0.069
Batch: 211/422	Loss:0.067
Batch: 253/422	Loss:0.178
Batch: 295/422	Loss:0.086
Batch: 337/422	Loss:0.098
Batch: 379/422	Loss:0.113
Batch: 421/422	Loss:0.039
Batch: 422/422	Loss:0.001
Epoch: 17	Train Loss: 0.131	Val F1: 0.728
Best Epoch: 3	Best Epoch Val F1: 0.753

******************************Epoch: 18******************************
Batch: 1/422	Loss:0.113
Batch: 43/422	Loss:0.053
Batch: 85/422	Loss:0.151
Batch: 127/422	Loss:0.097
Batch: 169/422	Loss:0.183
Batch: 211/422	Loss:0.173
Batch: 253/422	Loss:0.116
Batch: 295/422	Loss:0.107
Batch: 337/422	Loss:0.039
Batch: 379/422	Loss:0.103
Batch: 421/422	Loss:0.206
Batch: 422/422	Loss:0.030
Epoch: 18	Train Loss: 0.117	Val F1: 0.697
Best Epoch: 3	Best Epoch Val F1: 0.753

Saving the best checkpoint....
Inference...
Test F1: 0.734	Test F1_Few: 0.756	Test F1_Zero: 0.710
Starting training with config: {'batch_size': 8, 'epochs': 75, 'l2_reg': 4.673699971346352e-05, 'lr': 9.634512316843116e-06, 'n_layers_freeze': 2, 'patience': 15}
Let's use 1 GPUs!
Preparing data....
Training data....
# of train examples: 13477
max len: 512, max len wiki: 1
Val data....
# of val examples: 2062
max len: 512, max len wiki: 1
Test data....
# of test examples: 3006
max len: 512, max len wiki: 1
Done

Initializing model....
******************************Epoch: 1******************************
Batch: 1/1685	Loss:1.082
Batch: 169/1685	Loss:1.112
Batch: 337/1685	Loss:1.156
Batch: 505/1685	Loss:0.979
Batch: 673/1685	Loss:0.731
Batch: 841/1685	Loss:0.672
Batch: 1009/1685	Loss:0.484
Batch: 1177/1685	Loss:0.423
Batch: 1345/1685	Loss:0.874
Batch: 1513/1685	Loss:0.829
Batch: 1681/1685	Loss:0.710
Batch: 1685/1685	Loss:0.934
Epoch: 1	Train Loss: 0.845	Val F1: 0.677
Best Epoch: 1	Best Epoch Val F1: 0.677

******************************Epoch: 2******************************
Batch: 1/1685	Loss:0.386
Batch: 169/1685	Loss:1.089
Batch: 337/1685	Loss:0.813
Batch: 505/1685	Loss:0.392
Batch: 673/1685	Loss:0.385
Batch: 841/1685	Loss:1.083
Batch: 1009/1685	Loss:0.481
Batch: 1177/1685	Loss:0.423
Batch: 1345/1685	Loss:0.581
Batch: 1513/1685	Loss:0.712
Batch: 1681/1685	Loss:0.483
Batch: 1685/1685	Loss:0.333
Epoch: 2	Train Loss: 0.584	Val F1: 0.707
Best Epoch: 2	Best Epoch Val F1: 0.707

******************************Epoch: 3******************************
Batch: 1/1685	Loss:0.387
Batch: 169/1685	Loss:0.386
Batch: 337/1685	Loss:0.532
Batch: 505/1685	Loss:0.190
Batch: 673/1685	Loss:0.436
Batch: 841/1685	Loss:1.097
Batch: 1009/1685	Loss:0.392
Batch: 1177/1685	Loss:0.423
Batch: 1345/1685	Loss:0.168
Batch: 1513/1685	Loss:0.523
Batch: 1681/1685	Loss:0.465
Batch: 1685/1685	Loss:0.091
Epoch: 3	Train Loss: 0.487	Val F1: 0.708
Best Epoch: 3	Best Epoch Val F1: 0.708

******************************Epoch: 4******************************
Batch: 1/1685	Loss:0.198
Batch: 169/1685	Loss:0.713
Batch: 337/1685	Loss:0.392
Batch: 505/1685	Loss:0.670
Batch: 673/1685	Loss:0.294
Batch: 841/1685	Loss:0.307
Batch: 1009/1685	Loss:0.590
Batch: 1177/1685	Loss:0.512
Batch: 1345/1685	Loss:0.714
Batch: 1513/1685	Loss:0.167
Batch: 1681/1685	Loss:0.224
Batch: 1685/1685	Loss:0.877
Epoch: 4	Train Loss: 0.418	Val F1: 0.695
Best Epoch: 3	Best Epoch Val F1: 0.708

******************************Epoch: 5******************************
Batch: 1/1685	Loss:0.423
Batch: 169/1685	Loss:0.217
Batch: 337/1685	Loss:0.297
Batch: 505/1685	Loss:0.062
Batch: 673/1685	Loss:0.715
Batch: 841/1685	Loss:0.282
Batch: 1009/1685	Loss:0.276
Batch: 1177/1685	Loss:0.543
Batch: 1345/1685	Loss:0.581
Batch: 1513/1685	Loss:0.369
Batch: 1681/1685	Loss:0.314
Batch: 1685/1685	Loss:0.596
Epoch: 5	Train Loss: 0.373	Val F1: 0.686
Best Epoch: 3	Best Epoch Val F1: 0.708

******************************Epoch: 6******************************
Batch: 1/1685	Loss:0.089
Batch: 169/1685	Loss:0.086
Batch: 337/1685	Loss:0.108
Batch: 505/1685	Loss:0.277
Batch: 673/1685	Loss:0.172
Batch: 841/1685	Loss:0.293
Batch: 1009/1685	Loss:0.221
Batch: 1177/1685	Loss:0.205
Batch: 1345/1685	Loss:0.350
Batch: 1513/1685	Loss:0.291
Batch: 1681/1685	Loss:0.255
Batch: 1685/1685	Loss:0.017
Epoch: 6	Train Loss: 0.332	Val F1: 0.708
Best Epoch: 3	Best Epoch Val F1: 0.708

******************************Epoch: 7******************************
Batch: 1/1685	Loss:0.284
Batch: 169/1685	Loss:0.193
Batch: 337/1685	Loss:0.224
Batch: 505/1685	Loss:0.183
Batch: 673/1685	Loss:0.591
Batch: 841/1685	Loss:0.228
Batch: 1009/1685	Loss:0.320
Batch: 1177/1685	Loss:0.306
Batch: 1345/1685	Loss:0.199
Batch: 1513/1685	Loss:0.596
Batch: 1681/1685	Loss:0.136
Batch: 1685/1685	Loss:0.131
Epoch: 7	Train Loss: 0.301	Val F1: 0.695
Best Epoch: 3	Best Epoch Val F1: 0.708

******************************Epoch: 8******************************
Batch: 1/1685	Loss:0.134
Batch: 169/1685	Loss:0.154
Batch: 337/1685	Loss:0.024
Batch: 505/1685	Loss:0.399
Batch: 673/1685	Loss:0.255
Batch: 841/1685	Loss:0.091
Batch: 1009/1685	Loss:0.576
Batch: 1177/1685	Loss:0.326
Batch: 1345/1685	Loss:0.071
Batch: 1513/1685	Loss:0.705
Batch: 1681/1685	Loss:0.423
Batch: 1685/1685	Loss:0.365
Epoch: 8	Train Loss: 0.269	Val F1: 0.666
Best Epoch: 3	Best Epoch Val F1: 0.708

******************************Epoch: 9******************************
Batch: 1/1685	Loss:0.270
Batch: 169/1685	Loss:0.317
Batch: 337/1685	Loss:0.199
Batch: 505/1685	Loss:0.345
Batch: 673/1685	Loss:0.344
Batch: 841/1685	Loss:0.425
Batch: 1009/1685	Loss:0.299
Batch: 1177/1685	Loss:0.270
Batch: 1345/1685	Loss:0.362
Batch: 1513/1685	Loss:0.118
Batch: 1681/1685	Loss:0.041
Batch: 1685/1685	Loss:0.410
Epoch: 9	Train Loss: 0.239	Val F1: 0.699
Best Epoch: 3	Best Epoch Val F1: 0.708

******************************Epoch: 10******************************
Batch: 1/1685	Loss:0.370
Batch: 169/1685	Loss:0.244
Batch: 337/1685	Loss:0.268
Batch: 505/1685	Loss:0.065
Batch: 673/1685	Loss:0.118
Batch: 841/1685	Loss:0.119
Batch: 1009/1685	Loss:0.466
Batch: 1177/1685	Loss:0.040
Batch: 1345/1685	Loss:0.044
Batch: 1513/1685	Loss:0.135
Batch: 1681/1685	Loss:0.032
Batch: 1685/1685	Loss:0.182
Epoch: 10	Train Loss: 0.218	Val F1: 0.720
Best Epoch: 10	Best Epoch Val F1: 0.720

******************************Epoch: 11******************************
Batch: 1/1685	Loss:0.345
Batch: 169/1685	Loss:0.534
Batch: 337/1685	Loss:0.244
Batch: 505/1685	Loss:0.120
Batch: 673/1685	Loss:0.140
Batch: 841/1685	Loss:0.372
Batch: 1009/1685	Loss:0.151
Batch: 1177/1685	Loss:0.144
Batch: 1345/1685	Loss:0.531
Batch: 1513/1685	Loss:0.051
Batch: 1681/1685	Loss:0.143
Batch: 1685/1685	Loss:0.028
Epoch: 11	Train Loss: 0.199	Val F1: 0.702
Best Epoch: 10	Best Epoch Val F1: 0.720

******************************Epoch: 12******************************
Batch: 1/1685	Loss:0.142
Batch: 169/1685	Loss:0.195
Batch: 337/1685	Loss:0.308
Batch: 505/1685	Loss:0.503
Batch: 673/1685	Loss:0.130
Batch: 841/1685	Loss:0.538
Batch: 1009/1685	Loss:0.618
Batch: 1177/1685	Loss:0.112
Batch: 1345/1685	Loss:0.028
Batch: 1513/1685	Loss:0.036
Batch: 1681/1685	Loss:0.072
Batch: 1685/1685	Loss:0.006
Epoch: 12	Train Loss: 0.188	Val F1: 0.701
Best Epoch: 10	Best Epoch Val F1: 0.720

******************************Epoch: 13******************************
Batch: 1/1685	Loss:0.214
Batch: 169/1685	Loss:0.023
Batch: 337/1685	Loss:0.296
Batch: 505/1685	Loss:0.093
Batch: 673/1685	Loss:0.008
Batch: 841/1685	Loss:0.076
Batch: 1009/1685	Loss:0.150
Batch: 1177/1685	Loss:0.056
Batch: 1345/1685	Loss:0.117
Batch: 1513/1685	Loss:0.285
Batch: 1681/1685	Loss:0.202
Batch: 1685/1685	Loss:0.057
Epoch: 13	Train Loss: 0.175	Val F1: 0.679
Best Epoch: 10	Best Epoch Val F1: 0.720

******************************Epoch: 14******************************
Batch: 1/1685	Loss:0.521
Batch: 169/1685	Loss:0.043
Batch: 337/1685	Loss:0.006
Batch: 505/1685	Loss:0.167
Batch: 673/1685	Loss:0.237
Batch: 841/1685	Loss:0.367
Batch: 1009/1685	Loss:0.062
Batch: 1177/1685	Loss:0.088
Batch: 1345/1685	Loss:0.113
Batch: 1513/1685	Loss:0.038
Batch: 1681/1685	Loss:0.562
Batch: 1685/1685	Loss:0.048
Epoch: 14	Train Loss: 0.160	Val F1: 0.693
Best Epoch: 10	Best Epoch Val F1: 0.720

******************************Epoch: 15******************************
Batch: 1/1685	Loss:0.017
Batch: 169/1685	Loss:0.017
Batch: 337/1685	Loss:0.009
Batch: 505/1685	Loss:0.048
Batch: 673/1685	Loss:0.116
Batch: 841/1685	Loss:0.005
Batch: 1009/1685	Loss:0.204
Batch: 1177/1685	Loss:0.029
Batch: 1345/1685	Loss:0.143
Batch: 1513/1685	Loss:0.120
Batch: 1681/1685	Loss:0.124
Batch: 1685/1685	Loss:0.002
Epoch: 15	Train Loss: 0.152	Val F1: 0.693
Best Epoch: 10	Best Epoch Val F1: 0.720

******************************Epoch: 16******************************
Batch: 1/1685	Loss:0.067
Batch: 169/1685	Loss:0.257
Batch: 337/1685	Loss:0.202
Batch: 505/1685	Loss:0.421
Batch: 673/1685	Loss:0.587
Batch: 841/1685	Loss:0.151
Batch: 1009/1685	Loss:0.086
Batch: 1177/1685	Loss:0.008
Batch: 1345/1685	Loss:0.043
Batch: 1513/1685	Loss:0.089
Batch: 1681/1685	Loss:0.055
Batch: 1685/1685	Loss:0.021
Epoch: 16	Train Loss: 0.143	Val F1: 0.683
Best Epoch: 10	Best Epoch Val F1: 0.720

******************************Epoch: 17******************************
Batch: 1/1685	Loss:0.076
Batch: 169/1685	Loss:0.192
Batch: 337/1685	Loss:0.138
Batch: 505/1685	Loss:0.070
Batch: 673/1685	Loss:0.072
Batch: 841/1685	Loss:0.076
Batch: 1009/1685	Loss:0.190
Batch: 1177/1685	Loss:0.014
Batch: 1345/1685	Loss:0.193
Batch: 1513/1685	Loss:0.382
Batch: 1681/1685	Loss:0.167
Batch: 1685/1685	Loss:0.005
Epoch: 17	Train Loss: 0.138	Val F1: 0.693
Best Epoch: 10	Best Epoch Val F1: 0.720

******************************Epoch: 18******************************
Batch: 1/1685	Loss:0.016
Batch: 169/1685	Loss:0.091
Batch: 337/1685	Loss:0.205
Batch: 505/1685	Loss:0.200
Batch: 673/1685	Loss:0.132
Batch: 841/1685	Loss:0.186
Batch: 1009/1685	Loss:0.001
Batch: 1177/1685	Loss:0.155
Batch: 1345/1685	Loss:0.011
Batch: 1513/1685	Loss:0.044
Batch: 1681/1685	Loss:0.074
Batch: 1685/1685	Loss:0.292
Epoch: 18	Train Loss: 0.128	Val F1: 0.707
Best Epoch: 10	Best Epoch Val F1: 0.720

******************************Epoch: 19******************************
Batch: 1/1685	Loss:0.307
Batch: 169/1685	Loss:0.001
Batch: 337/1685	Loss:0.241
Batch: 505/1685	Loss:0.158
Batch: 673/1685	Loss:0.039
Batch: 841/1685	Loss:0.128
Batch: 1009/1685	Loss:0.170
Batch: 1177/1685	Loss:0.116
Batch: 1345/1685	Loss:0.083
Batch: 1513/1685	Loss:0.067
Batch: 1681/1685	Loss:0.001
Batch: 1685/1685	Loss:0.083
Epoch: 19	Train Loss: 0.125	Val F1: 0.703
Best Epoch: 10	Best Epoch Val F1: 0.720

******************************Epoch: 20******************************
Batch: 1/1685	Loss:0.003
Batch: 169/1685	Loss:0.559
Batch: 337/1685	Loss:0.157
Batch: 505/1685	Loss:0.054
Batch: 673/1685	Loss:0.233
Batch: 841/1685	Loss:0.094
Batch: 1009/1685	Loss:0.116
Batch: 1177/1685	Loss:0.096
Batch: 1345/1685	Loss:0.004
Batch: 1513/1685	Loss:0.051
Batch: 1681/1685	Loss:0.119
Batch: 1685/1685	Loss:0.013
Epoch: 20	Train Loss: 0.123	Val F1: 0.705
Best Epoch: 10	Best Epoch Val F1: 0.720

******************************Epoch: 21******************************
Batch: 1/1685	Loss:0.002
Batch: 169/1685	Loss:0.069
Batch: 337/1685	Loss:0.037
Batch: 505/1685	Loss:0.096
Batch: 673/1685	Loss:0.059
Batch: 841/1685	Loss:0.071
Batch: 1009/1685	Loss:0.061
Batch: 1177/1685	Loss:0.192
Batch: 1345/1685	Loss:0.012
Batch: 1513/1685	Loss:0.097
Batch: 1681/1685	Loss:0.007
Batch: 1685/1685	Loss:0.148
Epoch: 21	Train Loss: 0.116	Val F1: 0.673
Best Epoch: 10	Best Epoch Val F1: 0.720

******************************Epoch: 22******************************
Batch: 1/1685	Loss:0.030
Batch: 169/1685	Loss:0.010
Batch: 337/1685	Loss:0.001
Batch: 505/1685	Loss:0.006
Batch: 673/1685	Loss:0.133
Batch: 841/1685	Loss:0.005
Batch: 1009/1685	Loss:0.392
Batch: 1177/1685	Loss:0.205
Batch: 1345/1685	Loss:0.096
Batch: 1513/1685	Loss:0.025
Batch: 1681/1685	Loss:0.062
Batch: 1685/1685	Loss:0.233
Epoch: 22	Train Loss: 0.114	Val F1: 0.709
Best Epoch: 10	Best Epoch Val F1: 0.720

******************************Epoch: 23******************************
Batch: 1/1685	Loss:0.439
Batch: 169/1685	Loss:0.004
Batch: 337/1685	Loss:0.357
Batch: 505/1685	Loss:0.011
Batch: 673/1685	Loss:0.013
Batch: 841/1685	Loss:0.002
Batch: 1009/1685	Loss:0.005
Batch: 1177/1685	Loss:0.173
Batch: 1345/1685	Loss:0.240
Batch: 1513/1685	Loss:0.082
Batch: 1681/1685	Loss:0.085
Batch: 1685/1685	Loss:0.147
Epoch: 23	Train Loss: 0.111	Val F1: 0.686
Best Epoch: 10	Best Epoch Val F1: 0.720

******************************Epoch: 24******************************
Batch: 1/1685	Loss:0.113
Batch: 169/1685	Loss:0.008
Batch: 337/1685	Loss:0.002
Batch: 505/1685	Loss:0.000
Batch: 673/1685	Loss:0.028
Batch: 841/1685	Loss:0.186
Batch: 1009/1685	Loss:0.136
Batch: 1177/1685	Loss:0.009
Batch: 1345/1685	Loss:0.230
Batch: 1513/1685	Loss:0.012
Batch: 1681/1685	Loss:0.037
Batch: 1685/1685	Loss:0.008
Epoch: 24	Train Loss: 0.109	Val F1: 0.697
Best Epoch: 10	Best Epoch Val F1: 0.720

******************************Epoch: 25******************************
Batch: 1/1685	Loss:0.134
Batch: 169/1685	Loss:0.021
Batch: 337/1685	Loss:0.025
Batch: 505/1685	Loss:0.126
Batch: 673/1685	Loss:0.177
Batch: 841/1685	Loss:0.001
Batch: 1009/1685	Loss:0.030
Batch: 1177/1685	Loss:0.062
Batch: 1345/1685	Loss:0.004
Batch: 1513/1685	Loss:0.022
Batch: 1681/1685	Loss:0.136
Batch: 1685/1685	Loss:0.006
Epoch: 25	Train Loss: 0.104	Val F1: 0.705
Best Epoch: 10	Best Epoch Val F1: 0.720

Saving the best checkpoint....
Inference...
Test F1: 0.729	Test F1_Few: 0.740	Test F1_Zero: 0.718
Starting training with config: {'batch_size': 8, 'epochs': 50, 'l2_reg': 8.121029538775144e-05, 'lr': 3.826037064972067e-05, 'n_layers_freeze': 4, 'patience': 15}
Let's use 1 GPUs!
Preparing data....
Training data....
# of train examples: 13477
max len: 512, max len wiki: 1
Val data....
# of val examples: 2062
max len: 512, max len wiki: 1
Test data....
# of test examples: 3006
max len: 512, max len wiki: 1
Done

Initializing model....
******************************Epoch: 1******************************
Batch: 1/1685	Loss:1.082
Batch: 169/1685	Loss:1.102
Batch: 337/1685	Loss:1.113
Batch: 505/1685	Loss:1.240
Batch: 673/1685	Loss:0.667
Batch: 841/1685	Loss:0.621
Batch: 1009/1685	Loss:0.434
Batch: 1177/1685	Loss:0.464
Batch: 1345/1685	Loss:0.848
Batch: 1513/1685	Loss:0.833
Batch: 1681/1685	Loss:0.842
Batch: 1685/1685	Loss:1.045
Epoch: 1	Train Loss: 0.778	Val F1: 0.621
Best Epoch: 1	Best Epoch Val F1: 0.621

******************************Epoch: 2******************************
Batch: 1/1685	Loss:0.358
Batch: 169/1685	Loss:1.067
Batch: 337/1685	Loss:0.814
Batch: 505/1685	Loss:0.434
Batch: 673/1685	Loss:0.492
Batch: 841/1685	Loss:0.989
Batch: 1009/1685	Loss:0.478
Batch: 1177/1685	Loss:0.471
Batch: 1345/1685	Loss:0.505
Batch: 1513/1685	Loss:0.758
Batch: 1681/1685	Loss:0.208
Batch: 1685/1685	Loss:0.444
Epoch: 2	Train Loss: 0.604	Val F1: 0.683
Best Epoch: 2	Best Epoch Val F1: 0.683

******************************Epoch: 3******************************
Batch: 1/1685	Loss:0.382
Batch: 169/1685	Loss:0.602
Batch: 337/1685	Loss:0.285
Batch: 505/1685	Loss:0.278
Batch: 673/1685	Loss:0.739
Batch: 841/1685	Loss:1.303
Batch: 1009/1685	Loss:0.387
Batch: 1177/1685	Loss:0.314
Batch: 1345/1685	Loss:0.142
Batch: 1513/1685	Loss:0.545
Batch: 1681/1685	Loss:0.424
Batch: 1685/1685	Loss:0.705
Epoch: 3	Train Loss: 0.518	Val F1: 0.699
Best Epoch: 3	Best Epoch Val F1: 0.699

******************************Epoch: 4******************************
Batch: 1/1685	Loss:0.239
Batch: 169/1685	Loss:0.854
Batch: 337/1685	Loss:0.339
Batch: 505/1685	Loss:0.673
Batch: 673/1685	Loss:0.414
Batch: 841/1685	Loss:0.378
Batch: 1009/1685	Loss:0.686
Batch: 1177/1685	Loss:0.496
Batch: 1345/1685	Loss:0.601
Batch: 1513/1685	Loss:0.165
Batch: 1681/1685	Loss:0.358
Batch: 1685/1685	Loss:0.724
Epoch: 4	Train Loss: 0.453	Val F1: 0.666
Best Epoch: 3	Best Epoch Val F1: 0.699

******************************Epoch: 5******************************
Batch: 1/1685	Loss:0.588
Batch: 169/1685	Loss:0.348
Batch: 337/1685	Loss:0.445
Batch: 505/1685	Loss:0.185
Batch: 673/1685	Loss:0.703
Batch: 841/1685	Loss:0.382
Batch: 1009/1685	Loss:0.183
Batch: 1177/1685	Loss:0.483
Batch: 1345/1685	Loss:0.410
Batch: 1513/1685	Loss:0.291
Batch: 1681/1685	Loss:0.518
Batch: 1685/1685	Loss:0.610
Epoch: 5	Train Loss: 0.408	Val F1: 0.662
Best Epoch: 3	Best Epoch Val F1: 0.699

******************************Epoch: 6******************************
Batch: 1/1685	Loss:0.254
Batch: 169/1685	Loss:0.059
Batch: 337/1685	Loss:0.123
Batch: 505/1685	Loss:0.479
Batch: 673/1685	Loss:0.381
Batch: 841/1685	Loss:0.701
Batch: 1009/1685	Loss:0.450
Batch: 1177/1685	Loss:0.491
Batch: 1345/1685	Loss:0.867
Batch: 1513/1685	Loss:0.231
Batch: 1681/1685	Loss:0.242
Batch: 1685/1685	Loss:0.062
Epoch: 6	Train Loss: 0.374	Val F1: 0.698
Best Epoch: 3	Best Epoch Val F1: 0.699

******************************Epoch: 7******************************
Batch: 1/1685	Loss:0.247
Batch: 169/1685	Loss:0.046
Batch: 337/1685	Loss:0.680
Batch: 505/1685	Loss:0.344
Batch: 673/1685	Loss:0.224
Batch: 841/1685	Loss:0.256
Batch: 1009/1685	Loss:0.398
Batch: 1177/1685	Loss:0.478
Batch: 1345/1685	Loss:0.271
Batch: 1513/1685	Loss:0.473
Batch: 1681/1685	Loss:0.294
Batch: 1685/1685	Loss:0.167
Epoch: 7	Train Loss: 0.345	Val F1: 0.680
Best Epoch: 3	Best Epoch Val F1: 0.699

******************************Epoch: 8******************************
Batch: 1/1685	Loss:0.187
Batch: 169/1685	Loss:0.509
Batch: 337/1685	Loss:0.013
Batch: 505/1685	Loss:0.355
Batch: 673/1685	Loss:0.383
Batch: 841/1685	Loss:0.681
Batch: 1009/1685	Loss:0.614
Batch: 1177/1685	Loss:0.494
Batch: 1345/1685	Loss:0.125
Batch: 1513/1685	Loss:0.240
Batch: 1681/1685	Loss:0.255
Batch: 1685/1685	Loss:0.341
Epoch: 8	Train Loss: 0.307	Val F1: 0.664
Best Epoch: 3	Best Epoch Val F1: 0.699

******************************Epoch: 9******************************
Batch: 1/1685	Loss:0.327
Batch: 169/1685	Loss:0.331
Batch: 337/1685	Loss:1.183
Batch: 505/1685	Loss:0.389
Batch: 673/1685	Loss:0.188
Batch: 841/1685	Loss:0.873
Batch: 1009/1685	Loss:0.240
Batch: 1177/1685	Loss:0.250
Batch: 1345/1685	Loss:0.665
Batch: 1513/1685	Loss:0.085
Batch: 1681/1685	Loss:0.087
Batch: 1685/1685	Loss:0.179
Epoch: 9	Train Loss: 0.289	Val F1: 0.701
Best Epoch: 9	Best Epoch Val F1: 0.701

******************************Epoch: 10******************************
Batch: 1/1685	Loss:0.206
Batch: 169/1685	Loss:0.253
Batch: 337/1685	Loss:0.226
Batch: 505/1685	Loss:0.060
Batch: 673/1685	Loss:0.074
Batch: 841/1685	Loss:0.223
Batch: 1009/1685	Loss:0.313
Batch: 1177/1685	Loss:0.167
Batch: 1345/1685	Loss:0.007
Batch: 1513/1685	Loss:0.144
Batch: 1681/1685	Loss:0.086
Batch: 1685/1685	Loss:0.027
Epoch: 10	Train Loss: 0.268	Val F1: 0.699
Best Epoch: 9	Best Epoch Val F1: 0.701

******************************Epoch: 11******************************
Batch: 1/1685	Loss:0.422
Batch: 169/1685	Loss:0.448
Batch: 337/1685	Loss:0.318
Batch: 505/1685	Loss:0.101
Batch: 673/1685	Loss:0.181
Batch: 841/1685	Loss:0.525
Batch: 1009/1685	Loss:0.742
Batch: 1177/1685	Loss:0.513
Batch: 1345/1685	Loss:0.729
Batch: 1513/1685	Loss:0.141
Batch: 1681/1685	Loss:0.073
Batch: 1685/1685	Loss:0.044
Epoch: 11	Train Loss: 0.247	Val F1: 0.677
Best Epoch: 9	Best Epoch Val F1: 0.701

******************************Epoch: 12******************************
Batch: 1/1685	Loss:0.261
Batch: 169/1685	Loss:0.036
Batch: 337/1685	Loss:0.313
Batch: 505/1685	Loss:0.453
Batch: 673/1685	Loss:0.202
Batch: 841/1685	Loss:1.578
Batch: 1009/1685	Loss:0.283
Batch: 1177/1685	Loss:0.068
Batch: 1345/1685	Loss:0.048
Batch: 1513/1685	Loss:0.064
Batch: 1681/1685	Loss:0.078
Batch: 1685/1685	Loss:0.010
Epoch: 12	Train Loss: 0.229	Val F1: 0.717
Best Epoch: 12	Best Epoch Val F1: 0.717

******************************Epoch: 13******************************
Batch: 1/1685	Loss:0.249
Batch: 169/1685	Loss:0.019
Batch: 337/1685	Loss:0.337
Batch: 505/1685	Loss:0.077
Batch: 673/1685	Loss:0.017
Batch: 841/1685	Loss:0.093
Batch: 1009/1685	Loss:0.062
Batch: 1177/1685	Loss:0.117
Batch: 1345/1685	Loss:0.102
Batch: 1513/1685	Loss:0.320
Batch: 1681/1685	Loss:0.230
Batch: 1685/1685	Loss:0.228
Epoch: 13	Train Loss: 0.216	Val F1: 0.703
Best Epoch: 12	Best Epoch Val F1: 0.717

******************************Epoch: 14******************************
Batch: 1/1685	Loss:0.469
Batch: 169/1685	Loss:0.013
Batch: 337/1685	Loss:0.087
Batch: 505/1685	Loss:0.109
Batch: 673/1685	Loss:0.226
Batch: 841/1685	Loss:0.322
Batch: 1009/1685	Loss:0.255
Batch: 1177/1685	Loss:0.221
Batch: 1345/1685	Loss:0.096
Batch: 1513/1685	Loss:0.036
Batch: 1681/1685	Loss:0.287
Batch: 1685/1685	Loss:0.005
Epoch: 14	Train Loss: 0.200	Val F1: 0.699
Best Epoch: 12	Best Epoch Val F1: 0.717

******************************Epoch: 15******************************
Batch: 1/1685	Loss:0.057
Batch: 169/1685	Loss:0.004
Batch: 337/1685	Loss:0.206
Batch: 505/1685	Loss:0.168
Batch: 673/1685	Loss:0.032
Batch: 841/1685	Loss:0.020
Batch: 1009/1685	Loss:0.076
Batch: 1177/1685	Loss:0.058
Batch: 1345/1685	Loss:0.272
Batch: 1513/1685	Loss:0.104
Batch: 1681/1685	Loss:0.089
Batch: 1685/1685	Loss:0.001
Epoch: 15	Train Loss: 0.192	Val F1: 0.665
Best Epoch: 12	Best Epoch Val F1: 0.717

******************************Epoch: 16******************************
Batch: 1/1685	Loss:0.104
Batch: 169/1685	Loss:0.308
Batch: 337/1685	Loss:0.227
Batch: 505/1685	Loss:0.338
Batch: 673/1685	Loss:0.471
Batch: 841/1685	Loss:0.084
Batch: 1009/1685	Loss:0.038
Batch: 1177/1685	Loss:0.008
Batch: 1345/1685	Loss:0.024
Batch: 1513/1685	Loss:0.119
Batch: 1681/1685	Loss:0.054
Batch: 1685/1685	Loss:0.191
Epoch: 16	Train Loss: 0.177	Val F1: 0.712
Best Epoch: 12	Best Epoch Val F1: 0.717

******************************Epoch: 17******************************
Batch: 1/1685	Loss:0.105
Batch: 169/1685	Loss:0.244
Batch: 337/1685	Loss:0.029
Batch: 505/1685	Loss:0.144
Batch: 673/1685	Loss:0.158
Batch: 841/1685	Loss:0.030
Batch: 1009/1685	Loss:0.148
Batch: 1177/1685	Loss:0.169
Batch: 1345/1685	Loss:0.427
Batch: 1513/1685	Loss:0.316
Batch: 1681/1685	Loss:0.944
Batch: 1685/1685	Loss:0.037
Epoch: 17	Train Loss: 0.183	Val F1: 0.704
Best Epoch: 12	Best Epoch Val F1: 0.717

******************************Epoch: 18******************************
Batch: 1/1685	Loss:0.105
Batch: 169/1685	Loss:0.135
Batch: 337/1685	Loss:0.302
Batch: 505/1685	Loss:0.087
Batch: 673/1685	Loss:0.604
Batch: 841/1685	Loss:0.248
Batch: 1009/1685	Loss:0.007
Batch: 1177/1685	Loss:0.151
Batch: 1345/1685	Loss:0.163
Batch: 1513/1685	Loss:0.177
Batch: 1681/1685	Loss:0.288
Batch: 1685/1685	Loss:0.136
Epoch: 18	Train Loss: 0.171	Val F1: 0.712
Best Epoch: 12	Best Epoch Val F1: 0.717

******************************Epoch: 19******************************
Batch: 1/1685	Loss:0.296
Batch: 169/1685	Loss:0.007
Batch: 337/1685	Loss:0.179
Batch: 505/1685	Loss:0.108
Batch: 673/1685	Loss:0.192
Batch: 841/1685	Loss:0.121
Batch: 1009/1685	Loss:0.254
Batch: 1177/1685	Loss:0.188
Batch: 1345/1685	Loss:0.032
Batch: 1513/1685	Loss:0.192
Batch: 1681/1685	Loss:0.001
Batch: 1685/1685	Loss:0.128
Epoch: 19	Train Loss: 0.164	Val F1: 0.700
Best Epoch: 12	Best Epoch Val F1: 0.717

******************************Epoch: 20******************************
Batch: 1/1685	Loss:0.021
Batch: 169/1685	Loss:0.332
Batch: 337/1685	Loss:0.015
Batch: 505/1685	Loss:0.015
Batch: 673/1685	Loss:0.259
Batch: 841/1685	Loss:0.091
Batch: 1009/1685	Loss:0.255
Batch: 1177/1685	Loss:0.053
Batch: 1345/1685	Loss:0.451
Batch: 1513/1685	Loss:0.087
Batch: 1681/1685	Loss:0.068
Batch: 1685/1685	Loss:0.010
Epoch: 20	Train Loss: 0.158	Val F1: 0.698
Best Epoch: 12	Best Epoch Val F1: 0.717

******************************Epoch: 21******************************
Batch: 1/1685	Loss:0.010
Batch: 169/1685	Loss:0.092
Batch: 337/1685	Loss:0.008
Batch: 505/1685	Loss:0.139
Batch: 673/1685	Loss:0.058
Batch: 841/1685	Loss:0.002
Batch: 1009/1685	Loss:0.100
Batch: 1177/1685	Loss:0.037
Batch: 1345/1685	Loss:0.063
Batch: 1513/1685	Loss:0.198
Batch: 1681/1685	Loss:0.009
Batch: 1685/1685	Loss:0.578
Epoch: 21	Train Loss: 0.152	Val F1: 0.704
Best Epoch: 12	Best Epoch Val F1: 0.717

******************************Epoch: 22******************************
Batch: 1/1685	Loss:0.245
Batch: 169/1685	Loss:0.083
Batch: 337/1685	Loss:0.002
Batch: 505/1685	Loss:0.007
Batch: 673/1685	Loss:0.152
Batch: 841/1685	Loss:0.042
Batch: 1009/1685	Loss:0.525
Batch: 1177/1685	Loss:0.207
Batch: 1345/1685	Loss:0.630
Batch: 1513/1685	Loss:0.053
Batch: 1681/1685	Loss:0.053
Batch: 1685/1685	Loss:0.067
Epoch: 22	Train Loss: 0.147	Val F1: 0.696
Best Epoch: 12	Best Epoch Val F1: 0.717

******************************Epoch: 23******************************
Batch: 1/1685	Loss:0.165
Batch: 169/1685	Loss:0.562
Batch: 337/1685	Loss:0.213
Batch: 505/1685	Loss:0.037
Batch: 673/1685	Loss:0.113
Batch: 841/1685	Loss:0.003
Batch: 1009/1685	Loss:0.069
Batch: 1177/1685	Loss:0.137
Batch: 1345/1685	Loss:0.173
Batch: 1513/1685	Loss:0.156
Batch: 1681/1685	Loss:0.161
Batch: 1685/1685	Loss:0.155
Epoch: 23	Train Loss: 0.145	Val F1: 0.701
Best Epoch: 12	Best Epoch Val F1: 0.717

******************************Epoch: 24******************************
Batch: 1/1685	Loss:0.116
Batch: 169/1685	Loss:0.024
Batch: 337/1685	Loss:0.699
Batch: 505/1685	Loss:0.005
Batch: 673/1685	Loss:0.042
Batch: 841/1685	Loss:0.162
Batch: 1009/1685	Loss:0.048
Batch: 1177/1685	Loss:0.005
Batch: 1345/1685	Loss:0.479
Batch: 1513/1685	Loss:0.066
Batch: 1681/1685	Loss:0.022
Batch: 1685/1685	Loss:0.095
Epoch: 24	Train Loss: 0.145	Val F1: 0.701
Best Epoch: 12	Best Epoch Val F1: 0.717

******************************Epoch: 25******************************
Batch: 1/1685	Loss:0.150
Batch: 169/1685	Loss:0.002
Batch: 337/1685	Loss:0.208
Batch: 505/1685	Loss:0.167
Batch: 673/1685	Loss:0.254
Batch: 841/1685	Loss:0.156
Batch: 1009/1685	Loss:0.217
Batch: 1177/1685	Loss:0.155
Batch: 1345/1685	Loss:0.007
Batch: 1513/1685	Loss:0.122
Batch: 1681/1685	Loss:0.128
Batch: 1685/1685	Loss:0.006
Epoch: 25	Train Loss: 0.137	Val F1: 0.697
Best Epoch: 12	Best Epoch Val F1: 0.717

******************************Epoch: 26******************************
Batch: 1/1685	Loss:0.044
Batch: 169/1685	Loss:0.076
Batch: 337/1685	Loss:0.436
Batch: 505/1685	Loss:0.520
Batch: 673/1685	Loss:0.205
Batch: 841/1685	Loss:0.230
Batch: 1009/1685	Loss:0.086
Batch: 1177/1685	Loss:0.297
Batch: 1345/1685	Loss:0.070
Batch: 1513/1685	Loss:0.328
Batch: 1681/1685	Loss:0.206
Batch: 1685/1685	Loss:0.001
Epoch: 26	Train Loss: 0.137	Val F1: 0.705
Best Epoch: 12	Best Epoch Val F1: 0.717

******************************Epoch: 27******************************
Batch: 1/1685	Loss:0.080
Batch: 169/1685	Loss:0.004
Batch: 337/1685	Loss:0.463
Batch: 505/1685	Loss:0.034
Batch: 673/1685	Loss:0.328
Batch: 841/1685	Loss:0.187
Batch: 1009/1685	Loss:0.209
Batch: 1177/1685	Loss:0.579
Batch: 1345/1685	Loss:0.148
Batch: 1513/1685	Loss:0.088
Batch: 1681/1685	Loss:0.080
Batch: 1685/1685	Loss:0.464
Epoch: 27	Train Loss: 0.133	Val F1: 0.701
Best Epoch: 12	Best Epoch Val F1: 0.717

Saving the best checkpoint....
Inference...
Test F1: 0.721	Test F1_Few: 0.730	Test F1_Zero: 0.711
Starting training with config: {'batch_size': 4, 'epochs': 50, 'l2_reg': 3.432815179488767e-05, 'lr': 9.222159401351857e-06, 'n_layers_freeze': 2, 'patience': 15}
Let's use 1 GPUs!
Preparing data....
Training data....
# of train examples: 13477
max len: 512, max len wiki: 1
Val data....
# of val examples: 2062
max len: 512, max len wiki: 1
Test data....
# of test examples: 3006
max len: 512, max len wiki: 1
Done

Initializing model....
******************************Epoch: 1******************************
Batch: 1/3370	Loss:1.322
Batch: 338/3370	Loss:1.225
Batch: 675/3370	Loss:0.895
Batch: 1012/3370	Loss:0.671
Batch: 1349/3370	Loss:0.694
Batch: 1686/3370	Loss:1.538
Batch: 2023/3370	Loss:0.296
Batch: 2360/3370	Loss:1.364
Batch: 2697/3370	Loss:0.631
Batch: 3034/3370	Loss:0.501
Batch: 3370/3370	Loss:1.354
Epoch: 1	Train Loss: 0.773	Val F1: 0.683
Best Epoch: 1	Best Epoch Val F1: 0.683

******************************Epoch: 2******************************
Batch: 1/3370	Loss:0.721
Batch: 338/3370	Loss:0.884
Batch: 675/3370	Loss:0.488
Batch: 1012/3370	Loss:0.567
Batch: 1349/3370	Loss:0.488
Batch: 1686/3370	Loss:0.365
Batch: 2023/3370	Loss:0.554
Batch: 2360/3370	Loss:0.531
Batch: 2697/3370	Loss:0.648
Batch: 3034/3370	Loss:0.451
Batch: 3370/3370	Loss:0.012
Epoch: 2	Train Loss: 0.600	Val F1: 0.687
Best Epoch: 2	Best Epoch Val F1: 0.687

******************************Epoch: 3******************************
Batch: 1/3370	Loss:0.193
Batch: 338/3370	Loss:0.521
Batch: 675/3370	Loss:0.628
Batch: 1012/3370	Loss:0.722
Batch: 1349/3370	Loss:0.318
Batch: 1686/3370	Loss:0.842
Batch: 2023/3370	Loss:0.582
Batch: 2360/3370	Loss:0.360
Batch: 2697/3370	Loss:0.112
Batch: 3034/3370	Loss:0.191
Batch: 3370/3370	Loss:0.066
Epoch: 3	Train Loss: 0.514	Val F1: 0.699
Best Epoch: 3	Best Epoch Val F1: 0.699

******************************Epoch: 4******************************
Batch: 1/3370	Loss:0.117
Batch: 338/3370	Loss:0.404
Batch: 675/3370	Loss:0.148
Batch: 1012/3370	Loss:0.827
Batch: 1349/3370	Loss:0.182
Batch: 1686/3370	Loss:0.257
Batch: 2023/3370	Loss:0.513
Batch: 2360/3370	Loss:0.300
Batch: 2697/3370	Loss:0.697
Batch: 3034/3370	Loss:0.730
Batch: 3370/3370	Loss:0.005
Epoch: 4	Train Loss: 0.436	Val F1: 0.680
Best Epoch: 3	Best Epoch Val F1: 0.699

******************************Epoch: 5******************************
Batch: 1/3370	Loss:0.507
Batch: 338/3370	Loss:0.436
Batch: 675/3370	Loss:0.229
Batch: 1012/3370	Loss:0.204
Batch: 1349/3370	Loss:0.041
Batch: 1686/3370	Loss:0.311
Batch: 2023/3370	Loss:0.087
Batch: 2360/3370	Loss:0.058
Batch: 2697/3370	Loss:0.796
Batch: 3034/3370	Loss:0.520
Batch: 3370/3370	Loss:0.663
Epoch: 5	Train Loss: 0.388	Val F1: 0.689
Best Epoch: 3	Best Epoch Val F1: 0.699

******************************Epoch: 6******************************
Batch: 1/3370	Loss:0.040
Batch: 338/3370	Loss:0.261
Batch: 675/3370	Loss:0.114
Batch: 1012/3370	Loss:0.189
Batch: 1349/3370	Loss:0.042
Batch: 1686/3370	Loss:0.733
Batch: 2023/3370	Loss:0.015
Batch: 2360/3370	Loss:0.312
Batch: 2697/3370	Loss:0.078
Batch: 3034/3370	Loss:1.023
Batch: 3370/3370	Loss:0.003
Epoch: 6	Train Loss: 0.343	Val F1: 0.709
Best Epoch: 6	Best Epoch Val F1: 0.709

******************************Epoch: 7******************************
Batch: 1/3370	Loss:0.171
Batch: 338/3370	Loss:0.161
Batch: 675/3370	Loss:0.218
Batch: 1012/3370	Loss:0.025
Batch: 1349/3370	Loss:0.051
Batch: 1686/3370	Loss:1.591
Batch: 2023/3370	Loss:0.535
Batch: 2360/3370	Loss:0.450
Batch: 2697/3370	Loss:0.209
Batch: 3034/3370	Loss:0.331
Batch: 3370/3370	Loss:0.002
Epoch: 7	Train Loss: 0.303	Val F1: 0.682
Best Epoch: 6	Best Epoch Val F1: 0.709

******************************Epoch: 8******************************
Batch: 1/3370	Loss:0.120
Batch: 338/3370	Loss:0.713
Batch: 675/3370	Loss:0.003
Batch: 1012/3370	Loss:0.038
Batch: 1349/3370	Loss:0.040
Batch: 1686/3370	Loss:0.054
Batch: 2023/3370	Loss:0.461
Batch: 2360/3370	Loss:0.517
Batch: 2697/3370	Loss:0.016
Batch: 3034/3370	Loss:0.004
Batch: 3370/3370	Loss:0.001
Epoch: 8	Train Loss: 0.267	Val F1: 0.669
Best Epoch: 6	Best Epoch Val F1: 0.709

******************************Epoch: 9******************************
Batch: 1/3370	Loss:1.380
Batch: 338/3370	Loss:0.624
Batch: 675/3370	Loss:1.525
Batch: 1012/3370	Loss:0.155
Batch: 1349/3370	Loss:0.370
Batch: 1686/3370	Loss:0.571
Batch: 2023/3370	Loss:0.046
Batch: 2360/3370	Loss:0.235
Batch: 2697/3370	Loss:0.125
Batch: 3034/3370	Loss:0.196
Batch: 3370/3370	Loss:0.678
Epoch: 9	Train Loss: 0.239	Val F1: 0.701
Best Epoch: 6	Best Epoch Val F1: 0.709

******************************Epoch: 10******************************
Batch: 1/3370	Loss:0.088
Batch: 338/3370	Loss:0.380
Batch: 675/3370	Loss:0.180
Batch: 1012/3370	Loss:0.054
Batch: 1349/3370	Loss:0.008
Batch: 1686/3370	Loss:0.206
Batch: 2023/3370	Loss:0.290
Batch: 2360/3370	Loss:0.010
Batch: 2697/3370	Loss:1.053
Batch: 3034/3370	Loss:0.118
Batch: 3370/3370	Loss:0.019
Epoch: 10	Train Loss: 0.217	Val F1: 0.683
Best Epoch: 6	Best Epoch Val F1: 0.709

******************************Epoch: 11******************************
Batch: 1/3370	Loss:0.117
Batch: 338/3370	Loss:0.029
Batch: 675/3370	Loss:0.050
Batch: 1012/3370	Loss:0.009
Batch: 1349/3370	Loss:0.045
Batch: 1686/3370	Loss:0.020
Batch: 2023/3370	Loss:0.380
Batch: 2360/3370	Loss:1.028
Batch: 2697/3370	Loss:0.532
Batch: 3034/3370	Loss:0.162
Batch: 3370/3370	Loss:0.001
Epoch: 11	Train Loss: 0.198	Val F1: 0.695
Best Epoch: 6	Best Epoch Val F1: 0.709

******************************Epoch: 12******************************
Batch: 1/3370	Loss:0.657
Batch: 338/3370	Loss:0.001
Batch: 675/3370	Loss:0.082
Batch: 1012/3370	Loss:0.012
Batch: 1349/3370	Loss:0.034
Batch: 1686/3370	Loss:0.277
Batch: 2023/3370	Loss:0.077
Batch: 2360/3370	Loss:0.003
Batch: 2697/3370	Loss:0.002
Batch: 3034/3370	Loss:0.410
Batch: 3370/3370	Loss:0.001
Epoch: 12	Train Loss: 0.179	Val F1: 0.696
Best Epoch: 6	Best Epoch Val F1: 0.709

******************************Epoch: 13******************************
Batch: 1/3370	Loss:0.021
Batch: 338/3370	Loss:0.025
Batch: 675/3370	Loss:0.186
Batch: 1012/3370	Loss:0.011
Batch: 1349/3370	Loss:0.102
Batch: 1686/3370	Loss:0.173
Batch: 2023/3370	Loss:0.005
Batch: 2360/3370	Loss:0.089
Batch: 2697/3370	Loss:0.038
Batch: 3034/3370	Loss:0.003
Batch: 3370/3370	Loss:0.280
Epoch: 13	Train Loss: 0.172	Val F1: 0.707
Best Epoch: 6	Best Epoch Val F1: 0.709

******************************Epoch: 14******************************
Batch: 1/3370	Loss:0.603
Batch: 338/3370	Loss:0.012
Batch: 675/3370	Loss:0.064
Batch: 1012/3370	Loss:0.014
Batch: 1349/3370	Loss:0.107
Batch: 1686/3370	Loss:0.244
Batch: 2023/3370	Loss:0.183
Batch: 2360/3370	Loss:0.001
Batch: 2697/3370	Loss:0.017
Batch: 3034/3370	Loss:0.040
Batch: 3370/3370	Loss:0.010
Epoch: 14	Train Loss: 0.159	Val F1: 0.680
Best Epoch: 6	Best Epoch Val F1: 0.709

******************************Epoch: 15******************************
Batch: 1/3370	Loss:0.005
Batch: 338/3370	Loss:0.079
Batch: 675/3370	Loss:0.085
Batch: 1012/3370	Loss:0.245
Batch: 1349/3370	Loss:0.189
Batch: 1686/3370	Loss:0.024
Batch: 2023/3370	Loss:0.163
Batch: 2360/3370	Loss:0.006
Batch: 2697/3370	Loss:0.107
Batch: 3034/3370	Loss:0.184
Batch: 3370/3370	Loss:0.013
Epoch: 15	Train Loss: 0.150	Val F1: 0.691
Best Epoch: 6	Best Epoch Val F1: 0.709

******************************Epoch: 16******************************
Batch: 1/3370	Loss:0.125
Batch: 338/3370	Loss:0.151
Batch: 675/3370	Loss:0.149
Batch: 1012/3370	Loss:0.001
Batch: 1349/3370	Loss:0.017
Batch: 1686/3370	Loss:0.062
Batch: 2023/3370	Loss:0.296
Batch: 2360/3370	Loss:0.008
Batch: 2697/3370	Loss:0.025
Batch: 3034/3370	Loss:0.299
Batch: 3370/3370	Loss:0.158
Epoch: 16	Train Loss: 0.141	Val F1: 0.698
Best Epoch: 6	Best Epoch Val F1: 0.709

******************************Epoch: 17******************************
Batch: 1/3370	Loss:0.031
Batch: 338/3370	Loss:0.001
Batch: 675/3370	Loss:0.234
Batch: 1012/3370	Loss:0.001
Batch: 1349/3370	Loss:0.040
Batch: 1686/3370	Loss:0.071
Batch: 2023/3370	Loss:0.060
Batch: 2360/3370	Loss:0.144
Batch: 2697/3370	Loss:0.284
Batch: 3034/3370	Loss:0.232
Batch: 3370/3370	Loss:0.013
Epoch: 17	Train Loss: 0.136	Val F1: 0.697
Best Epoch: 6	Best Epoch Val F1: 0.709

******************************Epoch: 18******************************
Batch: 1/3370	Loss:0.126
Batch: 338/3370	Loss:0.070
Batch: 675/3370	Loss:0.006
Batch: 1012/3370	Loss:0.089
Batch: 1349/3370	Loss:0.001
Batch: 1686/3370	Loss:0.018
Batch: 2023/3370	Loss:0.261
Batch: 2360/3370	Loss:0.062
Batch: 2697/3370	Loss:0.015
Batch: 3034/3370	Loss:0.008
Batch: 3370/3370	Loss:0.003
Epoch: 18	Train Loss: 0.127	Val F1: 0.713
Best Epoch: 18	Best Epoch Val F1: 0.713

******************************Epoch: 19******************************
Batch: 1/3370	Loss:0.002
Batch: 338/3370	Loss:0.001
Batch: 675/3370	Loss:0.003
Batch: 1012/3370	Loss:0.372
Batch: 1349/3370	Loss:0.664
Batch: 1686/3370	Loss:0.238
Batch: 2023/3370	Loss:0.061
Batch: 2360/3370	Loss:0.001
Batch: 2697/3370	Loss:0.044
Batch: 3034/3370	Loss:0.001
Batch: 3370/3370	Loss:0.834
Epoch: 19	Train Loss: 0.126	Val F1: 0.697
Best Epoch: 18	Best Epoch Val F1: 0.713

******************************Epoch: 20******************************
Batch: 1/3370	Loss:0.019
Batch: 338/3370	Loss:0.211
Batch: 675/3370	Loss:0.000
Batch: 1012/3370	Loss:0.002
Batch: 1349/3370	Loss:0.119
Batch: 1686/3370	Loss:0.049
Batch: 2023/3370	Loss:0.019
Batch: 2360/3370	Loss:0.435
Batch: 2697/3370	Loss:0.016
Batch: 3034/3370	Loss:0.548
Batch: 3370/3370	Loss:0.006
Epoch: 20	Train Loss: 0.125	Val F1: 0.702
Best Epoch: 18	Best Epoch Val F1: 0.713

******************************Epoch: 21******************************
Batch: 1/3370	Loss:0.001
Batch: 338/3370	Loss:0.194
Batch: 675/3370	Loss:0.059
Batch: 1012/3370	Loss:0.003
Batch: 1349/3370	Loss:0.001
Batch: 1686/3370	Loss:0.000
Batch: 2023/3370	Loss:0.061
Batch: 2360/3370	Loss:0.002
Batch: 2697/3370	Loss:0.041
Batch: 3034/3370	Loss:0.010
Batch: 3370/3370	Loss:0.001
Epoch: 21	Train Loss: 0.115	Val F1: 0.690
Best Epoch: 18	Best Epoch Val F1: 0.713

******************************Epoch: 22******************************
Batch: 1/3370	Loss:0.001
Batch: 338/3370	Loss:0.383
Batch: 675/3370	Loss:0.001
Batch: 1012/3370	Loss:0.009
Batch: 1349/3370	Loss:0.234
Batch: 1686/3370	Loss:0.001
Batch: 2023/3370	Loss:0.225
Batch: 2360/3370	Loss:0.114
Batch: 2697/3370	Loss:0.055
Batch: 3034/3370	Loss:0.226
Batch: 3370/3370	Loss:0.012
Epoch: 22	Train Loss: 0.114	Val F1: 0.685
Best Epoch: 18	Best Epoch Val F1: 0.713

******************************Epoch: 23******************************
Batch: 1/3370	Loss:0.146
Batch: 338/3370	Loss:0.005
Batch: 675/3370	Loss:0.012
Batch: 1012/3370	Loss:0.001
Batch: 1349/3370	Loss:0.240
Batch: 1686/3370	Loss:0.193
Batch: 2023/3370	Loss:0.149
Batch: 2360/3370	Loss:0.217
Batch: 2697/3370	Loss:0.367
Batch: 3034/3370	Loss:0.190
Batch: 3370/3370	Loss:0.005
Epoch: 23	Train Loss: 0.107	Val F1: 0.681
Best Epoch: 18	Best Epoch Val F1: 0.713

******************************Epoch: 24******************************
Batch: 1/3370	Loss:0.000
Batch: 338/3370	Loss:0.006
Batch: 675/3370	Loss:0.000
Batch: 1012/3370	Loss:0.051
Batch: 1349/3370	Loss:0.174
Batch: 1686/3370	Loss:0.002
Batch: 2023/3370	Loss:0.246
Batch: 2360/3370	Loss:0.243
Batch: 2697/3370	Loss:0.136
Batch: 3034/3370	Loss:0.576
Batch: 3370/3370	Loss:1.391
Epoch: 24	Train Loss: 0.113	Val F1: 0.683
Best Epoch: 18	Best Epoch Val F1: 0.713

******************************Epoch: 25******************************
Batch: 1/3370	Loss:0.073
Batch: 338/3370	Loss:0.004
Batch: 675/3370	Loss:0.167
Batch: 1012/3370	Loss:0.063
Batch: 1349/3370	Loss:0.008
Batch: 1686/3370	Loss:0.227
Batch: 2023/3370	Loss:0.000
Batch: 2360/3370	Loss:0.037
Batch: 2697/3370	Loss:0.012
Batch: 3034/3370	Loss:0.088
Batch: 3370/3370	Loss:0.001
Epoch: 25	Train Loss: 0.107	Val F1: 0.685
Best Epoch: 18	Best Epoch Val F1: 0.713

******************************Epoch: 26******************************
Batch: 1/3370	Loss:0.023
Batch: 338/3370	Loss:0.005
Batch: 675/3370	Loss:0.005
Batch: 1012/3370	Loss:0.268
Batch: 1349/3370	Loss:0.000
Batch: 1686/3370	Loss:0.009
Batch: 2023/3370	Loss:0.397
Batch: 2360/3370	Loss:0.027
Batch: 2697/3370	Loss:0.005
Batch: 3034/3370	Loss:0.018
Batch: 3370/3370	Loss:0.000
Epoch: 26	Train Loss: 0.101	Val F1: 0.691
Best Epoch: 18	Best Epoch Val F1: 0.713

******************************Epoch: 27******************************
Batch: 1/3370	Loss:0.027
Batch: 338/3370	Loss:0.002
Batch: 675/3370	Loss:0.000
Batch: 1012/3370	Loss:0.095
Batch: 1349/3370	Loss:0.064
Batch: 1686/3370	Loss:0.022
Batch: 2023/3370	Loss:0.079
Batch: 2360/3370	Loss:0.060
Batch: 2697/3370	Loss:0.020
Batch: 3034/3370	Loss:0.000
Batch: 3370/3370	Loss:0.003
Epoch: 27	Train Loss: 0.103	Val F1: 0.694
Best Epoch: 18	Best Epoch Val F1: 0.713

******************************Epoch: 28******************************
Batch: 1/3370	Loss:0.026
Batch: 338/3370	Loss:0.006
Batch: 675/3370	Loss:0.005
Batch: 1012/3370	Loss:0.009
Batch: 1349/3370	Loss:0.003
Batch: 1686/3370	Loss:0.001
Batch: 2023/3370	Loss:0.339
Batch: 2360/3370	Loss:0.001
Batch: 2697/3370	Loss:0.001
Batch: 3034/3370	Loss:0.002
Batch: 3370/3370	Loss:0.000
Epoch: 28	Train Loss: 0.101	Val F1: 0.681
Best Epoch: 18	Best Epoch Val F1: 0.713

******************************Epoch: 29******************************
Batch: 1/3370	Loss:0.001
Batch: 338/3370	Loss:0.000
Batch: 675/3370	Loss:0.002
Batch: 1012/3370	Loss:0.042
Batch: 1349/3370	Loss:0.000
Batch: 1686/3370	Loss:0.000
Batch: 2023/3370	Loss:0.000
Batch: 2360/3370	Loss:0.006
Batch: 2697/3370	Loss:0.001
Batch: 3034/3370	Loss:0.181
Batch: 3370/3370	Loss:0.001
Epoch: 29	Train Loss: 0.102	Val F1: 0.687
Best Epoch: 18	Best Epoch Val F1: 0.713

******************************Epoch: 30******************************
Batch: 1/3370	Loss:0.002
Batch: 338/3370	Loss:0.552
Batch: 675/3370	Loss:0.001
Batch: 1012/3370	Loss:0.001
Batch: 1349/3370	Loss:0.086
Batch: 1686/3370	Loss:0.001
Batch: 2023/3370	Loss:0.002
Batch: 2360/3370	Loss:0.001
Batch: 2697/3370	Loss:0.058
Batch: 3034/3370	Loss:0.000
Batch: 3370/3370	Loss:0.009
Epoch: 30	Train Loss: 0.097	Val F1: 0.686
Best Epoch: 18	Best Epoch Val F1: 0.713

******************************Epoch: 31******************************
Batch: 1/3370	Loss:0.187
Batch: 338/3370	Loss:0.002
Batch: 675/3370	Loss:0.409
Batch: 1012/3370	Loss:0.166
Batch: 1349/3370	Loss:0.004
Batch: 1686/3370	Loss:0.000
Batch: 2023/3370	Loss:0.001
Batch: 2360/3370	Loss:0.000
Batch: 2697/3370	Loss:0.000
Batch: 3034/3370	Loss:0.001
Batch: 3370/3370	Loss:0.798
Epoch: 31	Train Loss: 0.094	Val F1: 0.690
Best Epoch: 18	Best Epoch Val F1: 0.713

******************************Epoch: 32******************************
Batch: 1/3370	Loss:0.001
Batch: 338/3370	Loss:0.010
Batch: 675/3370	Loss:0.059
Batch: 1012/3370	Loss:0.000
Batch: 1349/3370	Loss:0.111
Batch: 1686/3370	Loss:0.219
Batch: 2023/3370	Loss:0.758
Batch: 2360/3370	Loss:0.002
Batch: 2697/3370	Loss:0.015
Batch: 3034/3370	Loss:0.158
Batch: 3370/3370	Loss:0.000
Epoch: 32	Train Loss: 0.089	Val F1: 0.691
Best Epoch: 18	Best Epoch Val F1: 0.713

******************************Epoch: 33******************************
Batch: 1/3370	Loss:0.003
Batch: 338/3370	Loss:0.001
Batch: 675/3370	Loss:0.192
Batch: 1012/3370	Loss:0.002
Batch: 1349/3370	Loss:0.018
Batch: 1686/3370	Loss:0.005
Batch: 2023/3370	Loss:0.001
Batch: 2360/3370	Loss:0.003
Batch: 2697/3370	Loss:0.040
Batch: 3034/3370	Loss:0.184
Batch: 3370/3370	Loss:0.656
Epoch: 33	Train Loss: 0.089	Val F1: 0.680
Best Epoch: 18	Best Epoch Val F1: 0.713

Saving the best checkpoint....
Inference...
Test F1: 0.733	Test F1_Few: 0.750	Test F1_Zero: 0.716
Starting training with config: {'batch_size': 16, 'epochs': 50, 'l2_reg': 5.497389313892825e-05, 'lr': 1.5077737992737464e-05, 'n_layers_freeze': 2, 'patience': 15}
Let's use 1 GPUs!
Preparing data....
Training data....
# of train examples: 13477
max len: 512, max len wiki: 1
Val data....
# of val examples: 2062
max len: 512, max len wiki: 1
Test data....
# of test examples: 3006
max len: 512, max len wiki: 1
Done

Initializing model....
******************************Epoch: 1******************************
Batch: 1/843	Loss:1.114
Batch: 85/843	Loss:1.136
Batch: 169/843	Loss:1.140
Batch: 253/843	Loss:0.912
Batch: 337/843	Loss:0.738
Batch: 421/843	Loss:0.614
Batch: 505/843	Loss:0.375
Batch: 589/843	Loss:0.528
Batch: 673/843	Loss:0.596
Batch: 757/843	Loss:0.700
Batch: 841/843	Loss:0.697
Batch: 843/843	Loss:0.957
Epoch: 1	Train Loss: 0.819	Val F1: 0.682
Best Epoch: 1	Best Epoch Val F1: 0.682

******************************Epoch: 2******************************
Batch: 1/843	Loss:0.565
Batch: 85/843	Loss:0.890
Batch: 169/843	Loss:0.785
Batch: 253/843	Loss:0.544
Batch: 337/843	Loss:0.640
Batch: 421/843	Loss:0.818
Batch: 505/843	Loss:0.669
Batch: 589/843	Loss:0.805
Batch: 673/843	Loss:0.585
Batch: 757/843	Loss:0.625
Batch: 841/843	Loss:0.805
Batch: 843/843	Loss:0.452
Epoch: 2	Train Loss: 0.589	Val F1: 0.705
Best Epoch: 2	Best Epoch Val F1: 0.705

******************************Epoch: 3******************************
Batch: 1/843	Loss:0.447
Batch: 85/843	Loss:0.540
Batch: 169/843	Loss:0.503
Batch: 253/843	Loss:0.378
Batch: 337/843	Loss:0.511
Batch: 421/843	Loss:0.563
Batch: 505/843	Loss:0.394
Batch: 589/843	Loss:0.558
Batch: 673/843	Loss:0.229
Batch: 757/843	Loss:0.554
Batch: 841/843	Loss:0.360
Batch: 843/843	Loss:0.252
Epoch: 3	Train Loss: 0.494	Val F1: 0.729
Best Epoch: 3	Best Epoch Val F1: 0.729

******************************Epoch: 4******************************
Batch: 1/843	Loss:0.257
Batch: 85/843	Loss:0.518
Batch: 169/843	Loss:0.384
Batch: 253/843	Loss:0.663
Batch: 337/843	Loss:0.404
Batch: 421/843	Loss:0.557
Batch: 505/843	Loss:0.449
Batch: 589/843	Loss:0.215
Batch: 673/843	Loss:0.475
Batch: 757/843	Loss:0.430
Batch: 841/843	Loss:0.185
Batch: 843/843	Loss:0.768
Epoch: 4	Train Loss: 0.422	Val F1: 0.695
Best Epoch: 3	Best Epoch Val F1: 0.729

******************************Epoch: 5******************************
Batch: 1/843	Loss:0.383
Batch: 85/843	Loss:0.353
Batch: 169/843	Loss:0.360
Batch: 253/843	Loss:0.169
Batch: 337/843	Loss:0.576
Batch: 421/843	Loss:0.414
Batch: 505/843	Loss:0.321
Batch: 589/843	Loss:0.656
Batch: 673/843	Loss:0.301
Batch: 757/843	Loss:0.395
Batch: 841/843	Loss:0.230
Batch: 843/843	Loss:0.532
Epoch: 5	Train Loss: 0.374	Val F1: 0.711
Best Epoch: 3	Best Epoch Val F1: 0.729

******************************Epoch: 6******************************
Batch: 1/843	Loss:0.184
Batch: 85/843	Loss:0.161
Batch: 169/843	Loss:0.324
Batch: 253/843	Loss:0.316
Batch: 337/843	Loss:0.264
Batch: 421/843	Loss:0.158
Batch: 505/843	Loss:0.255
Batch: 589/843	Loss:0.272
Batch: 673/843	Loss:0.306
Batch: 757/843	Loss:0.196
Batch: 841/843	Loss:0.379
Batch: 843/843	Loss:0.062
Epoch: 6	Train Loss: 0.335	Val F1: 0.723
Best Epoch: 3	Best Epoch Val F1: 0.729

******************************Epoch: 7******************************
Batch: 1/843	Loss:0.231
Batch: 85/843	Loss:0.159
Batch: 169/843	Loss:0.242
Batch: 253/843	Loss:0.108
Batch: 337/843	Loss:0.523
Batch: 421/843	Loss:0.206
Batch: 505/843	Loss:0.206
Batch: 589/843	Loss:0.161
Batch: 673/843	Loss:0.442
Batch: 757/843	Loss:0.446
Batch: 841/843	Loss:0.428
Batch: 843/843	Loss:0.140
Epoch: 7	Train Loss: 0.295	Val F1: 0.729
Best Epoch: 7	Best Epoch Val F1: 0.729

******************************Epoch: 8******************************
Batch: 1/843	Loss:0.205
Batch: 85/843	Loss:0.139
Batch: 169/843	Loss:0.096
Batch: 253/843	Loss:0.303
Batch: 337/843	Loss:0.178
Batch: 421/843	Loss:0.279
Batch: 505/843	Loss:0.348
Batch: 589/843	Loss:0.227
Batch: 673/843	Loss:0.174
Batch: 757/843	Loss:0.434
Batch: 841/843	Loss:0.427
Batch: 843/843	Loss:0.226
Epoch: 8	Train Loss: 0.264	Val F1: 0.697
Best Epoch: 7	Best Epoch Val F1: 0.729

******************************Epoch: 9******************************
Batch: 1/843	Loss:0.441
Batch: 85/843	Loss:0.116
Batch: 169/843	Loss:0.304
Batch: 253/843	Loss:0.350
Batch: 337/843	Loss:0.064
Batch: 421/843	Loss:0.460
Batch: 505/843	Loss:0.192
Batch: 589/843	Loss:0.163
Batch: 673/843	Loss:0.301
Batch: 757/843	Loss:0.152
Batch: 841/843	Loss:0.220
Batch: 843/843	Loss:1.669
Epoch: 9	Train Loss: 0.238	Val F1: 0.722
Best Epoch: 7	Best Epoch Val F1: 0.729

******************************Epoch: 10******************************
Batch: 1/843	Loss:0.248
Batch: 85/843	Loss:0.306
Batch: 169/843	Loss:0.293
Batch: 253/843	Loss:0.067
Batch: 337/843	Loss:0.110
Batch: 421/843	Loss:0.117
Batch: 505/843	Loss:0.249
Batch: 589/843	Loss:0.209
Batch: 673/843	Loss:0.043
Batch: 757/843	Loss:0.205
Batch: 841/843	Loss:0.028
Batch: 843/843	Loss:0.058
Epoch: 10	Train Loss: 0.215	Val F1: 0.722
Best Epoch: 7	Best Epoch Val F1: 0.729

******************************Epoch: 11******************************
Batch: 1/843	Loss:0.557
Batch: 85/843	Loss:0.331
Batch: 169/843	Loss:0.067
Batch: 253/843	Loss:0.303
Batch: 337/843	Loss:0.172
Batch: 421/843	Loss:0.171
Batch: 505/843	Loss:0.302
Batch: 589/843	Loss:0.091
Batch: 673/843	Loss:0.311
Batch: 757/843	Loss:0.105
Batch: 841/843	Loss:0.238
Batch: 843/843	Loss:0.021
Epoch: 11	Train Loss: 0.187	Val F1: 0.711
Best Epoch: 7	Best Epoch Val F1: 0.729

******************************Epoch: 12******************************
Batch: 1/843	Loss:0.171
Batch: 85/843	Loss:0.051
Batch: 169/843	Loss:0.204
Batch: 253/843	Loss:0.496
Batch: 337/843	Loss:0.094
Batch: 421/843	Loss:0.189
Batch: 505/843	Loss:0.171
Batch: 589/843	Loss:0.187
Batch: 673/843	Loss:0.191
Batch: 757/843	Loss:0.180
Batch: 841/843	Loss:0.048
Batch: 843/843	Loss:0.035
Epoch: 12	Train Loss: 0.178	Val F1: 0.717
Best Epoch: 7	Best Epoch Val F1: 0.729

******************************Epoch: 13******************************
Batch: 1/843	Loss:0.151
Batch: 85/843	Loss:0.451
Batch: 169/843	Loss:0.216
Batch: 253/843	Loss:0.091
Batch: 337/843	Loss:0.142
Batch: 421/843	Loss:0.073
Batch: 505/843	Loss:0.114
Batch: 589/843	Loss:0.169
Batch: 673/843	Loss:0.080
Batch: 757/843	Loss:0.202
Batch: 841/843	Loss:0.214
Batch: 843/843	Loss:0.161
Epoch: 13	Train Loss: 0.167	Val F1: 0.708
Best Epoch: 7	Best Epoch Val F1: 0.729

******************************Epoch: 14******************************
Batch: 1/843	Loss:0.225
Batch: 85/843	Loss:0.147
Batch: 169/843	Loss:0.010
Batch: 253/843	Loss:0.243
Batch: 337/843	Loss:0.160
Batch: 421/843	Loss:0.124
Batch: 505/843	Loss:0.041
Batch: 589/843	Loss:0.029
Batch: 673/843	Loss:0.127
Batch: 757/843	Loss:0.068
Batch: 841/843	Loss:0.378
Batch: 843/843	Loss:0.082
Epoch: 14	Train Loss: 0.153	Val F1: 0.715
Best Epoch: 7	Best Epoch Val F1: 0.729

******************************Epoch: 15******************************
Batch: 1/843	Loss:0.085
Batch: 85/843	Loss:0.060
Batch: 169/843	Loss:0.050
Batch: 253/843	Loss:0.105
Batch: 337/843	Loss:0.096
Batch: 421/843	Loss:0.060
Batch: 505/843	Loss:0.154
Batch: 589/843	Loss:0.060
Batch: 673/843	Loss:0.171
Batch: 757/843	Loss:0.072
Batch: 841/843	Loss:0.151
Batch: 843/843	Loss:0.000
Epoch: 15	Train Loss: 0.141	Val F1: 0.711
Best Epoch: 7	Best Epoch Val F1: 0.729

******************************Epoch: 16******************************
Batch: 1/843	Loss:0.154
Batch: 85/843	Loss:0.202
Batch: 169/843	Loss:0.186
Batch: 253/843	Loss:0.244
Batch: 337/843	Loss:0.474
Batch: 421/843	Loss:0.081
Batch: 505/843	Loss:0.062
Batch: 589/843	Loss:0.049
Batch: 673/843	Loss:0.019
Batch: 757/843	Loss:0.127
Batch: 841/843	Loss:0.169
Batch: 843/843	Loss:0.055
Epoch: 16	Train Loss: 0.135	Val F1: 0.721
Best Epoch: 7	Best Epoch Val F1: 0.729

******************************Epoch: 17******************************
Batch: 1/843	Loss:0.047
Batch: 85/843	Loss:0.153
Batch: 169/843	Loss:0.093
Batch: 253/843	Loss:0.195
Batch: 337/843	Loss:0.032
Batch: 421/843	Loss:0.032
Batch: 505/843	Loss:0.226
Batch: 589/843	Loss:0.090
Batch: 673/843	Loss:0.121
Batch: 757/843	Loss:0.182
Batch: 841/843	Loss:0.068
Batch: 843/843	Loss:0.004
Epoch: 17	Train Loss: 0.137	Val F1: 0.731
Best Epoch: 17	Best Epoch Val F1: 0.731

******************************Epoch: 18******************************
Batch: 1/843	Loss:0.161
Batch: 85/843	Loss:0.027
Batch: 169/843	Loss:0.188
Batch: 253/843	Loss:0.114
Batch: 337/843	Loss:0.222
Batch: 421/843	Loss:0.280
Batch: 505/843	Loss:0.092
Batch: 589/843	Loss:0.055
Batch: 673/843	Loss:0.098
Batch: 757/843	Loss:0.092
Batch: 841/843	Loss:0.107
Batch: 843/843	Loss:0.079
Epoch: 18	Train Loss: 0.119	Val F1: 0.716
Best Epoch: 17	Best Epoch Val F1: 0.731

******************************Epoch: 19******************************
Batch: 1/843	Loss:0.201
Batch: 85/843	Loss:0.020
Batch: 169/843	Loss:0.037
Batch: 253/843	Loss:0.168
Batch: 337/843	Loss:0.131
Batch: 421/843	Loss:0.204
Batch: 505/843	Loss:0.115
Batch: 589/843	Loss:0.091
Batch: 673/843	Loss:0.130
Batch: 757/843	Loss:0.045
Batch: 841/843	Loss:0.042
Batch: 843/843	Loss:0.030
Epoch: 19	Train Loss: 0.122	Val F1: 0.712
Best Epoch: 17	Best Epoch Val F1: 0.731

******************************Epoch: 20******************************
Batch: 1/843	Loss:0.036
Batch: 85/843	Loss:0.373
Batch: 169/843	Loss:0.036
Batch: 253/843	Loss:0.047
Batch: 337/843	Loss:0.165
Batch: 421/843	Loss:0.086
Batch: 505/843	Loss:0.097
Batch: 589/843	Loss:0.214
Batch: 673/843	Loss:0.075
Batch: 757/843	Loss:0.144
Batch: 841/843	Loss:0.045
Batch: 843/843	Loss:0.015
Epoch: 20	Train Loss: 0.119	Val F1: 0.714
Best Epoch: 17	Best Epoch Val F1: 0.731

******************************Epoch: 21******************************
Batch: 1/843	Loss:0.017
Batch: 85/843	Loss:0.098
Batch: 169/843	Loss:0.068
Batch: 253/843	Loss:0.070
Batch: 337/843	Loss:0.086
Batch: 421/843	Loss:0.204
Batch: 505/843	Loss:0.145
Batch: 589/843	Loss:0.029
Batch: 673/843	Loss:0.040
Batch: 757/843	Loss:0.124
Batch: 841/843	Loss:0.041
Batch: 843/843	Loss:0.314
Epoch: 21	Train Loss: 0.109	Val F1: 0.713
Best Epoch: 17	Best Epoch Val F1: 0.731

******************************Epoch: 22******************************
Batch: 1/843	Loss:0.073
Batch: 85/843	Loss:0.056
Batch: 169/843	Loss:0.035
Batch: 253/843	Loss:0.008
Batch: 337/843	Loss:0.097
Batch: 421/843	Loss:0.024
Batch: 505/843	Loss:0.147
Batch: 589/843	Loss:0.149
Batch: 673/843	Loss:0.122
Batch: 757/843	Loss:0.047
Batch: 841/843	Loss:0.038
Batch: 843/843	Loss:0.166
Epoch: 22	Train Loss: 0.108	Val F1: 0.708
Best Epoch: 17	Best Epoch Val F1: 0.731

******************************Epoch: 23******************************
Batch: 1/843	Loss:0.076
Batch: 85/843	Loss:0.001
Batch: 169/843	Loss:0.138
Batch: 253/843	Loss:0.019
Batch: 337/843	Loss:0.017
Batch: 421/843	Loss:0.010
Batch: 505/843	Loss:0.100
Batch: 589/843	Loss:0.400
Batch: 673/843	Loss:0.492
Batch: 757/843	Loss:0.184
Batch: 841/843	Loss:0.043
Batch: 843/843	Loss:0.090
Epoch: 23	Train Loss: 0.111	Val F1: 0.707
Best Epoch: 17	Best Epoch Val F1: 0.731

******************************Epoch: 24******************************
Batch: 1/843	Loss:0.093
Batch: 85/843	Loss:0.058
Batch: 169/843	Loss:0.008
Batch: 253/843	Loss:0.011
Batch: 337/843	Loss:0.039
Batch: 421/843	Loss:0.092
Batch: 505/843	Loss:0.074
Batch: 589/843	Loss:0.005
Batch: 673/843	Loss:0.090
Batch: 757/843	Loss:0.260
Batch: 841/843	Loss:0.044
Batch: 843/843	Loss:0.043
Epoch: 24	Train Loss: 0.103	Val F1: 0.717
Best Epoch: 17	Best Epoch Val F1: 0.731

******************************Epoch: 25******************************
Batch: 1/843	Loss:0.128
Batch: 85/843	Loss:0.095
Batch: 169/843	Loss:0.094
Batch: 253/843	Loss:0.050
Batch: 337/843	Loss:0.201
Batch: 421/843	Loss:0.260
Batch: 505/843	Loss:0.069
Batch: 589/843	Loss:0.057
Batch: 673/843	Loss:0.151
Batch: 757/843	Loss:0.004
Batch: 841/843	Loss:0.082
Batch: 843/843	Loss:0.031
Epoch: 25	Train Loss: 0.104	Val F1: 0.715
Best Epoch: 17	Best Epoch Val F1: 0.731

******************************Epoch: 26******************************
Batch: 1/843	Loss:0.098
Batch: 85/843	Loss:0.253
Batch: 169/843	Loss:0.154
Batch: 253/843	Loss:0.184
Batch: 337/843	Loss:0.131
Batch: 421/843	Loss:0.208
Batch: 505/843	Loss:0.074
Batch: 589/843	Loss:0.153
Batch: 673/843	Loss:0.079
Batch: 757/843	Loss:0.112
Batch: 841/843	Loss:0.275
Batch: 843/843	Loss:0.001
Epoch: 26	Train Loss: 0.102	Val F1: 0.707
Best Epoch: 17	Best Epoch Val F1: 0.731

******************************Epoch: 27******************************
Batch: 1/843	Loss:0.048
Batch: 85/843	Loss:0.016
Batch: 169/843	Loss:0.127
Batch: 253/843	Loss:0.312
Batch: 337/843	Loss:0.216
Batch: 421/843	Loss:0.175
Batch: 505/843	Loss:0.137
Batch: 589/843	Loss:0.115
Batch: 673/843	Loss:0.008
Batch: 757/843	Loss:0.128
Batch: 841/843	Loss:0.061
Batch: 843/843	Loss:0.269
Epoch: 27	Train Loss: 0.102	Val F1: 0.709
Best Epoch: 17	Best Epoch Val F1: 0.731

******************************Epoch: 28******************************
Batch: 1/843	Loss:0.105
Batch: 85/843	Loss:0.171
Batch: 169/843	Loss:0.150
Batch: 253/843	Loss:0.051
Batch: 337/843	Loss:0.056
Batch: 421/843	Loss:0.033
Batch: 505/843	Loss:0.027
Batch: 589/843	Loss:0.043
Batch: 673/843	Loss:0.025
Batch: 757/843	Loss:0.072
Batch: 841/843	Loss:0.082
Batch: 843/843	Loss:0.158
Epoch: 28	Train Loss: 0.089	Val F1: 0.708
Best Epoch: 17	Best Epoch Val F1: 0.731

******************************Epoch: 29******************************
Batch: 1/843	Loss:0.025
Batch: 85/843	Loss:0.033
Batch: 169/843	Loss:0.058
Batch: 253/843	Loss:0.002
Batch: 337/843	Loss:0.042
Batch: 421/843	Loss:0.055
Batch: 505/843	Loss:0.062
Batch: 589/843	Loss:0.037
Batch: 673/843	Loss:0.065
Batch: 757/843	Loss:0.011
Batch: 841/843	Loss:0.150
Batch: 843/843	Loss:0.096
Epoch: 29	Train Loss: 0.099	Val F1: 0.721
Best Epoch: 17	Best Epoch Val F1: 0.731

******************************Epoch: 30******************************
Batch: 1/843	Loss:0.175
Batch: 85/843	Loss:0.035
Batch: 169/843	Loss:0.190
Batch: 253/843	Loss:0.040
Batch: 337/843	Loss:0.004
Batch: 421/843	Loss:0.054
Batch: 505/843	Loss:0.216
Batch: 589/843	Loss:0.067
Batch: 673/843	Loss:0.195
Batch: 757/843	Loss:0.037
Batch: 841/843	Loss:0.028
Batch: 843/843	Loss:0.000
Epoch: 30	Train Loss: 0.091	Val F1: 0.706
Best Epoch: 17	Best Epoch Val F1: 0.731

******************************Epoch: 31******************************
Batch: 1/843	Loss:0.163
Batch: 85/843	Loss:0.144
Batch: 169/843	Loss:0.125
Batch: 253/843	Loss:0.151
Batch: 337/843	Loss:0.115
Batch: 421/843	Loss:0.144
Batch: 505/843	Loss:0.008
Batch: 589/843	Loss:0.156
Batch: 673/843	Loss:0.002
Batch: 757/843	Loss:0.106
Batch: 841/843	Loss:0.036
Batch: 843/843	Loss:0.318
Epoch: 31	Train Loss: 0.088	Val F1: 0.702
Best Epoch: 17	Best Epoch Val F1: 0.731

******************************Epoch: 32******************************
Batch: 1/843	Loss:0.058
Batch: 85/843	Loss:0.055
Batch: 169/843	Loss:0.136
Batch: 253/843	Loss:0.039
Batch: 337/843	Loss:0.020
Batch: 421/843	Loss:0.015
Batch: 505/843	Loss:0.091
Batch: 589/843	Loss:0.057
Batch: 673/843	Loss:0.067
Batch: 757/843	Loss:0.167
Batch: 841/843	Loss:0.042
Batch: 843/843	Loss:0.069
Epoch: 32	Train Loss: 0.093	Val F1: 0.713
Best Epoch: 17	Best Epoch Val F1: 0.731

Saving the best checkpoint....
Inference...
Test F1: 0.724	Test F1_Few: 0.733	Test F1_Zero: 0.714
Starting training with config: {'batch_size': 16, 'epochs': 50, 'l2_reg': 1.7103089447261418e-05, 'lr': 3.1266983901951186e-05, 'n_layers_freeze': 4, 'patience': 10}
Let's use 1 GPUs!
Preparing data....
Training data....
# of train examples: 13477
max len: 512, max len wiki: 1
Val data....
# of val examples: 2062
max len: 512, max len wiki: 1
Test data....
# of test examples: 3006
max len: 512, max len wiki: 1
Done

Initializing model....
******************************Epoch: 1******************************
Batch: 1/843	Loss:1.114
Batch: 85/843	Loss:1.130
Batch: 169/843	Loss:1.153
Batch: 253/843	Loss:0.826
Batch: 337/843	Loss:0.904
Batch: 421/843	Loss:0.474
Batch: 505/843	Loss:0.551
Batch: 589/843	Loss:0.519
Batch: 673/843	Loss:0.834
Batch: 757/843	Loss:0.604
Batch: 841/843	Loss:0.757
Batch: 843/843	Loss:0.886
Epoch: 1	Train Loss: 0.806	Val F1: 0.675
Best Epoch: 1	Best Epoch Val F1: 0.675

******************************Epoch: 2******************************
Batch: 1/843	Loss:0.508
Batch: 85/843	Loss:0.830
Batch: 169/843	Loss:0.905
Batch: 253/843	Loss:0.544
Batch: 337/843	Loss:0.455
Batch: 421/843	Loss:0.777
Batch: 505/843	Loss:0.587
Batch: 589/843	Loss:0.936
Batch: 673/843	Loss:0.597
Batch: 757/843	Loss:0.568
Batch: 841/843	Loss:0.627
Batch: 843/843	Loss:0.693
Epoch: 2	Train Loss: 0.587	Val F1: 0.711
Best Epoch: 2	Best Epoch Val F1: 0.711

******************************Epoch: 3******************************
Batch: 1/843	Loss:0.394
Batch: 85/843	Loss:0.502
Batch: 169/843	Loss:0.435
Batch: 253/843	Loss:0.378
Batch: 337/843	Loss:0.619
Batch: 421/843	Loss:0.729
Batch: 505/843	Loss:0.409
Batch: 589/843	Loss:0.624
Batch: 673/843	Loss:0.360
Batch: 757/843	Loss:0.625
Batch: 841/843	Loss:0.329
Batch: 843/843	Loss:0.074
Epoch: 3	Train Loss: 0.491	Val F1: 0.714
Best Epoch: 3	Best Epoch Val F1: 0.714

******************************Epoch: 4******************************
Batch: 1/843	Loss:0.265
Batch: 85/843	Loss:0.551
Batch: 169/843	Loss:0.286
Batch: 253/843	Loss:0.663
Batch: 337/843	Loss:0.375
Batch: 421/843	Loss:0.535
Batch: 505/843	Loss:0.462
Batch: 589/843	Loss:0.257
Batch: 673/843	Loss:0.522
Batch: 757/843	Loss:0.528
Batch: 841/843	Loss:0.166
Batch: 843/843	Loss:0.653
Epoch: 4	Train Loss: 0.420	Val F1: 0.676
Best Epoch: 3	Best Epoch Val F1: 0.714

******************************Epoch: 5******************************
Batch: 1/843	Loss:0.539
Batch: 85/843	Loss:0.374
Batch: 169/843	Loss:0.404
Batch: 253/843	Loss:0.322
Batch: 337/843	Loss:0.498
Batch: 421/843	Loss:0.400
Batch: 505/843	Loss:0.173
Batch: 589/843	Loss:1.086
Batch: 673/843	Loss:0.223
Batch: 757/843	Loss:0.364
Batch: 841/843	Loss:0.287
Batch: 843/843	Loss:0.691
Epoch: 5	Train Loss: 0.374	Val F1: 0.708
Best Epoch: 3	Best Epoch Val F1: 0.714

******************************Epoch: 6******************************
Batch: 1/843	Loss:0.157
Batch: 85/843	Loss:0.269
Batch: 169/843	Loss:0.214
Batch: 253/843	Loss:0.277
Batch: 337/843	Loss:0.311
Batch: 421/843	Loss:0.219
Batch: 505/843	Loss:0.289
Batch: 589/843	Loss:0.337
Batch: 673/843	Loss:0.259
Batch: 757/843	Loss:0.135
Batch: 841/843	Loss:0.390
Batch: 843/843	Loss:0.028
Epoch: 6	Train Loss: 0.332	Val F1: 0.711
Best Epoch: 3	Best Epoch Val F1: 0.714

******************************Epoch: 7******************************
Batch: 1/843	Loss:0.312
Batch: 85/843	Loss:0.109
Batch: 169/843	Loss:0.278
Batch: 253/843	Loss:0.116
Batch: 337/843	Loss:0.779
Batch: 421/843	Loss:0.109
Batch: 505/843	Loss:0.168
Batch: 589/843	Loss:0.172
Batch: 673/843	Loss:0.363
Batch: 757/843	Loss:0.344
Batch: 841/843	Loss:0.557
Batch: 843/843	Loss:0.292
Epoch: 7	Train Loss: 0.298	Val F1: 0.709
Best Epoch: 3	Best Epoch Val F1: 0.714

******************************Epoch: 8******************************
Batch: 1/843	Loss:0.171
Batch: 85/843	Loss:0.339
Batch: 169/843	Loss:0.083
Batch: 253/843	Loss:0.315
Batch: 337/843	Loss:0.165
Batch: 421/843	Loss:0.239
Batch: 505/843	Loss:0.403
Batch: 589/843	Loss:0.176
Batch: 673/843	Loss:0.218
Batch: 757/843	Loss:0.229
Batch: 841/843	Loss:0.272
Batch: 843/843	Loss:0.216
Epoch: 8	Train Loss: 0.266	Val F1: 0.690
Best Epoch: 3	Best Epoch Val F1: 0.714

******************************Epoch: 9******************************
Batch: 1/843	Loss:0.459
Batch: 85/843	Loss:0.194
Batch: 169/843	Loss:0.341
Batch: 253/843	Loss:0.743
Batch: 337/843	Loss:0.124
Batch: 421/843	Loss:0.453
Batch: 505/843	Loss:0.357
Batch: 589/843	Loss:0.215
Batch: 673/843	Loss:0.364
Batch: 757/843	Loss:0.195
Batch: 841/843	Loss:0.180
Batch: 843/843	Loss:0.553
Epoch: 9	Train Loss: 0.243	Val F1: 0.734
Best Epoch: 9	Best Epoch Val F1: 0.734

******************************Epoch: 10******************************
Batch: 1/843	Loss:0.325
Batch: 85/843	Loss:0.329
Batch: 169/843	Loss:0.206
Batch: 253/843	Loss:0.234
Batch: 337/843	Loss:0.260
Batch: 421/843	Loss:0.187
Batch: 505/843	Loss:0.315
Batch: 589/843	Loss:0.093
Batch: 673/843	Loss:0.119
Batch: 757/843	Loss:0.196
Batch: 841/843	Loss:0.040
Batch: 843/843	Loss:0.060
Epoch: 10	Train Loss: 0.217	Val F1: 0.722
Best Epoch: 9	Best Epoch Val F1: 0.734

******************************Epoch: 11******************************
Batch: 1/843	Loss:0.380
Batch: 85/843	Loss:0.279
Batch: 169/843	Loss:0.164
Batch: 253/843	Loss:0.129
Batch: 337/843	Loss:0.192
Batch: 421/843	Loss:0.179
Batch: 505/843	Loss:0.424
Batch: 589/843	Loss:0.089
Batch: 673/843	Loss:0.375
Batch: 757/843	Loss:0.125
Batch: 841/843	Loss:0.183
Batch: 843/843	Loss:0.151
Epoch: 11	Train Loss: 0.198	Val F1: 0.720
Best Epoch: 9	Best Epoch Val F1: 0.734

******************************Epoch: 12******************************
Batch: 1/843	Loss:0.255
Batch: 85/843	Loss:0.045
Batch: 169/843	Loss:0.109
Batch: 253/843	Loss:0.162
Batch: 337/843	Loss:0.303
Batch: 421/843	Loss:0.134
Batch: 505/843	Loss:0.262
Batch: 589/843	Loss:0.111
Batch: 673/843	Loss:0.085
Batch: 757/843	Loss:0.092
Batch: 841/843	Loss:0.108
Batch: 843/843	Loss:0.002
Epoch: 12	Train Loss: 0.186	Val F1: 0.715
Best Epoch: 9	Best Epoch Val F1: 0.734

******************************Epoch: 13******************************
Batch: 1/843	Loss:0.114
Batch: 85/843	Loss:0.327
Batch: 169/843	Loss:0.289
Batch: 253/843	Loss:0.559
Batch: 337/843	Loss:0.059
Batch: 421/843	Loss:0.019
Batch: 505/843	Loss:0.096
Batch: 589/843	Loss:0.206
Batch: 673/843	Loss:0.138
Batch: 757/843	Loss:0.174
Batch: 841/843	Loss:0.307
Batch: 843/843	Loss:0.563
Epoch: 13	Train Loss: 0.169	Val F1: 0.716
Best Epoch: 9	Best Epoch Val F1: 0.734

******************************Epoch: 14******************************
Batch: 1/843	Loss:0.062
Batch: 85/843	Loss:0.071
Batch: 169/843	Loss:0.056
Batch: 253/843	Loss:0.063
Batch: 337/843	Loss:0.142
Batch: 421/843	Loss:0.126
Batch: 505/843	Loss:0.077
Batch: 589/843	Loss:0.029
Batch: 673/843	Loss:0.192
Batch: 757/843	Loss:0.049
Batch: 841/843	Loss:0.317
Batch: 843/843	Loss:0.019
Epoch: 14	Train Loss: 0.160	Val F1: 0.715
Best Epoch: 9	Best Epoch Val F1: 0.734

******************************Epoch: 15******************************
Batch: 1/843	Loss:0.033
Batch: 85/843	Loss:0.044
Batch: 169/843	Loss:0.381
Batch: 253/843	Loss:0.277
Batch: 337/843	Loss:0.091
Batch: 421/843	Loss:0.069
Batch: 505/843	Loss:0.103
Batch: 589/843	Loss:0.049
Batch: 673/843	Loss:0.190
Batch: 757/843	Loss:0.065
Batch: 841/843	Loss:0.350
Batch: 843/843	Loss:0.089
Epoch: 15	Train Loss: 0.154	Val F1: 0.683
Best Epoch: 9	Best Epoch Val F1: 0.734

******************************Epoch: 16******************************
Batch: 1/843	Loss:0.183
Batch: 85/843	Loss:0.089
Batch: 169/843	Loss:0.240
Batch: 253/843	Loss:0.102
Batch: 337/843	Loss:0.394
Batch: 421/843	Loss:0.091
Batch: 505/843	Loss:0.105
Batch: 589/843	Loss:0.084
Batch: 673/843	Loss:0.180
Batch: 757/843	Loss:0.180
Batch: 841/843	Loss:0.164
Batch: 843/843	Loss:0.195
Epoch: 16	Train Loss: 0.142	Val F1: 0.703
Best Epoch: 9	Best Epoch Val F1: 0.734

******************************Epoch: 17******************************
Batch: 1/843	Loss:0.043
Batch: 85/843	Loss:0.142
Batch: 169/843	Loss:0.458
Batch: 253/843	Loss:0.069
Batch: 337/843	Loss:0.037
Batch: 421/843	Loss:0.019
Batch: 505/843	Loss:0.214
Batch: 589/843	Loss:0.079
Batch: 673/843	Loss:0.106
Batch: 757/843	Loss:0.145
Batch: 841/843	Loss:0.062
Batch: 843/843	Loss:0.048
Epoch: 17	Train Loss: 0.141	Val F1: 0.711
Best Epoch: 9	Best Epoch Val F1: 0.734

******************************Epoch: 18******************************
Batch: 1/843	Loss:0.102
Batch: 85/843	Loss:0.069
Batch: 169/843	Loss:0.159
Batch: 253/843	Loss:0.314
Batch: 337/843	Loss:0.358
Batch: 421/843	Loss:0.191
Batch: 505/843	Loss:0.152
Batch: 589/843	Loss:0.161
Batch: 673/843	Loss:0.048
Batch: 757/843	Loss:0.163
Batch: 841/843	Loss:0.121
Batch: 843/843	Loss:0.303
Epoch: 18	Train Loss: 0.134	Val F1: 0.713
Best Epoch: 9	Best Epoch Val F1: 0.734

******************************Epoch: 19******************************
Batch: 1/843	Loss:0.221
Batch: 85/843	Loss:0.103
Batch: 169/843	Loss:0.042
Batch: 253/843	Loss:0.175
Batch: 337/843	Loss:0.060
Batch: 421/843	Loss:0.068
Batch: 505/843	Loss:0.163
Batch: 589/843	Loss:0.183
Batch: 673/843	Loss:0.125
Batch: 757/843	Loss:0.181
Batch: 841/843	Loss:0.069
Batch: 843/843	Loss:0.058
Epoch: 19	Train Loss: 0.132	Val F1: 0.714
Best Epoch: 9	Best Epoch Val F1: 0.734

Saving the best checkpoint....
Inference...
Test F1: 0.739	Test F1_Few: 0.758	Test F1_Zero: 0.718
Starting training with config: {'batch_size': 4, 'epochs': 50, 'l2_reg': 7.938403030078804e-05, 'lr': 4.933302500960058e-05, 'n_layers_freeze': 3, 'patience': 5}
Let's use 1 GPUs!
Preparing data....
Training data....
# of train examples: 13477
max len: 512, max len wiki: 1
Val data....
# of val examples: 2062
max len: 512, max len wiki: 1
Test data....
# of test examples: 3006
max len: 512, max len wiki: 1
Done

Initializing model....
******************************Epoch: 1******************************
Batch: 1/3370	Loss:1.322
Batch: 338/3370	Loss:1.212
Batch: 675/3370	Loss:1.094
Batch: 1012/3370	Loss:1.133
Batch: 1349/3370	Loss:0.808
Batch: 1686/3370	Loss:1.376
Batch: 2023/3370	Loss:1.027
Batch: 2360/3370	Loss:1.269
Batch: 2697/3370	Loss:0.966
Batch: 3034/3370	Loss:1.049
Batch: 3370/3370	Loss:0.929
Epoch: 1	Train Loss: 1.056	Val F1: 0.166
Best Epoch: 1	Best Epoch Val F1: 0.166

******************************Epoch: 2******************************
Batch: 1/3370	Loss:1.093
Batch: 338/3370	Loss:0.872
Batch: 675/3370	Loss:0.934
Batch: 1012/3370	Loss:0.917
Batch: 1349/3370	Loss:1.086
Batch: 1686/3370	Loss:0.854
Batch: 2023/3370	Loss:0.895
Batch: 2360/3370	Loss:1.096
Batch: 2697/3370	Loss:0.952
Batch: 3034/3370	Loss:0.900
Batch: 3370/3370	Loss:1.628
Epoch: 2	Train Loss: 1.052	Val F1: 0.166
Best Epoch: 1	Best Epoch Val F1: 0.166

******************************Epoch: 3******************************
Batch: 1/3370	Loss:1.107
Batch: 338/3370	Loss:1.090
Batch: 675/3370	Loss:0.937
Batch: 1012/3370	Loss:1.058
Batch: 1349/3370	Loss:1.066
Batch: 1686/3370	Loss:0.980
Batch: 2023/3370	Loss:1.237
Batch: 2360/3370	Loss:1.350
Batch: 2697/3370	Loss:0.935
Batch: 3034/3370	Loss:1.165
Batch: 3370/3370	Loss:0.778
Epoch: 3	Train Loss: 1.063	Val F1: 0.166
Best Epoch: 1	Best Epoch Val F1: 0.166

******************************Epoch: 4******************************
Batch: 1/3370	Loss:0.865
Batch: 338/3370	Loss:0.795
Batch: 675/3370	Loss:1.129
Batch: 1012/3370	Loss:0.997
Batch: 1349/3370	Loss:0.911
Batch: 1686/3370	Loss:1.102
Batch: 2023/3370	Loss:1.157
Batch: 2360/3370	Loss:1.203
Batch: 2697/3370	Loss:0.885
Batch: 3034/3370	Loss:1.140
Batch: 3370/3370	Loss:1.750
Epoch: 4	Train Loss: 1.062	Val F1: 0.166
Best Epoch: 1	Best Epoch Val F1: 0.166

******************************Epoch: 5******************************
Batch: 1/3370	Loss:1.271
Batch: 338/3370	Loss:0.967
Batch: 675/3370	Loss:0.872
Batch: 1012/3370	Loss:1.171
Batch: 1349/3370	Loss:0.850
Batch: 1686/3370	Loss:0.998
Batch: 2023/3370	Loss:1.365
Batch: 2360/3370	Loss:1.293
Batch: 2697/3370	Loss:1.129
Batch: 3034/3370	Loss:0.985
Batch: 3370/3370	Loss:0.909
Epoch: 5	Train Loss: 1.060	Val F1: 0.166
Best Epoch: 1	Best Epoch Val F1: 0.166

******************************Epoch: 6******************************
Batch: 1/3370	Loss:1.567
Batch: 338/3370	Loss:1.151
Batch: 675/3370	Loss:0.873
Batch: 1012/3370	Loss:1.067
Batch: 1349/3370	Loss:1.057
Batch: 1686/3370	Loss:1.138
Batch: 2023/3370	Loss:1.027
Batch: 2360/3370	Loss:0.970
Batch: 2697/3370	Loss:1.101
Batch: 3034/3370	Loss:1.064
Batch: 3370/3370	Loss:1.696
Epoch: 6	Train Loss: 1.061	Val F1: 0.166
Best Epoch: 1	Best Epoch Val F1: 0.166

Saving the best checkpoint....
Inference...
Test F1: 0.169	Test F1_Few: 0.170	Test F1_Zero: 0.168
Starting training with config: {'batch_size': 64, 'epochs': 75, 'l2_reg': 7.169510348412174e-05, 'lr': 3.738983060718425e-05, 'n_layers_freeze': 3, 'patience': 5}
Let's use 1 GPUs!
Preparing data....
Training data....
# of train examples: 13477
max len: 512, max len wiki: 1
Val data....
# of val examples: 2062
max len: 512, max len wiki: 1
Test data....
# of test examples: 3006
max len: 512, max len wiki: 1
Done

Initializing model....
******************************Epoch: 1******************************
Batch: 1/211	Loss:1.300
Batch: 22/211	Loss:1.035
Batch: 43/211	Loss:1.133
Batch: 64/211	Loss:1.005
Batch: 85/211	Loss:1.049
Batch: 106/211	Loss:0.915
Batch: 127/211	Loss:0.690
Batch: 148/211	Loss:0.693
Batch: 169/211	Loss:0.711
Batch: 190/211	Loss:0.580
Batch: 211/211	Loss:0.761
Epoch: 1	Train Loss: 0.884	Val F1: 0.675
Best Epoch: 1	Best Epoch Val F1: 0.675

******************************Epoch: 2******************************
Batch: 1/211	Loss:0.679
Batch: 22/211	Loss:0.691
Batch: 43/211	Loss:0.695
Batch: 64/211	Loss:0.639
Batch: 85/211	Loss:0.639
Batch: 106/211	Loss:0.725
Batch: 127/211	Loss:0.705
Batch: 148/211	Loss:0.620
Batch: 169/211	Loss:0.607
Batch: 190/211	Loss:0.551
Batch: 211/211	Loss:0.451
Epoch: 2	Train Loss: 0.591	Val F1: 0.712
Best Epoch: 2	Best Epoch Val F1: 0.712

******************************Epoch: 3******************************
Batch: 1/211	Loss:0.496
Batch: 22/211	Loss:0.504
Batch: 43/211	Loss:0.415
Batch: 64/211	Loss:0.434
Batch: 85/211	Loss:0.421
Batch: 106/211	Loss:0.623
Batch: 127/211	Loss:0.346
Batch: 148/211	Loss:0.595
Batch: 169/211	Loss:0.502
Batch: 190/211	Loss:0.484
Batch: 211/211	Loss:0.422
Epoch: 3	Train Loss: 0.484	Val F1: 0.744
Best Epoch: 3	Best Epoch Val F1: 0.744

******************************Epoch: 4******************************
Batch: 1/211	Loss:0.317
Batch: 22/211	Loss:0.418
Batch: 43/211	Loss:0.399
Batch: 64/211	Loss:0.397
Batch: 85/211	Loss:0.410
Batch: 106/211	Loss:0.362
Batch: 127/211	Loss:0.362
Batch: 148/211	Loss:0.344
Batch: 169/211	Loss:0.451
Batch: 190/211	Loss:0.451
Batch: 211/211	Loss:0.345
Epoch: 4	Train Loss: 0.412	Val F1: 0.648
Best Epoch: 3	Best Epoch Val F1: 0.744

******************************Epoch: 5******************************
Batch: 1/211	Loss:0.435
Batch: 22/211	Loss:0.451
Batch: 43/211	Loss:0.224
Batch: 64/211	Loss:0.380
Batch: 85/211	Loss:0.395
Batch: 106/211	Loss:0.445
Batch: 127/211	Loss:0.309
Batch: 148/211	Loss:0.400
Batch: 169/211	Loss:0.369
Batch: 190/211	Loss:0.417
Batch: 211/211	Loss:0.406
Epoch: 5	Train Loss: 0.361	Val F1: 0.714
Best Epoch: 3	Best Epoch Val F1: 0.744

******************************Epoch: 6******************************
Batch: 1/211	Loss:0.248
Batch: 22/211	Loss:0.226
Batch: 43/211	Loss:0.327
Batch: 64/211	Loss:0.326
Batch: 85/211	Loss:0.301
Batch: 106/211	Loss:0.494
Batch: 127/211	Loss:0.353
Batch: 148/211	Loss:0.256
Batch: 169/211	Loss:0.408
Batch: 190/211	Loss:0.314
Batch: 211/211	Loss:0.206
Epoch: 6	Train Loss: 0.318	Val F1: 0.722
Best Epoch: 3	Best Epoch Val F1: 0.744

******************************Epoch: 7******************************
Batch: 1/211	Loss:0.302
Batch: 22/211	Loss:0.157
Batch: 43/211	Loss:0.263
Batch: 64/211	Loss:0.318
Batch: 85/211	Loss:0.335
Batch: 106/211	Loss:0.347
Batch: 127/211	Loss:0.377
Batch: 148/211	Loss:0.335
Batch: 169/211	Loss:0.330
Batch: 190/211	Loss:0.431
Batch: 211/211	Loss:0.321
Epoch: 7	Train Loss: 0.275	Val F1: 0.717
Best Epoch: 3	Best Epoch Val F1: 0.744

******************************Epoch: 8******************************
Batch: 1/211	Loss:0.138
Batch: 22/211	Loss:0.225
Batch: 43/211	Loss:0.215
Batch: 64/211	Loss:0.229
Batch: 85/211	Loss:0.344
Batch: 106/211	Loss:0.157
Batch: 127/211	Loss:0.235
Batch: 148/211	Loss:0.206
Batch: 169/211	Loss:0.354
Batch: 190/211	Loss:0.213
Batch: 211/211	Loss:0.445
Epoch: 8	Train Loss: 0.240	Val F1: 0.699
Best Epoch: 3	Best Epoch Val F1: 0.744

Saving the best checkpoint....
Inference...
Test F1: 0.737	Test F1_Few: 0.746	Test F1_Zero: 0.727
Starting training with config: {'batch_size': 8, 'epochs': 75, 'l2_reg': 4.295032419077487e-05, 'lr': 2.2563616654732652e-05, 'n_layers_freeze': 1, 'patience': 10}
Let's use 1 GPUs!
Preparing data....
Training data....
# of train examples: 13477
max len: 512, max len wiki: 1
Val data....
# of val examples: 2062
max len: 512, max len wiki: 1
Test data....
# of test examples: 3006
max len: 512, max len wiki: 1
Done

Initializing model....
******************************Epoch: 1******************************
Batch: 1/1685	Loss:1.082
Batch: 169/1685	Loss:1.105
Batch: 337/1685	Loss:1.072
Batch: 505/1685	Loss:0.674
Batch: 673/1685	Loss:0.452
Batch: 841/1685	Loss:0.558
Batch: 1009/1685	Loss:0.432
Batch: 1177/1685	Loss:0.487
Batch: 1345/1685	Loss:0.741
Batch: 1513/1685	Loss:0.649
Batch: 1681/1685	Loss:0.857
Batch: 1685/1685	Loss:0.870
Epoch: 1	Train Loss: 0.759	Val F1: 0.655
Best Epoch: 1	Best Epoch Val F1: 0.655

******************************Epoch: 2******************************
Batch: 1/1685	Loss:0.398
Batch: 169/1685	Loss:1.181
Batch: 337/1685	Loss:1.036
Batch: 505/1685	Loss:0.387
Batch: 673/1685	Loss:0.380
Batch: 841/1685	Loss:1.074
Batch: 1009/1685	Loss:0.371
Batch: 1177/1685	Loss:0.312
Batch: 1345/1685	Loss:0.559
Batch: 1513/1685	Loss:0.800
Batch: 1681/1685	Loss:0.269
Batch: 1685/1685	Loss:0.314
Epoch: 2	Train Loss: 0.571	Val F1: 0.726
Best Epoch: 2	Best Epoch Val F1: 0.726

******************************Epoch: 3******************************
Batch: 1/1685	Loss:0.229
Batch: 169/1685	Loss:0.562
Batch: 337/1685	Loss:0.387
Batch: 505/1685	Loss:0.404
Batch: 673/1685	Loss:0.547
Batch: 841/1685	Loss:1.175
Batch: 1009/1685	Loss:0.412
Batch: 1177/1685	Loss:0.471
Batch: 1345/1685	Loss:0.151
Batch: 1513/1685	Loss:0.747
Batch: 1681/1685	Loss:0.350
Batch: 1685/1685	Loss:0.060
Epoch: 3	Train Loss: 0.481	Val F1: 0.699
Best Epoch: 2	Best Epoch Val F1: 0.726

******************************Epoch: 4******************************
Batch: 1/1685	Loss:0.209
Batch: 169/1685	Loss:0.696
Batch: 337/1685	Loss:0.629
Batch: 505/1685	Loss:0.387
Batch: 673/1685	Loss:0.304
Batch: 841/1685	Loss:1.273
Batch: 1009/1685	Loss:0.717
Batch: 1177/1685	Loss:0.320
Batch: 1345/1685	Loss:0.648
Batch: 1513/1685	Loss:0.136
Batch: 1681/1685	Loss:0.096
Batch: 1685/1685	Loss:1.028
Epoch: 4	Train Loss: 0.411	Val F1: 0.700
Best Epoch: 2	Best Epoch Val F1: 0.726

******************************Epoch: 5******************************
Batch: 1/1685	Loss:0.488
Batch: 169/1685	Loss:0.321
Batch: 337/1685	Loss:0.241
Batch: 505/1685	Loss:0.205
Batch: 673/1685	Loss:0.644
Batch: 841/1685	Loss:0.287
Batch: 1009/1685	Loss:0.228
Batch: 1177/1685	Loss:0.418
Batch: 1345/1685	Loss:0.426
Batch: 1513/1685	Loss:0.284
Batch: 1681/1685	Loss:0.256
Batch: 1685/1685	Loss:0.321
Epoch: 5	Train Loss: 0.364	Val F1: 0.703
Best Epoch: 2	Best Epoch Val F1: 0.726

******************************Epoch: 6******************************
Batch: 1/1685	Loss:0.140
Batch: 169/1685	Loss:0.059
Batch: 337/1685	Loss:0.250
Batch: 505/1685	Loss:0.284
Batch: 673/1685	Loss:0.163
Batch: 841/1685	Loss:0.311
Batch: 1009/1685	Loss:0.281
Batch: 1177/1685	Loss:0.299
Batch: 1345/1685	Loss:0.268
Batch: 1513/1685	Loss:0.104
Batch: 1681/1685	Loss:0.159
Batch: 1685/1685	Loss:0.105
Epoch: 6	Train Loss: 0.323	Val F1: 0.709
Best Epoch: 2	Best Epoch Val F1: 0.726

******************************Epoch: 7******************************
Batch: 1/1685	Loss:0.455
Batch: 169/1685	Loss:0.134
Batch: 337/1685	Loss:0.154
Batch: 505/1685	Loss:0.420
Batch: 673/1685	Loss:0.198
Batch: 841/1685	Loss:0.159
Batch: 1009/1685	Loss:0.141
Batch: 1177/1685	Loss:0.268
Batch: 1345/1685	Loss:0.235
Batch: 1513/1685	Loss:0.695
Batch: 1681/1685	Loss:0.307
Batch: 1685/1685	Loss:0.327
Epoch: 7	Train Loss: 0.285	Val F1: 0.699
Best Epoch: 2	Best Epoch Val F1: 0.726

******************************Epoch: 8******************************
Batch: 1/1685	Loss:0.122
Batch: 169/1685	Loss:0.385
Batch: 337/1685	Loss:0.025
Batch: 505/1685	Loss:0.337
Batch: 673/1685	Loss:0.422
Batch: 841/1685	Loss:0.265
Batch: 1009/1685	Loss:0.385
Batch: 1177/1685	Loss:0.497
Batch: 1345/1685	Loss:0.039
Batch: 1513/1685	Loss:0.219
Batch: 1681/1685	Loss:0.231
Batch: 1685/1685	Loss:0.401
Epoch: 8	Train Loss: 0.252	Val F1: 0.668
Best Epoch: 2	Best Epoch Val F1: 0.726

******************************Epoch: 9******************************
Batch: 1/1685	Loss:0.580
Batch: 169/1685	Loss:0.392
Batch: 337/1685	Loss:0.581
Batch: 505/1685	Loss:0.307
Batch: 673/1685	Loss:0.134
Batch: 841/1685	Loss:0.508
Batch: 1009/1685	Loss:0.270
Batch: 1177/1685	Loss:0.249
Batch: 1345/1685	Loss:0.743
Batch: 1513/1685	Loss:0.071
Batch: 1681/1685	Loss:0.016
Batch: 1685/1685	Loss:0.221
Epoch: 9	Train Loss: 0.226	Val F1: 0.698
Best Epoch: 2	Best Epoch Val F1: 0.726

******************************Epoch: 10******************************
Batch: 1/1685	Loss:0.059
Batch: 169/1685	Loss:0.308
Batch: 337/1685	Loss:0.247
Batch: 505/1685	Loss:0.003
Batch: 673/1685	Loss:0.718
Batch: 841/1685	Loss:0.151
Batch: 1009/1685	Loss:0.428
Batch: 1177/1685	Loss:0.140
Batch: 1345/1685	Loss:0.049
Batch: 1513/1685	Loss:0.414
Batch: 1681/1685	Loss:0.103
Batch: 1685/1685	Loss:0.096
Epoch: 10	Train Loss: 0.216	Val F1: 0.709
Best Epoch: 2	Best Epoch Val F1: 0.726

******************************Epoch: 11******************************
Batch: 1/1685	Loss:0.392
Batch: 169/1685	Loss:0.350
Batch: 337/1685	Loss:0.334
Batch: 505/1685	Loss:0.046
Batch: 673/1685	Loss:0.084
Batch: 841/1685	Loss:0.879
Batch: 1009/1685	Loss:0.544
Batch: 1177/1685	Loss:0.090
Batch: 1345/1685	Loss:0.416
Batch: 1513/1685	Loss:0.074
Batch: 1681/1685	Loss:0.275
Batch: 1685/1685	Loss:0.022
Epoch: 11	Train Loss: 0.193	Val F1: 0.694
Best Epoch: 2	Best Epoch Val F1: 0.726

******************************Epoch: 12******************************
Batch: 1/1685	Loss:0.147
Batch: 169/1685	Loss:0.049
Batch: 337/1685	Loss:0.319
Batch: 505/1685	Loss:0.372
Batch: 673/1685	Loss:0.009
Batch: 841/1685	Loss:0.381
Batch: 1009/1685	Loss:0.355
Batch: 1177/1685	Loss:0.115
Batch: 1345/1685	Loss:0.011
Batch: 1513/1685	Loss:0.007
Batch: 1681/1685	Loss:0.097
Batch: 1685/1685	Loss:0.002
Epoch: 12	Train Loss: 0.181	Val F1: 0.715
Best Epoch: 2	Best Epoch Val F1: 0.726

Saving the best checkpoint....
Inference...
Test F1: 0.741	Test F1_Few: 0.759	Test F1_Zero: 0.721
Starting training with config: {'batch_size': 16, 'epochs': 75, 'l2_reg': 4.283153321737122e-05, 'lr': 4.6729890196438976e-05, 'n_layers_freeze': 3, 'patience': 15}
Let's use 1 GPUs!
Preparing data....
Training data....
# of train examples: 13477
max len: 512, max len wiki: 1
Val data....
# of val examples: 2062
max len: 512, max len wiki: 1
Test data....
# of test examples: 3006
max len: 512, max len wiki: 1
Done

Initializing model....
******************************Epoch: 1******************************
Batch: 1/843	Loss:1.114
Batch: 85/843	Loss:1.136
Batch: 169/843	Loss:1.110
Batch: 253/843	Loss:0.780
Batch: 337/843	Loss:0.845
Batch: 421/843	Loss:0.605
Batch: 505/843	Loss:0.381
Batch: 589/843	Loss:0.504
Batch: 673/843	Loss:0.848
Batch: 757/843	Loss:0.695
Batch: 841/843	Loss:0.773
Batch: 843/843	Loss:0.758
Epoch: 1	Train Loss: 0.826	Val F1: 0.645
Best Epoch: 1	Best Epoch Val F1: 0.645

******************************Epoch: 2******************************
Batch: 1/843	Loss:0.551
Batch: 85/843	Loss:0.781
Batch: 169/843	Loss:0.854
Batch: 253/843	Loss:0.538
Batch: 337/843	Loss:0.845
Batch: 421/843	Loss:0.738
Batch: 505/843	Loss:0.705
Batch: 589/843	Loss:1.187
Batch: 673/843	Loss:0.711
Batch: 757/843	Loss:0.674
Batch: 841/843	Loss:0.804
Batch: 843/843	Loss:0.691
Epoch: 2	Train Loss: 0.633	Val F1: 0.660
Best Epoch: 2	Best Epoch Val F1: 0.660

******************************Epoch: 3******************************
Batch: 1/843	Loss:0.535
Batch: 85/843	Loss:0.476
Batch: 169/843	Loss:0.461
Batch: 253/843	Loss:0.374
Batch: 337/843	Loss:0.599
Batch: 421/843	Loss:0.780
Batch: 505/843	Loss:0.402
Batch: 589/843	Loss:0.824
Batch: 673/843	Loss:0.361
Batch: 757/843	Loss:0.702
Batch: 841/843	Loss:0.363
Batch: 843/843	Loss:0.186
Epoch: 3	Train Loss: 0.535	Val F1: 0.702
Best Epoch: 3	Best Epoch Val F1: 0.702

******************************Epoch: 4******************************
Batch: 1/843	Loss:0.341
Batch: 85/843	Loss:0.635
Batch: 169/843	Loss:0.403
Batch: 253/843	Loss:0.696
Batch: 337/843	Loss:0.318
Batch: 421/843	Loss:0.621
Batch: 505/843	Loss:0.581
Batch: 589/843	Loss:0.309
Batch: 673/843	Loss:0.798
Batch: 757/843	Loss:0.326
Batch: 841/843	Loss:0.157
Batch: 843/843	Loss:1.607
Epoch: 4	Train Loss: 0.468	Val F1: 0.678
Best Epoch: 3	Best Epoch Val F1: 0.702

******************************Epoch: 5******************************
Batch: 1/843	Loss:0.517
Batch: 85/843	Loss:0.427
Batch: 169/843	Loss:0.709
Batch: 253/843	Loss:0.294
Batch: 337/843	Loss:0.697
Batch: 421/843	Loss:0.468
Batch: 505/843	Loss:0.340
Batch: 589/843	Loss:0.643
Batch: 673/843	Loss:0.349
Batch: 757/843	Loss:0.579
Batch: 841/843	Loss:0.243
Batch: 843/843	Loss:0.582
Epoch: 5	Train Loss: 0.417	Val F1: 0.671
Best Epoch: 3	Best Epoch Val F1: 0.702

******************************Epoch: 6******************************
Batch: 1/843	Loss:0.256
Batch: 85/843	Loss:0.108
Batch: 169/843	Loss:0.377
Batch: 253/843	Loss:0.465
Batch: 337/843	Loss:0.529
Batch: 421/843	Loss:0.349
Batch: 505/843	Loss:0.412
Batch: 589/843	Loss:0.439
Batch: 673/843	Loss:0.341
Batch: 757/843	Loss:0.449
Batch: 841/843	Loss:0.333
Batch: 843/843	Loss:0.075
Epoch: 6	Train Loss: 0.377	Val F1: 0.719
Best Epoch: 6	Best Epoch Val F1: 0.719

******************************Epoch: 7******************************
Batch: 1/843	Loss:0.248
Batch: 85/843	Loss:0.260
Batch: 169/843	Loss:0.297
Batch: 253/843	Loss:0.155
Batch: 337/843	Loss:0.653
Batch: 421/843	Loss:0.117
Batch: 505/843	Loss:0.166
Batch: 589/843	Loss:0.313
Batch: 673/843	Loss:0.354
Batch: 757/843	Loss:0.432
Batch: 841/843	Loss:0.441
Batch: 843/843	Loss:0.189
Epoch: 7	Train Loss: 0.340	Val F1: 0.688
Best Epoch: 6	Best Epoch Val F1: 0.719

******************************Epoch: 8******************************
Batch: 1/843	Loss:0.212
Batch: 85/843	Loss:0.195
Batch: 169/843	Loss:0.114
Batch: 253/843	Loss:0.163
Batch: 337/843	Loss:0.179
Batch: 421/843	Loss:0.559
Batch: 505/843	Loss:0.482
Batch: 589/843	Loss:0.353
Batch: 673/843	Loss:0.115
Batch: 757/843	Loss:0.238
Batch: 841/843	Loss:0.281
Batch: 843/843	Loss:0.427
Epoch: 8	Train Loss: 0.302	Val F1: 0.651
Best Epoch: 6	Best Epoch Val F1: 0.719

******************************Epoch: 9******************************
Batch: 1/843	Loss:0.674
Batch: 85/843	Loss:0.274
Batch: 169/843	Loss:0.506
Batch: 253/843	Loss:0.350
Batch: 337/843	Loss:0.591
Batch: 421/843	Loss:0.394
Batch: 505/843	Loss:0.327
Batch: 589/843	Loss:0.234
Batch: 673/843	Loss:0.267
Batch: 757/843	Loss:0.227
Batch: 841/843	Loss:0.372
Batch: 843/843	Loss:0.341
Epoch: 9	Train Loss: 0.275	Val F1: 0.724
Best Epoch: 9	Best Epoch Val F1: 0.724

******************************Epoch: 10******************************
Batch: 1/843	Loss:0.289
Batch: 85/843	Loss:0.429
Batch: 169/843	Loss:0.312
Batch: 253/843	Loss:0.133
Batch: 337/843	Loss:0.164
Batch: 421/843	Loss:0.174
Batch: 505/843	Loss:0.211
Batch: 589/843	Loss:0.208
Batch: 673/843	Loss:0.104
Batch: 757/843	Loss:0.348
Batch: 841/843	Loss:0.076
Batch: 843/843	Loss:0.082
Epoch: 10	Train Loss: 0.254	Val F1: 0.701
Best Epoch: 9	Best Epoch Val F1: 0.724

******************************Epoch: 11******************************
Batch: 1/843	Loss:0.472
Batch: 85/843	Loss:0.564
Batch: 169/843	Loss:0.392
Batch: 253/843	Loss:0.122
Batch: 337/843	Loss:0.153
Batch: 421/843	Loss:0.379
Batch: 505/843	Loss:0.243
Batch: 589/843	Loss:0.070
Batch: 673/843	Loss:0.386
Batch: 757/843	Loss:0.114
Batch: 841/843	Loss:0.198
Batch: 843/843	Loss:0.038
Epoch: 11	Train Loss: 0.230	Val F1: 0.695
Best Epoch: 9	Best Epoch Val F1: 0.724

******************************Epoch: 12******************************
Batch: 1/843	Loss:0.276
Batch: 85/843	Loss:0.044
Batch: 169/843	Loss:0.163
Batch: 253/843	Loss:0.216
Batch: 337/843	Loss:0.153
Batch: 421/843	Loss:0.253
Batch: 505/843	Loss:0.261
Batch: 589/843	Loss:0.160
Batch: 673/843	Loss:0.099
Batch: 757/843	Loss:0.064
Batch: 841/843	Loss:0.055
Batch: 843/843	Loss:0.001
Epoch: 12	Train Loss: 0.211	Val F1: 0.708
Best Epoch: 9	Best Epoch Val F1: 0.724

******************************Epoch: 13******************************
Batch: 1/843	Loss:0.052
Batch: 85/843	Loss:0.124
Batch: 169/843	Loss:0.212
Batch: 253/843	Loss:0.107
Batch: 337/843	Loss:0.085
Batch: 421/843	Loss:0.260
Batch: 505/843	Loss:0.200
Batch: 589/843	Loss:0.224
Batch: 673/843	Loss:0.189
Batch: 757/843	Loss:0.122
Batch: 841/843	Loss:0.214
Batch: 843/843	Loss:0.030
Epoch: 13	Train Loss: 0.208	Val F1: 0.708
Best Epoch: 9	Best Epoch Val F1: 0.724

******************************Epoch: 14******************************
Batch: 1/843	Loss:0.249
Batch: 85/843	Loss:0.109
Batch: 169/843	Loss:0.052
Batch: 253/843	Loss:0.111
Batch: 337/843	Loss:0.173
Batch: 421/843	Loss:0.343
Batch: 505/843	Loss:0.125
Batch: 589/843	Loss:0.094
Batch: 673/843	Loss:0.120
Batch: 757/843	Loss:0.054
Batch: 841/843	Loss:0.261
Batch: 843/843	Loss:0.103
Epoch: 14	Train Loss: 0.187	Val F1: 0.702
Best Epoch: 9	Best Epoch Val F1: 0.724

******************************Epoch: 15******************************
Batch: 1/843	Loss:0.043
Batch: 85/843	Loss:0.107
Batch: 169/843	Loss:0.179
Batch: 253/843	Loss:0.148
Batch: 337/843	Loss:0.149
Batch: 421/843	Loss:0.012
Batch: 505/843	Loss:0.187
Batch: 589/843	Loss:0.130
Batch: 673/843	Loss:0.163
Batch: 757/843	Loss:0.043
Batch: 841/843	Loss:0.203
Batch: 843/843	Loss:0.004
Epoch: 15	Train Loss: 0.179	Val F1: 0.682
Best Epoch: 9	Best Epoch Val F1: 0.724

******************************Epoch: 16******************************
Batch: 1/843	Loss:0.138
Batch: 85/843	Loss:0.103
Batch: 169/843	Loss:0.157
Batch: 253/843	Loss:0.136
Batch: 337/843	Loss:0.453
Batch: 421/843	Loss:0.062
Batch: 505/843	Loss:0.149
Batch: 589/843	Loss:0.133
Batch: 673/843	Loss:0.050
Batch: 757/843	Loss:0.195
Batch: 841/843	Loss:0.128
Batch: 843/843	Loss:0.277
Epoch: 16	Train Loss: 0.170	Val F1: 0.704
Best Epoch: 9	Best Epoch Val F1: 0.724

******************************Epoch: 17******************************
Batch: 1/843	Loss:0.080
Batch: 85/843	Loss:0.251
Batch: 169/843	Loss:0.009
Batch: 253/843	Loss:0.344
Batch: 337/843	Loss:0.036
Batch: 421/843	Loss:0.106
Batch: 505/843	Loss:0.436
Batch: 589/843	Loss:0.022
Batch: 673/843	Loss:0.351
Batch: 757/843	Loss:0.155
Batch: 841/843	Loss:0.076
Batch: 843/843	Loss:0.008
Epoch: 17	Train Loss: 0.165	Val F1: 0.679
Best Epoch: 9	Best Epoch Val F1: 0.724

******************************Epoch: 18******************************
Batch: 1/843	Loss:0.104
Batch: 85/843	Loss:0.047
Batch: 169/843	Loss:0.130
Batch: 253/843	Loss:0.122
Batch: 337/843	Loss:0.196
Batch: 421/843	Loss:0.122
Batch: 505/843	Loss:0.061
Batch: 589/843	Loss:0.089
Batch: 673/843	Loss:0.211
Batch: 757/843	Loss:0.095
Batch: 841/843	Loss:0.137
Batch: 843/843	Loss:0.064
Epoch: 18	Train Loss: 0.153	Val F1: 0.694
Best Epoch: 9	Best Epoch Val F1: 0.724

******************************Epoch: 19******************************
Batch: 1/843	Loss:0.223
Batch: 85/843	Loss:0.059
Batch: 169/843	Loss:0.160
Batch: 253/843	Loss:0.280
Batch: 337/843	Loss:0.107
Batch: 421/843	Loss:0.072
Batch: 505/843	Loss:0.084
Batch: 589/843	Loss:0.217
Batch: 673/843	Loss:0.145
Batch: 757/843	Loss:0.320
Batch: 841/843	Loss:0.010
Batch: 843/843	Loss:0.414
Epoch: 19	Train Loss: 0.156	Val F1: 0.685
Best Epoch: 9	Best Epoch Val F1: 0.724

******************************Epoch: 20******************************
Batch: 1/843	Loss:0.109
Batch: 85/843	Loss:0.213
Batch: 169/843	Loss:0.167
Batch: 253/843	Loss:0.096
Batch: 337/843	Loss:0.314
Batch: 421/843	Loss:0.145
Batch: 505/843	Loss:0.135
Batch: 589/843	Loss:0.179
Batch: 673/843	Loss:0.139
Batch: 757/843	Loss:0.341
Batch: 841/843	Loss:0.080
Batch: 843/843	Loss:0.142
Epoch: 20	Train Loss: 0.157	Val F1: 0.696
Best Epoch: 9	Best Epoch Val F1: 0.724

******************************Epoch: 21******************************
Batch: 1/843	Loss:0.028
Batch: 85/843	Loss:0.164
Batch: 169/843	Loss:0.183
Batch: 253/843	Loss:0.102
Batch: 337/843	Loss:0.047
Batch: 421/843	Loss:0.078
Batch: 505/843	Loss:0.202
Batch: 589/843	Loss:0.012
Batch: 673/843	Loss:0.094
Batch: 757/843	Loss:0.259
Batch: 841/843	Loss:0.018
Batch: 843/843	Loss:0.161
Epoch: 21	Train Loss: 0.139	Val F1: 0.694
Best Epoch: 9	Best Epoch Val F1: 0.724

******************************Epoch: 22******************************
Batch: 1/843	Loss:0.102
Batch: 85/843	Loss:0.025
Batch: 169/843	Loss:0.034
Batch: 253/843	Loss:0.541
Batch: 337/843	Loss:0.116
Batch: 421/843	Loss:0.075
Batch: 505/843	Loss:0.404
Batch: 589/843	Loss:0.326
Batch: 673/843	Loss:0.206
Batch: 757/843	Loss:0.027
Batch: 841/843	Loss:0.034
Batch: 843/843	Loss:0.153
Epoch: 22	Train Loss: 0.137	Val F1: 0.683
Best Epoch: 9	Best Epoch Val F1: 0.724

******************************Epoch: 23******************************
Batch: 1/843	Loss:0.205
Batch: 85/843	Loss:0.002
Batch: 169/843	Loss:0.117
Batch: 253/843	Loss:0.005
Batch: 337/843	Loss:0.149
Batch: 421/843	Loss:0.076
Batch: 505/843	Loss:0.089
Batch: 589/843	Loss:0.055
Batch: 673/843	Loss:0.432
Batch: 757/843	Loss:0.166
Batch: 841/843	Loss:0.040
Batch: 843/843	Loss:0.141
Epoch: 23	Train Loss: 0.136	Val F1: 0.687
Best Epoch: 9	Best Epoch Val F1: 0.724

******************************Epoch: 24******************************
Batch: 1/843	Loss:0.107
Batch: 85/843	Loss:0.011
Batch: 169/843	Loss:0.068
Batch: 253/843	Loss:0.021
Batch: 337/843	Loss:0.050
Batch: 421/843	Loss:0.216
Batch: 505/843	Loss:0.019
Batch: 589/843	Loss:0.116
Batch: 673/843	Loss:0.102
Batch: 757/843	Loss:0.099
Batch: 841/843	Loss:0.134
Batch: 843/843	Loss:0.144
Epoch: 24	Train Loss: 0.134	Val F1: 0.683
Best Epoch: 9	Best Epoch Val F1: 0.724

Saving the best checkpoint....
Inference...
Test F1: 0.731	Test F1_Few: 0.751	Test F1_Zero: 0.708
Starting training with config: {'batch_size': 8, 'epochs': 50, 'l2_reg': 6.661708491563726e-05, 'lr': 4.38916475428621e-05, 'n_layers_freeze': 4, 'patience': 10}
Let's use 1 GPUs!
Preparing data....
Training data....
# of train examples: 13477
max len: 512, max len wiki: 1
Val data....
# of val examples: 2062
max len: 512, max len wiki: 1
Test data....
# of test examples: 3006
max len: 512, max len wiki: 1
Done

Initializing model....
******************************Epoch: 1******************************
Batch: 1/1685	Loss:1.082
Batch: 169/1685	Loss:1.077
Batch: 337/1685	Loss:1.219
Batch: 505/1685	Loss:1.028
Batch: 673/1685	Loss:1.037
Batch: 841/1685	Loss:0.830
Batch: 1009/1685	Loss:0.805
Batch: 1177/1685	Loss:0.555
Batch: 1345/1685	Loss:1.423
Batch: 1513/1685	Loss:0.820
Batch: 1681/1685	Loss:1.093
Batch: 1685/1685	Loss:0.837
Epoch: 1	Train Loss: 0.914	Val F1: 0.645
Best Epoch: 1	Best Epoch Val F1: 0.645

******************************Epoch: 2******************************
Batch: 1/1685	Loss:0.602
Batch: 169/1685	Loss:1.155
Batch: 337/1685	Loss:0.719
Batch: 505/1685	Loss:0.575
Batch: 673/1685	Loss:0.377
Batch: 841/1685	Loss:0.993
Batch: 1009/1685	Loss:0.640
Batch: 1177/1685	Loss:0.502
Batch: 1345/1685	Loss:0.556
Batch: 1513/1685	Loss:0.603
Batch: 1681/1685	Loss:0.281
Batch: 1685/1685	Loss:0.361
Epoch: 2	Train Loss: 0.645	Val F1: 0.683
Best Epoch: 2	Best Epoch Val F1: 0.683

******************************Epoch: 3******************************
Batch: 1/1685	Loss:0.481
Batch: 169/1685	Loss:0.674
Batch: 337/1685	Loss:0.435
Batch: 505/1685	Loss:0.270
Batch: 673/1685	Loss:0.884
Batch: 841/1685	Loss:0.949
Batch: 1009/1685	Loss:0.507
Batch: 1177/1685	Loss:0.762
Batch: 1345/1685	Loss:0.186
Batch: 1513/1685	Loss:0.659
Batch: 1681/1685	Loss:0.430
Batch: 1685/1685	Loss:0.876
Epoch: 3	Train Loss: 0.555	Val F1: 0.687
Best Epoch: 3	Best Epoch Val F1: 0.687

******************************Epoch: 4******************************
Batch: 1/1685	Loss:0.232
Batch: 169/1685	Loss:1.081
Batch: 337/1685	Loss:0.399
Batch: 505/1685	Loss:0.824
Batch: 673/1685	Loss:0.365
Batch: 841/1685	Loss:0.437
Batch: 1009/1685	Loss:0.764
Batch: 1177/1685	Loss:0.495
Batch: 1345/1685	Loss:0.994
Batch: 1513/1685	Loss:0.200
Batch: 1681/1685	Loss:0.263
Batch: 1685/1685	Loss:0.640
Epoch: 4	Train Loss: 0.487	Val F1: 0.671
Best Epoch: 3	Best Epoch Val F1: 0.687

******************************Epoch: 5******************************
Batch: 1/1685	Loss:1.045
Batch: 169/1685	Loss:0.309
Batch: 337/1685	Loss:0.420
Batch: 505/1685	Loss:0.125
Batch: 673/1685	Loss:0.746
Batch: 841/1685	Loss:0.450
Batch: 1009/1685	Loss:0.495
Batch: 1177/1685	Loss:0.856
Batch: 1345/1685	Loss:0.516
Batch: 1513/1685	Loss:0.379
Batch: 1681/1685	Loss:0.406
Batch: 1685/1685	Loss:0.541
Epoch: 5	Train Loss: 0.441	Val F1: 0.674
Best Epoch: 3	Best Epoch Val F1: 0.687

******************************Epoch: 6******************************
Batch: 1/1685	Loss:0.166
Batch: 169/1685	Loss:0.053
Batch: 337/1685	Loss:0.291
Batch: 505/1685	Loss:0.460
Batch: 673/1685	Loss:0.319
Batch: 841/1685	Loss:0.371
Batch: 1009/1685	Loss:0.601
Batch: 1177/1685	Loss:0.497
Batch: 1345/1685	Loss:0.790
Batch: 1513/1685	Loss:0.208
Batch: 1681/1685	Loss:0.212
Batch: 1685/1685	Loss:0.076
Epoch: 6	Train Loss: 0.400	Val F1: 0.707
Best Epoch: 6	Best Epoch Val F1: 0.707

******************************Epoch: 7******************************
Batch: 1/1685	Loss:0.583
Batch: 169/1685	Loss:0.180
Batch: 337/1685	Loss:0.224
Batch: 505/1685	Loss:0.274
Batch: 673/1685	Loss:0.395
Batch: 841/1685	Loss:0.324
Batch: 1009/1685	Loss:0.108
Batch: 1177/1685	Loss:0.655
Batch: 1345/1685	Loss:0.299
Batch: 1513/1685	Loss:0.640
Batch: 1681/1685	Loss:0.210
Batch: 1685/1685	Loss:0.494
Epoch: 7	Train Loss: 0.364	Val F1: 0.671
Best Epoch: 6	Best Epoch Val F1: 0.707

******************************Epoch: 8******************************
Batch: 1/1685	Loss:0.244
Batch: 169/1685	Loss:0.732
Batch: 337/1685	Loss:0.014
Batch: 505/1685	Loss:0.322
Batch: 673/1685	Loss:0.861
Batch: 841/1685	Loss:0.312
Batch: 1009/1685	Loss:0.382
Batch: 1177/1685	Loss:0.471
Batch: 1345/1685	Loss:0.078
Batch: 1513/1685	Loss:0.265
Batch: 1681/1685	Loss:0.193
Batch: 1685/1685	Loss:0.222
Epoch: 8	Train Loss: 0.334	Val F1: 0.636
Best Epoch: 6	Best Epoch Val F1: 0.707

******************************Epoch: 9******************************
Batch: 1/1685	Loss:0.429
Batch: 169/1685	Loss:0.339
Batch: 337/1685	Loss:0.232
Batch: 505/1685	Loss:0.398
Batch: 673/1685	Loss:0.509
Batch: 841/1685	Loss:0.491
Batch: 1009/1685	Loss:0.316
Batch: 1177/1685	Loss:0.281
Batch: 1345/1685	Loss:0.527
Batch: 1513/1685	Loss:0.176
Batch: 1681/1685	Loss:0.194
Batch: 1685/1685	Loss:0.304
Epoch: 9	Train Loss: 0.310	Val F1: 0.690
Best Epoch: 6	Best Epoch Val F1: 0.707

******************************Epoch: 10******************************
Batch: 1/1685	Loss:0.187
Batch: 169/1685	Loss:0.276
Batch: 337/1685	Loss:0.285
Batch: 505/1685	Loss:0.035
Batch: 673/1685	Loss:0.250
Batch: 841/1685	Loss:0.148
Batch: 1009/1685	Loss:0.381
Batch: 1177/1685	Loss:0.284
Batch: 1345/1685	Loss:0.017
Batch: 1513/1685	Loss:0.070
Batch: 1681/1685	Loss:0.108
Batch: 1685/1685	Loss:0.243
Epoch: 10	Train Loss: 0.290	Val F1: 0.703
Best Epoch: 6	Best Epoch Val F1: 0.707

******************************Epoch: 11******************************
Batch: 1/1685	Loss:0.486
Batch: 169/1685	Loss:0.376
Batch: 337/1685	Loss:0.290
Batch: 505/1685	Loss:0.136
Batch: 673/1685	Loss:0.217
Batch: 841/1685	Loss:0.375
Batch: 1009/1685	Loss:0.394
Batch: 1177/1685	Loss:0.171
Batch: 1345/1685	Loss:0.570
Batch: 1513/1685	Loss:0.071
Batch: 1681/1685	Loss:0.072
Batch: 1685/1685	Loss:0.087
Epoch: 11	Train Loss: 0.262	Val F1: 0.654
Best Epoch: 6	Best Epoch Val F1: 0.707

******************************Epoch: 12******************************
Batch: 1/1685	Loss:0.288
Batch: 169/1685	Loss:0.020
Batch: 337/1685	Loss:0.218
Batch: 505/1685	Loss:0.709
Batch: 673/1685	Loss:0.153
Batch: 841/1685	Loss:0.402
Batch: 1009/1685	Loss:0.313
Batch: 1177/1685	Loss:0.201
Batch: 1345/1685	Loss:0.028
Batch: 1513/1685	Loss:0.177
Batch: 1681/1685	Loss:0.019
Batch: 1685/1685	Loss:0.009
Epoch: 12	Train Loss: 0.246	Val F1: 0.679
Best Epoch: 6	Best Epoch Val F1: 0.707

******************************Epoch: 13******************************
Batch: 1/1685	Loss:0.318
Batch: 169/1685	Loss:0.028
Batch: 337/1685	Loss:0.420
Batch: 505/1685	Loss:0.078
Batch: 673/1685	Loss:0.148
Batch: 841/1685	Loss:0.128
Batch: 1009/1685	Loss:0.105
Batch: 1177/1685	Loss:0.224
Batch: 1345/1685	Loss:0.113
Batch: 1513/1685	Loss:0.278
Batch: 1681/1685	Loss:0.299
Batch: 1685/1685	Loss:0.073
Epoch: 13	Train Loss: 0.238	Val F1: 0.703
Best Epoch: 6	Best Epoch Val F1: 0.707

******************************Epoch: 14******************************
Batch: 1/1685	Loss:0.343
Batch: 169/1685	Loss:0.065
Batch: 337/1685	Loss:0.058
Batch: 505/1685	Loss:0.161
Batch: 673/1685	Loss:0.498
Batch: 841/1685	Loss:0.490
Batch: 1009/1685	Loss:0.354
Batch: 1177/1685	Loss:0.237
Batch: 1345/1685	Loss:0.293
Batch: 1513/1685	Loss:0.077
Batch: 1681/1685	Loss:0.413
Batch: 1685/1685	Loss:0.405
Epoch: 14	Train Loss: 0.217	Val F1: 0.667
Best Epoch: 6	Best Epoch Val F1: 0.707

******************************Epoch: 15******************************
Batch: 1/1685	Loss:0.087
Batch: 169/1685	Loss:0.025
Batch: 337/1685	Loss:0.230
Batch: 505/1685	Loss:0.171
Batch: 673/1685	Loss:0.003
Batch: 841/1685	Loss:0.227
Batch: 1009/1685	Loss:0.363
Batch: 1177/1685	Loss:0.074
Batch: 1345/1685	Loss:0.272
Batch: 1513/1685	Loss:0.131
Batch: 1681/1685	Loss:0.314
Batch: 1685/1685	Loss:0.001
Epoch: 15	Train Loss: 0.214	Val F1: 0.698
Best Epoch: 6	Best Epoch Val F1: 0.707

******************************Epoch: 16******************************
Batch: 1/1685	Loss:0.119
Batch: 169/1685	Loss:0.150
Batch: 337/1685	Loss:0.380
Batch: 505/1685	Loss:0.562
Batch: 673/1685	Loss:0.389
Batch: 841/1685	Loss:0.216
Batch: 1009/1685	Loss:0.109
Batch: 1177/1685	Loss:0.007
Batch: 1345/1685	Loss:0.081
Batch: 1513/1685	Loss:0.111
Batch: 1681/1685	Loss:0.013
Batch: 1685/1685	Loss:0.288
Epoch: 16	Train Loss: 0.189	Val F1: 0.700
Best Epoch: 6	Best Epoch Val F1: 0.707

Saving the best checkpoint....
Inference...
Test F1: 0.732	Test F1_Few: 0.751	Test F1_Zero: 0.710
Starting training with config: {'batch_size': 32, 'epochs': 75, 'l2_reg': 3.325585080210383e-05, 'lr': 1.6370070540656677e-05, 'n_layers_freeze': 1, 'patience': 15}
Let's use 1 GPUs!
Preparing data....
Training data....
# of train examples: 13477
max len: 512, max len wiki: 1
Val data....
# of val examples: 2062
max len: 512, max len wiki: 1
Test data....
# of test examples: 3006
max len: 512, max len wiki: 1
Done

Initializing model....
******************************Epoch: 1******************************
Batch: 1/422	Loss:1.244
Batch: 43/422	Loss:1.070
Batch: 85/422	Loss:1.170
Batch: 127/422	Loss:1.026
Batch: 169/422	Loss:1.023
Batch: 211/422	Loss:0.874
Batch: 253/422	Loss:0.606
Batch: 295/422	Loss:0.710
Batch: 337/422	Loss:0.849
Batch: 379/422	Loss:0.530
Batch: 421/422	Loss:0.764
Batch: 422/422	Loss:0.629
Epoch: 1	Train Loss: 0.875	Val F1: 0.703
Best Epoch: 1	Best Epoch Val F1: 0.703

******************************Epoch: 2******************************
Batch: 1/422	Loss:0.654
Batch: 43/422	Loss:0.783
Batch: 85/422	Loss:0.670
Batch: 127/422	Loss:0.599
Batch: 169/422	Loss:0.540
Batch: 211/422	Loss:0.721
Batch: 253/422	Loss:0.605
Batch: 295/422	Loss:0.626
Batch: 337/422	Loss:0.724
Batch: 379/422	Loss:0.588
Batch: 421/422	Loss:0.476
Batch: 422/422	Loss:0.480
Epoch: 2	Train Loss: 0.596	Val F1: 0.705
Best Epoch: 2	Best Epoch Val F1: 0.705

******************************Epoch: 3******************************
Batch: 1/422	Loss:0.571
Batch: 43/422	Loss:0.466
Batch: 85/422	Loss:0.635
Batch: 127/422	Loss:0.487
Batch: 169/422	Loss:0.401
Batch: 211/422	Loss:0.647
Batch: 253/422	Loss:0.479
Batch: 295/422	Loss:0.591
Batch: 337/422	Loss:0.388
Batch: 379/422	Loss:0.545
Batch: 421/422	Loss:0.399
Batch: 422/422	Loss:0.565
Epoch: 3	Train Loss: 0.500	Val F1: 0.727
Best Epoch: 3	Best Epoch Val F1: 0.727

******************************Epoch: 4******************************
Batch: 1/422	Loss:0.344
Batch: 43/422	Loss:0.494
Batch: 85/422	Loss:0.507
Batch: 127/422	Loss:0.424
Batch: 169/422	Loss:0.715
Batch: 211/422	Loss:0.447
Batch: 253/422	Loss:0.370
Batch: 295/422	Loss:0.310
Batch: 337/422	Loss:0.595
Batch: 379/422	Loss:0.475
Batch: 421/422	Loss:0.363
Batch: 422/422	Loss:0.767
Epoch: 4	Train Loss: 0.432	Val F1: 0.697
Best Epoch: 3	Best Epoch Val F1: 0.727

******************************Epoch: 5******************************
Batch: 1/422	Loss:0.349
Batch: 43/422	Loss:0.324
Batch: 85/422	Loss:0.309
Batch: 127/422	Loss:0.234
Batch: 169/422	Loss:0.390
Batch: 211/422	Loss:0.429
Batch: 253/422	Loss:0.284
Batch: 295/422	Loss:0.409
Batch: 337/422	Loss:0.439
Batch: 379/422	Loss:0.306
Batch: 421/422	Loss:0.354
Batch: 422/422	Loss:0.394
Epoch: 5	Train Loss: 0.382	Val F1: 0.687
Best Epoch: 3	Best Epoch Val F1: 0.727

******************************Epoch: 6******************************
Batch: 1/422	Loss:0.252
Batch: 43/422	Loss:0.229
Batch: 85/422	Loss:0.395
Batch: 127/422	Loss:0.259
Batch: 169/422	Loss:0.381
Batch: 211/422	Loss:0.384
Batch: 253/422	Loss:0.181
Batch: 295/422	Loss:0.292
Batch: 337/422	Loss:0.409
Batch: 379/422	Loss:0.334
Batch: 421/422	Loss:0.329
Batch: 422/422	Loss:0.050
Epoch: 6	Train Loss: 0.336	Val F1: 0.718
Best Epoch: 3	Best Epoch Val F1: 0.727

******************************Epoch: 7******************************
Batch: 1/422	Loss:0.333
Batch: 43/422	Loss:0.181
Batch: 85/422	Loss:0.260
Batch: 127/422	Loss:0.173
Batch: 169/422	Loss:0.605
Batch: 211/422	Loss:0.419
Batch: 253/422	Loss:0.375
Batch: 295/422	Loss:0.445
Batch: 337/422	Loss:0.559
Batch: 379/422	Loss:0.457
Batch: 421/422	Loss:0.427
Batch: 422/422	Loss:0.200
Epoch: 7	Train Loss: 0.299	Val F1: 0.730
Best Epoch: 7	Best Epoch Val F1: 0.730

******************************Epoch: 8******************************
Batch: 1/422	Loss:0.226
Batch: 43/422	Loss:0.370
Batch: 85/422	Loss:0.148
Batch: 127/422	Loss:0.309
Batch: 169/422	Loss:0.215
Batch: 211/422	Loss:0.187
Batch: 253/422	Loss:0.382
Batch: 295/422	Loss:0.249
Batch: 337/422	Loss:0.203
Batch: 379/422	Loss:0.210
Batch: 421/422	Loss:0.389
Batch: 422/422	Loss:0.089
Epoch: 8	Train Loss: 0.277	Val F1: 0.700
Best Epoch: 7	Best Epoch Val F1: 0.730

******************************Epoch: 9******************************
Batch: 1/422	Loss:0.302
Batch: 43/422	Loss:0.172
Batch: 85/422	Loss:0.160
Batch: 127/422	Loss:0.296
Batch: 169/422	Loss:0.162
Batch: 211/422	Loss:0.190
Batch: 253/422	Loss:0.225
Batch: 295/422	Loss:0.248
Batch: 337/422	Loss:0.170
Batch: 379/422	Loss:0.130
Batch: 421/422	Loss:0.187
Batch: 422/422	Loss:0.378
Epoch: 9	Train Loss: 0.235	Val F1: 0.721
Best Epoch: 7	Best Epoch Val F1: 0.730

******************************Epoch: 10******************************
Batch: 1/422	Loss:0.196
Batch: 43/422	Loss:0.342
Batch: 85/422	Loss:0.207
Batch: 127/422	Loss:0.039
Batch: 169/422	Loss:0.132
Batch: 211/422	Loss:0.147
Batch: 253/422	Loss:0.190
Batch: 295/422	Loss:0.120
Batch: 337/422	Loss:0.075
Batch: 379/422	Loss:0.122
Batch: 421/422	Loss:0.053
Batch: 422/422	Loss:0.028
Epoch: 10	Train Loss: 0.216	Val F1: 0.714
Best Epoch: 7	Best Epoch Val F1: 0.730

******************************Epoch: 11******************************
Batch: 1/422	Loss:0.130
Batch: 43/422	Loss:0.178
Batch: 85/422	Loss:0.154
Batch: 127/422	Loss:0.151
Batch: 169/422	Loss:0.169
Batch: 211/422	Loss:0.119
Batch: 253/422	Loss:0.145
Batch: 295/422	Loss:0.088
Batch: 337/422	Loss:0.421
Batch: 379/422	Loss:0.066
Batch: 421/422	Loss:0.357
Batch: 422/422	Loss:0.068
Epoch: 11	Train Loss: 0.192	Val F1: 0.721
Best Epoch: 7	Best Epoch Val F1: 0.730

******************************Epoch: 12******************************
Batch: 1/422	Loss:0.145
Batch: 43/422	Loss:0.125
Batch: 85/422	Loss:0.171
Batch: 127/422	Loss:0.223
Batch: 169/422	Loss:0.122
Batch: 211/422	Loss:0.191
Batch: 253/422	Loss:0.153
Batch: 295/422	Loss:0.207
Batch: 337/422	Loss:0.112
Batch: 379/422	Loss:0.176
Batch: 421/422	Loss:0.221
Batch: 422/422	Loss:0.008
Epoch: 12	Train Loss: 0.182	Val F1: 0.711
Best Epoch: 7	Best Epoch Val F1: 0.730

******************************Epoch: 13******************************
Batch: 1/422	Loss:0.131
Batch: 43/422	Loss:0.235
Batch: 85/422	Loss:0.168
Batch: 127/422	Loss:0.106
Batch: 169/422	Loss:0.129
Batch: 211/422	Loss:0.091
Batch: 253/422	Loss:0.244
Batch: 295/422	Loss:0.242
Batch: 337/422	Loss:0.312
Batch: 379/422	Loss:0.218
Batch: 421/422	Loss:0.117
Batch: 422/422	Loss:0.075
Epoch: 13	Train Loss: 0.171	Val F1: 0.704
Best Epoch: 7	Best Epoch Val F1: 0.730

******************************Epoch: 14******************************
Batch: 1/422	Loss:0.133
Batch: 43/422	Loss:0.098
Batch: 85/422	Loss:0.044
Batch: 127/422	Loss:0.164
Batch: 169/422	Loss:0.148
Batch: 211/422	Loss:0.100
Batch: 253/422	Loss:0.069
Batch: 295/422	Loss:0.072
Batch: 337/422	Loss:0.090
Batch: 379/422	Loss:0.173
Batch: 421/422	Loss:0.189
Batch: 422/422	Loss:0.012
Epoch: 14	Train Loss: 0.154	Val F1: 0.690
Best Epoch: 7	Best Epoch Val F1: 0.730

******************************Epoch: 15******************************
Batch: 1/422	Loss:0.099
Batch: 43/422	Loss:0.040
Batch: 85/422	Loss:0.070
Batch: 127/422	Loss:0.101
Batch: 169/422	Loss:0.145
Batch: 211/422	Loss:0.104
Batch: 253/422	Loss:0.437
Batch: 295/422	Loss:0.150
Batch: 337/422	Loss:0.118
Batch: 379/422	Loss:0.037
Batch: 421/422	Loss:0.232
Batch: 422/422	Loss:0.002
Epoch: 15	Train Loss: 0.141	Val F1: 0.709
Best Epoch: 7	Best Epoch Val F1: 0.730

******************************Epoch: 16******************************
Batch: 1/422	Loss:0.091
Batch: 43/422	Loss:0.159
Batch: 85/422	Loss:0.158
Batch: 127/422	Loss:0.035
Batch: 169/422	Loss:0.219
Batch: 211/422	Loss:0.048
Batch: 253/422	Loss:0.107
Batch: 295/422	Loss:0.061
Batch: 337/422	Loss:0.074
Batch: 379/422	Loss:0.336
Batch: 421/422	Loss:0.159
Batch: 422/422	Loss:0.057
Epoch: 16	Train Loss: 0.135	Val F1: 0.699
Best Epoch: 7	Best Epoch Val F1: 0.730

******************************Epoch: 17******************************
Batch: 1/422	Loss:0.144
Batch: 43/422	Loss:0.287
Batch: 85/422	Loss:0.066
Batch: 127/422	Loss:0.055
Batch: 169/422	Loss:0.068
Batch: 211/422	Loss:0.037
Batch: 253/422	Loss:0.225
Batch: 295/422	Loss:0.062
Batch: 337/422	Loss:0.202
Batch: 379/422	Loss:0.199
Batch: 421/422	Loss:0.094
Batch: 422/422	Loss:0.040
Epoch: 17	Train Loss: 0.136	Val F1: 0.712
Best Epoch: 7	Best Epoch Val F1: 0.730

******************************Epoch: 18******************************
Batch: 1/422	Loss:0.101
Batch: 43/422	Loss:0.066
Batch: 85/422	Loss:0.148
Batch: 127/422	Loss:0.150
Batch: 169/422	Loss:0.100
Batch: 211/422	Loss:0.161
Batch: 253/422	Loss:0.109
Batch: 295/422	Loss:0.067
Batch: 337/422	Loss:0.043
Batch: 379/422	Loss:0.138
Batch: 421/422	Loss:0.213
Batch: 422/422	Loss:0.178
Epoch: 18	Train Loss: 0.123	Val F1: 0.712
Best Epoch: 7	Best Epoch Val F1: 0.730

******************************Epoch: 19******************************
Batch: 1/422	Loss:0.175
Batch: 43/422	Loss:0.162
Batch: 85/422	Loss:0.165
Batch: 127/422	Loss:0.153
Batch: 169/422	Loss:0.244
Batch: 211/422	Loss:0.096
Batch: 253/422	Loss:0.142
Batch: 295/422	Loss:0.095
Batch: 337/422	Loss:0.259
Batch: 379/422	Loss:0.166
Batch: 421/422	Loss:0.077
Batch: 422/422	Loss:0.008
Epoch: 19	Train Loss: 0.122	Val F1: 0.715
Best Epoch: 7	Best Epoch Val F1: 0.730

******************************Epoch: 20******************************
Batch: 1/422	Loss:0.034
Batch: 43/422	Loss:0.205
Batch: 85/422	Loss:0.125
Batch: 127/422	Loss:0.013
Batch: 169/422	Loss:0.167
Batch: 211/422	Loss:0.033
Batch: 253/422	Loss:0.042
Batch: 295/422	Loss:0.139
Batch: 337/422	Loss:0.173
Batch: 379/422	Loss:0.185
Batch: 421/422	Loss:0.073
Batch: 422/422	Loss:0.012
Epoch: 20	Train Loss: 0.117	Val F1: 0.711
Best Epoch: 7	Best Epoch Val F1: 0.730

******************************Epoch: 21******************************
Batch: 1/422	Loss:0.053
Batch: 43/422	Loss:0.074
Batch: 85/422	Loss:0.050
Batch: 127/422	Loss:0.050
Batch: 169/422	Loss:0.089
Batch: 211/422	Loss:0.056
Batch: 253/422	Loss:0.055
Batch: 295/422	Loss:0.019
Batch: 337/422	Loss:0.187
Batch: 379/422	Loss:0.171
Batch: 421/422	Loss:0.037
Batch: 422/422	Loss:0.295
Epoch: 21	Train Loss: 0.115	Val F1: 0.723
Best Epoch: 7	Best Epoch Val F1: 0.730

******************************Epoch: 22******************************
Batch: 1/422	Loss:0.064
Batch: 43/422	Loss:0.135
Batch: 85/422	Loss:0.048
Batch: 127/422	Loss:0.061
Batch: 169/422	Loss:0.117
Batch: 211/422	Loss:0.032
Batch: 253/422	Loss:0.094
Batch: 295/422	Loss:0.125
Batch: 337/422	Loss:0.278
Batch: 379/422	Loss:0.109
Batch: 421/422	Loss:0.149
Batch: 422/422	Loss:0.243
Epoch: 22	Train Loss: 0.112	Val F1: 0.705
Best Epoch: 7	Best Epoch Val F1: 0.730

Saving the best checkpoint....
Inference...
Test F1: 0.751	Test F1_Few: 0.758	Test F1_Zero: 0.743
Starting training with config: {'batch_size': 64, 'epochs': 50, 'l2_reg': 1.6286138334758273e-05, 'lr': 1.9137507123903045e-05, 'n_layers_freeze': 0, 'patience': 15}
Let's use 1 GPUs!
Preparing data....
Training data....
# of train examples: 13477
max len: 512, max len wiki: 1
Val data....
# of val examples: 2062
max len: 512, max len wiki: 1
Test data....
# of test examples: 3006
max len: 512, max len wiki: 1
Done

Initializing model....
******************************Epoch: 1******************************
Batch: 1/211	Loss:1.300
Batch: 22/211	Loss:1.033
Batch: 43/211	Loss:1.151
Batch: 64/211	Loss:1.012
Batch: 85/211	Loss:1.055
Batch: 106/211	Loss:0.988
Batch: 127/211	Loss:1.074
Batch: 148/211	Loss:0.996
Batch: 169/211	Loss:0.878
Batch: 190/211	Loss:0.628
Batch: 211/211	Loss:0.727
Epoch: 1	Train Loss: 0.955	Val F1: 0.679
Best Epoch: 1	Best Epoch Val F1: 0.679

******************************Epoch: 2******************************
Batch: 1/211	Loss:0.708
Batch: 22/211	Loss:0.721
Batch: 43/211	Loss:0.656
Batch: 64/211	Loss:0.610
Batch: 85/211	Loss:0.604
Batch: 106/211	Loss:0.826
Batch: 127/211	Loss:0.675
Batch: 148/211	Loss:0.665
Batch: 169/211	Loss:0.593
Batch: 190/211	Loss:0.512
Batch: 211/211	Loss:0.518
Epoch: 2	Train Loss: 0.605	Val F1: 0.714
Best Epoch: 2	Best Epoch Val F1: 0.714

******************************Epoch: 3******************************
Batch: 1/211	Loss:0.542
Batch: 22/211	Loss:0.482
Batch: 43/211	Loss:0.485
Batch: 64/211	Loss:0.435
Batch: 85/211	Loss:0.414
Batch: 106/211	Loss:0.567
Batch: 127/211	Loss:0.368
Batch: 148/211	Loss:0.520
Batch: 169/211	Loss:0.591
Batch: 190/211	Loss:0.470
Batch: 211/211	Loss:0.434
Epoch: 3	Train Loss: 0.489	Val F1: 0.736
Best Epoch: 3	Best Epoch Val F1: 0.736

******************************Epoch: 4******************************
Batch: 1/211	Loss:0.322
Batch: 22/211	Loss:0.443
Batch: 43/211	Loss:0.378
Batch: 64/211	Loss:0.378
Batch: 85/211	Loss:0.448
Batch: 106/211	Loss:0.414
Batch: 127/211	Loss:0.275
Batch: 148/211	Loss:0.456
Batch: 169/211	Loss:0.423
Batch: 190/211	Loss:0.525
Batch: 211/211	Loss:0.431
Epoch: 4	Train Loss: 0.419	Val F1: 0.650
Best Epoch: 3	Best Epoch Val F1: 0.736

******************************Epoch: 5******************************
Batch: 1/211	Loss:0.465
Batch: 22/211	Loss:0.360
Batch: 43/211	Loss:0.252
Batch: 64/211	Loss:0.448
Batch: 85/211	Loss:0.426
Batch: 106/211	Loss:0.278
Batch: 127/211	Loss:0.294
Batch: 148/211	Loss:0.414
Batch: 169/211	Loss:0.281
Batch: 190/211	Loss:0.362
Batch: 211/211	Loss:0.400
Epoch: 5	Train Loss: 0.364	Val F1: 0.705
Best Epoch: 3	Best Epoch Val F1: 0.736

******************************Epoch: 6******************************
Batch: 1/211	Loss:0.261
Batch: 22/211	Loss:0.266
Batch: 43/211	Loss:0.360
Batch: 64/211	Loss:0.273
Batch: 85/211	Loss:0.329
Batch: 106/211	Loss:0.429
Batch: 127/211	Loss:0.362
Batch: 148/211	Loss:0.269
Batch: 169/211	Loss:0.344
Batch: 190/211	Loss:0.274
Batch: 211/211	Loss:0.182
Epoch: 6	Train Loss: 0.320	Val F1: 0.744
Best Epoch: 6	Best Epoch Val F1: 0.744

******************************Epoch: 7******************************
Batch: 1/211	Loss:0.329
Batch: 22/211	Loss:0.188
Batch: 43/211	Loss:0.282
Batch: 64/211	Loss:0.302
Batch: 85/211	Loss:0.496
Batch: 106/211	Loss:0.325
Batch: 127/211	Loss:0.369
Batch: 148/211	Loss:0.324
Batch: 169/211	Loss:0.353
Batch: 190/211	Loss:0.414
Batch: 211/211	Loss:0.359
Epoch: 7	Train Loss: 0.279	Val F1: 0.738
Best Epoch: 6	Best Epoch Val F1: 0.744

******************************Epoch: 8******************************
Batch: 1/211	Loss:0.172
Batch: 22/211	Loss:0.186
Batch: 43/211	Loss:0.273
Batch: 64/211	Loss:0.243
Batch: 85/211	Loss:0.251
Batch: 106/211	Loss:0.203
Batch: 127/211	Loss:0.316
Batch: 148/211	Loss:0.291
Batch: 169/211	Loss:0.309
Batch: 190/211	Loss:0.344
Batch: 211/211	Loss:0.353
Epoch: 8	Train Loss: 0.250	Val F1: 0.725
Best Epoch: 6	Best Epoch Val F1: 0.744

******************************Epoch: 9******************************
Batch: 1/211	Loss:0.187
Batch: 22/211	Loss:0.244
Batch: 43/211	Loss:0.276
Batch: 64/211	Loss:0.303
Batch: 85/211	Loss:0.239
Batch: 106/211	Loss:0.189
Batch: 127/211	Loss:0.153
Batch: 148/211	Loss:0.240
Batch: 169/211	Loss:0.128
Batch: 190/211	Loss:0.230
Batch: 211/211	Loss:0.195
Epoch: 9	Train Loss: 0.214	Val F1: 0.721
Best Epoch: 6	Best Epoch Val F1: 0.744

******************************Epoch: 10******************************
Batch: 1/211	Loss:0.177
Batch: 22/211	Loss:0.236
Batch: 43/211	Loss:0.166
Batch: 64/211	Loss:0.102
Batch: 85/211	Loss:0.177
Batch: 106/211	Loss:0.156
Batch: 127/211	Loss:0.232
Batch: 148/211	Loss:0.127
Batch: 169/211	Loss:0.114
Batch: 190/211	Loss:0.295
Batch: 211/211	Loss:0.099
Epoch: 10	Train Loss: 0.196	Val F1: 0.744
Best Epoch: 10	Best Epoch Val F1: 0.744

******************************Epoch: 11******************************
Batch: 1/211	Loss:0.112
Batch: 22/211	Loss:0.203
Batch: 43/211	Loss:0.124
Batch: 64/211	Loss:0.351
Batch: 85/211	Loss:0.313
Batch: 106/211	Loss:0.199
Batch: 127/211	Loss:0.184
Batch: 148/211	Loss:0.105
Batch: 169/211	Loss:0.211
Batch: 190/211	Loss:0.103
Batch: 211/211	Loss:0.177
Epoch: 11	Train Loss: 0.182	Val F1: 0.731
Best Epoch: 10	Best Epoch Val F1: 0.744

******************************Epoch: 12******************************
Batch: 1/211	Loss:0.114
Batch: 22/211	Loss:0.218
Batch: 43/211	Loss:0.210
Batch: 64/211	Loss:0.160
Batch: 85/211	Loss:0.118
Batch: 106/211	Loss:0.184
Batch: 127/211	Loss:0.128
Batch: 148/211	Loss:0.279
Batch: 169/211	Loss:0.097
Batch: 190/211	Loss:0.105
Batch: 211/211	Loss:0.044
Epoch: 12	Train Loss: 0.158	Val F1: 0.724
Best Epoch: 10	Best Epoch Val F1: 0.744

******************************Epoch: 13******************************
Batch: 1/211	Loss:0.143
Batch: 22/211	Loss:0.226
Batch: 43/211	Loss:0.072
Batch: 64/211	Loss:0.086
Batch: 85/211	Loss:0.045
Batch: 106/211	Loss:0.075
Batch: 127/211	Loss:0.116
Batch: 148/211	Loss:0.230
Batch: 169/211	Loss:0.118
Batch: 190/211	Loss:0.141
Batch: 211/211	Loss:0.167
Epoch: 13	Train Loss: 0.144	Val F1: 0.729
Best Epoch: 10	Best Epoch Val F1: 0.744

******************************Epoch: 14******************************
Batch: 1/211	Loss:0.093
Batch: 22/211	Loss:0.196
Batch: 43/211	Loss:0.078
Batch: 64/211	Loss:0.114
Batch: 85/211	Loss:0.104
Batch: 106/211	Loss:0.057
Batch: 127/211	Loss:0.075
Batch: 148/211	Loss:0.093
Batch: 169/211	Loss:0.076
Batch: 190/211	Loss:0.221
Batch: 211/211	Loss:0.186
Epoch: 14	Train Loss: 0.135	Val F1: 0.724
Best Epoch: 10	Best Epoch Val F1: 0.744

******************************Epoch: 15******************************
Batch: 1/211	Loss:0.079
Batch: 22/211	Loss:0.086
Batch: 43/211	Loss:0.056
Batch: 64/211	Loss:0.204
Batch: 85/211	Loss:0.082
Batch: 106/211	Loss:0.131
Batch: 127/211	Loss:0.209
Batch: 148/211	Loss:0.209
Batch: 169/211	Loss:0.103
Batch: 190/211	Loss:0.140
Batch: 211/211	Loss:0.162
Epoch: 15	Train Loss: 0.132	Val F1: 0.732
Best Epoch: 10	Best Epoch Val F1: 0.744

******************************Epoch: 16******************************
Batch: 1/211	Loss:0.101
Batch: 22/211	Loss:0.188
Batch: 43/211	Loss:0.070
Batch: 64/211	Loss:0.021
Batch: 85/211	Loss:0.142
Batch: 106/211	Loss:0.096
Batch: 127/211	Loss:0.155
Batch: 148/211	Loss:0.093
Batch: 169/211	Loss:0.053
Batch: 190/211	Loss:0.160
Batch: 211/211	Loss:0.141
Epoch: 16	Train Loss: 0.122	Val F1: 0.727
Best Epoch: 10	Best Epoch Val F1: 0.744

******************************Epoch: 17******************************
Batch: 1/211	Loss:0.114
Batch: 22/211	Loss:0.133
Batch: 43/211	Loss:0.109
Batch: 64/211	Loss:0.083
Batch: 85/211	Loss:0.058
Batch: 106/211	Loss:0.064
Batch: 127/211	Loss:0.185
Batch: 148/211	Loss:0.052
Batch: 169/211	Loss:0.116
Batch: 190/211	Loss:0.232
Batch: 211/211	Loss:0.037
Epoch: 17	Train Loss: 0.115	Val F1: 0.728
Best Epoch: 10	Best Epoch Val F1: 0.744

******************************Epoch: 18******************************
Batch: 1/211	Loss:0.163
Batch: 22/211	Loss:0.027
Batch: 43/211	Loss:0.075
Batch: 64/211	Loss:0.138
Batch: 85/211	Loss:0.131
Batch: 106/211	Loss:0.183
Batch: 127/211	Loss:0.105
Batch: 148/211	Loss:0.145
Batch: 169/211	Loss:0.066
Batch: 190/211	Loss:0.070
Batch: 211/211	Loss:0.184
Epoch: 18	Train Loss: 0.108	Val F1: 0.739
Best Epoch: 10	Best Epoch Val F1: 0.744

******************************Epoch: 19******************************
Batch: 1/211	Loss:0.096
Batch: 22/211	Loss:0.171
Batch: 43/211	Loss:0.116
Batch: 64/211	Loss:0.177
Batch: 85/211	Loss:0.084
Batch: 106/211	Loss:0.114
Batch: 127/211	Loss:0.113
Batch: 148/211	Loss:0.121
Batch: 169/211	Loss:0.174
Batch: 190/211	Loss:0.097
Batch: 211/211	Loss:0.075
Epoch: 19	Train Loss: 0.108	Val F1: 0.734
Best Epoch: 10	Best Epoch Val F1: 0.744

******************************Epoch: 20******************************
Batch: 1/211	Loss:0.075
Batch: 22/211	Loss:0.094
Batch: 43/211	Loss:0.082
Batch: 64/211	Loss:0.094
Batch: 85/211	Loss:0.148
Batch: 106/211	Loss:0.093
Batch: 127/211	Loss:0.055
Batch: 148/211	Loss:0.163
Batch: 169/211	Loss:0.125
Batch: 190/211	Loss:0.224
Batch: 211/211	Loss:0.034
Epoch: 20	Train Loss: 0.106	Val F1: 0.718
Best Epoch: 10	Best Epoch Val F1: 0.744

******************************Epoch: 21******************************
Batch: 1/211	Loss:0.068
Batch: 22/211	Loss:0.154
Batch: 43/211	Loss:0.059
Batch: 64/211	Loss:0.052
Batch: 85/211	Loss:0.127
Batch: 106/211	Loss:0.057
Batch: 127/211	Loss:0.118
Batch: 148/211	Loss:0.047
Batch: 169/211	Loss:0.142
Batch: 190/211	Loss:0.113
Batch: 211/211	Loss:0.106
Epoch: 21	Train Loss: 0.099	Val F1: 0.746
Best Epoch: 21	Best Epoch Val F1: 0.746

******************************Epoch: 22******************************
Batch: 1/211	Loss:0.037
Batch: 22/211	Loss:0.126
Batch: 43/211	Loss:0.090
Batch: 64/211	Loss:0.034
Batch: 85/211	Loss:0.082
Batch: 106/211	Loss:0.049
Batch: 127/211	Loss:0.121
Batch: 148/211	Loss:0.123
Batch: 169/211	Loss:0.101
Batch: 190/211	Loss:0.068
Batch: 211/211	Loss:0.202
Epoch: 22	Train Loss: 0.096	Val F1: 0.736
Best Epoch: 21	Best Epoch Val F1: 0.746

******************************Epoch: 23******************************
Batch: 1/211	Loss:0.067
Batch: 22/211	Loss:0.060
Batch: 43/211	Loss:0.136
Batch: 64/211	Loss:0.032
Batch: 85/211	Loss:0.052
Batch: 106/211	Loss:0.107
Batch: 127/211	Loss:0.097
Batch: 148/211	Loss:0.156
Batch: 169/211	Loss:0.158
Batch: 190/211	Loss:0.103
Batch: 211/211	Loss:0.158
Epoch: 23	Train Loss: 0.099	Val F1: 0.735
Best Epoch: 21	Best Epoch Val F1: 0.746

******************************Epoch: 24******************************
Batch: 1/211	Loss:0.076
Batch: 22/211	Loss:0.045
Batch: 43/211	Loss:0.112
Batch: 64/211	Loss:0.067
Batch: 85/211	Loss:0.060
Batch: 106/211	Loss:0.105
Batch: 127/211	Loss:0.102
Batch: 148/211	Loss:0.081
Batch: 169/211	Loss:0.054
Batch: 190/211	Loss:0.112
Batch: 211/211	Loss:0.120
Epoch: 24	Train Loss: 0.099	Val F1: 0.726
Best Epoch: 21	Best Epoch Val F1: 0.746

******************************Epoch: 25******************************
Batch: 1/211	Loss:0.071
Batch: 22/211	Loss:0.103
Batch: 43/211	Loss:0.079
Batch: 64/211	Loss:0.102
Batch: 85/211	Loss:0.075
Batch: 106/211	Loss:0.056
Batch: 127/211	Loss:0.085
Batch: 148/211	Loss:0.039
Batch: 169/211	Loss:0.051
Batch: 190/211	Loss:0.053
Batch: 211/211	Loss:0.122
Epoch: 25	Train Loss: 0.097	Val F1: 0.739
Best Epoch: 21	Best Epoch Val F1: 0.746

******************************Epoch: 26******************************
Batch: 1/211	Loss:0.049
Batch: 22/211	Loss:0.130
Batch: 43/211	Loss:0.023
Batch: 64/211	Loss:0.160
Batch: 85/211	Loss:0.105
Batch: 106/211	Loss:0.201
Batch: 127/211	Loss:0.100
Batch: 148/211	Loss:0.192
Batch: 169/211	Loss:0.131
Batch: 190/211	Loss:0.108
Batch: 211/211	Loss:0.084
Epoch: 26	Train Loss: 0.089	Val F1: 0.726
Best Epoch: 21	Best Epoch Val F1: 0.746

******************************Epoch: 27******************************
Batch: 1/211	Loss:0.029
Batch: 22/211	Loss:0.111
Batch: 43/211	Loss:0.086
Batch: 64/211	Loss:0.051
Batch: 85/211	Loss:0.133
Batch: 106/211	Loss:0.066
Batch: 127/211	Loss:0.104
Batch: 148/211	Loss:0.061
Batch: 169/211	Loss:0.105
Batch: 190/211	Loss:0.071
Batch: 211/211	Loss:0.090
Epoch: 27	Train Loss: 0.085	Val F1: 0.734
Best Epoch: 21	Best Epoch Val F1: 0.746

******************************Epoch: 28******************************
Batch: 1/211	Loss:0.026
Batch: 22/211	Loss:0.095
Batch: 43/211	Loss:0.134
Batch: 64/211	Loss:0.050
Batch: 85/211	Loss:0.077
Batch: 106/211	Loss:0.040
Batch: 127/211	Loss:0.200
Batch: 148/211	Loss:0.072
Batch: 169/211	Loss:0.116
Batch: 190/211	Loss:0.041
Batch: 211/211	Loss:0.096
Epoch: 28	Train Loss: 0.087	Val F1: 0.720
Best Epoch: 21	Best Epoch Val F1: 0.746

******************************Epoch: 29******************************
Batch: 1/211	Loss:0.031
Batch: 22/211	Loss:0.081
Batch: 43/211	Loss:0.041
Batch: 64/211	Loss:0.103
Batch: 85/211	Loss:0.073
Batch: 106/211	Loss:0.078
Batch: 127/211	Loss:0.079
Batch: 148/211	Loss:0.042
Batch: 169/211	Loss:0.152
Batch: 190/211	Loss:0.134
Batch: 211/211	Loss:0.108
Epoch: 29	Train Loss: 0.089	Val F1: 0.734
Best Epoch: 21	Best Epoch Val F1: 0.746

******************************Epoch: 30******************************
Batch: 1/211	Loss:0.112
Batch: 22/211	Loss:0.060
Batch: 43/211	Loss:0.064
Batch: 64/211	Loss:0.093
Batch: 85/211	Loss:0.084
Batch: 106/211	Loss:0.111
Batch: 127/211	Loss:0.070
Batch: 148/211	Loss:0.160
Batch: 169/211	Loss:0.138
Batch: 190/211	Loss:0.073
Batch: 211/211	Loss:0.087
Epoch: 30	Train Loss: 0.084	Val F1: 0.731
Best Epoch: 21	Best Epoch Val F1: 0.746

******************************Epoch: 31******************************
Batch: 1/211	Loss:0.066
Batch: 22/211	Loss:0.057
Batch: 43/211	Loss:0.065
Batch: 64/211	Loss:0.111
Batch: 85/211	Loss:0.075
Batch: 106/211	Loss:0.098
Batch: 127/211	Loss:0.067
Batch: 148/211	Loss:0.154
Batch: 169/211	Loss:0.039
Batch: 190/211	Loss:0.125
Batch: 211/211	Loss:0.056
Epoch: 31	Train Loss: 0.085	Val F1: 0.729
Best Epoch: 21	Best Epoch Val F1: 0.746

******************************Epoch: 32******************************
Batch: 1/211	Loss:0.034
Batch: 22/211	Loss:0.052
Batch: 43/211	Loss:0.071
Batch: 64/211	Loss:0.064
Batch: 85/211	Loss:0.077
Batch: 106/211	Loss:0.070
Batch: 127/211	Loss:0.090
Batch: 148/211	Loss:0.072
Batch: 169/211	Loss:0.029
Batch: 190/211	Loss:0.091
Batch: 211/211	Loss:0.095
Epoch: 32	Train Loss: 0.085	Val F1: 0.721
Best Epoch: 21	Best Epoch Val F1: 0.746

******************************Epoch: 33******************************
Batch: 1/211	Loss:0.081
Batch: 22/211	Loss:0.042
Batch: 43/211	Loss:0.057
Batch: 64/211	Loss:0.033
Batch: 85/211	Loss:0.072
Batch: 106/211	Loss:0.077
Batch: 127/211	Loss:0.095
Batch: 148/211	Loss:0.115
Batch: 169/211	Loss:0.073
Batch: 190/211	Loss:0.148
Batch: 211/211	Loss:0.161
Epoch: 33	Train Loss: 0.085	Val F1: 0.726
Best Epoch: 21	Best Epoch Val F1: 0.746

******************************Epoch: 34******************************
Batch: 1/211	Loss:0.061
Batch: 22/211	Loss:0.074
Batch: 43/211	Loss:0.102
Batch: 64/211	Loss:0.086
Batch: 85/211	Loss:0.187
Batch: 106/211	Loss:0.090
Batch: 127/211	Loss:0.097
Batch: 148/211	Loss:0.076
Batch: 169/211	Loss:0.036
Batch: 190/211	Loss:0.117
Batch: 211/211	Loss:0.059
Epoch: 34	Train Loss: 0.086	Val F1: 0.728
Best Epoch: 21	Best Epoch Val F1: 0.746

******************************Epoch: 35******************************
Batch: 1/211	Loss:0.164
Batch: 22/211	Loss:0.055
Batch: 43/211	Loss:0.046
Batch: 64/211	Loss:0.068
Batch: 85/211	Loss:0.128
Batch: 106/211	Loss:0.058
Batch: 127/211	Loss:0.073
Batch: 148/211	Loss:0.049
Batch: 169/211	Loss:0.107
Batch: 190/211	Loss:0.113
Batch: 211/211	Loss:0.165
Epoch: 35	Train Loss: 0.082	Val F1: 0.722
Best Epoch: 21	Best Epoch Val F1: 0.746

******************************Epoch: 36******************************
Batch: 1/211	Loss:0.035
Batch: 22/211	Loss:0.047
Batch: 43/211	Loss:0.065
Batch: 64/211	Loss:0.126
Batch: 85/211	Loss:0.064
Batch: 106/211	Loss:0.066
Batch: 127/211	Loss:0.095
Batch: 148/211	Loss:0.080
Batch: 169/211	Loss:0.056
Batch: 190/211	Loss:0.098
Batch: 211/211	Loss:0.091
Epoch: 36	Train Loss: 0.080	Val F1: 0.729
Best Epoch: 21	Best Epoch Val F1: 0.746

Saving the best checkpoint....
Inference...
Test F1: 0.738	Test F1_Few: 0.751	Test F1_Zero: 0.724
Starting training with config: {'batch_size': 4, 'epochs': 50, 'l2_reg': 5.3497768113913335e-05, 'lr': 5.871722474882151e-06, 'n_layers_freeze': 3, 'patience': 5}
Let's use 1 GPUs!
Preparing data....
Training data....
# of train examples: 13477
max len: 512, max len wiki: 1
Val data....
# of val examples: 2062
max len: 512, max len wiki: 1
Test data....
# of test examples: 3006
max len: 512, max len wiki: 1
Done

Initializing model....
******************************Epoch: 1******************************
Batch: 1/3370	Loss:1.322
Batch: 338/3370	Loss:1.211
Batch: 675/3370	Loss:0.976
Batch: 1012/3370	Loss:0.869
Batch: 1349/3370	Loss:0.695
Batch: 1686/3370	Loss:1.514
Batch: 2023/3370	Loss:0.350
Batch: 2360/3370	Loss:1.427
Batch: 2697/3370	Loss:0.725
Batch: 3034/3370	Loss:0.489
Batch: 3370/3370	Loss:1.278
Epoch: 1	Train Loss: 0.818	Val F1: 0.685
Best Epoch: 1	Best Epoch Val F1: 0.685

******************************Epoch: 2******************************
Batch: 1/3370	Loss:0.655
Batch: 338/3370	Loss:0.815
Batch: 675/3370	Loss:0.531
Batch: 1012/3370	Loss:0.699
Batch: 1349/3370	Loss:0.536
Batch: 1686/3370	Loss:0.462
Batch: 2023/3370	Loss:0.530
Batch: 2360/3370	Loss:0.532
Batch: 2697/3370	Loss:0.632
Batch: 3034/3370	Loss:0.494
Batch: 3370/3370	Loss:0.041
Epoch: 2	Train Loss: 0.619	Val F1: 0.701
Best Epoch: 2	Best Epoch Val F1: 0.701

******************************Epoch: 3******************************
Batch: 1/3370	Loss:0.276
Batch: 338/3370	Loss:0.440
Batch: 675/3370	Loss:0.647
Batch: 1012/3370	Loss:0.739
Batch: 1349/3370	Loss:0.562
Batch: 1686/3370	Loss:0.512
Batch: 2023/3370	Loss:0.585
Batch: 2360/3370	Loss:0.154
Batch: 2697/3370	Loss:0.141
Batch: 3034/3370	Loss:0.294
Batch: 3370/3370	Loss:0.082
Epoch: 3	Train Loss: 0.542	Val F1: 0.718
Best Epoch: 3	Best Epoch Val F1: 0.718

******************************Epoch: 4******************************
Batch: 1/3370	Loss:0.203
Batch: 338/3370	Loss:0.470
Batch: 675/3370	Loss:0.273
Batch: 1012/3370	Loss:0.746
Batch: 1349/3370	Loss:0.276
Batch: 1686/3370	Loss:0.428
Batch: 2023/3370	Loss:0.465
Batch: 2360/3370	Loss:0.331
Batch: 2697/3370	Loss:0.679
Batch: 3034/3370	Loss:0.955
Batch: 3370/3370	Loss:0.011
Epoch: 4	Train Loss: 0.465	Val F1: 0.704
Best Epoch: 3	Best Epoch Val F1: 0.718

******************************Epoch: 5******************************
Batch: 1/3370	Loss:0.783
Batch: 338/3370	Loss:0.502
Batch: 675/3370	Loss:0.301
Batch: 1012/3370	Loss:0.288
Batch: 1349/3370	Loss:0.089
Batch: 1686/3370	Loss:0.183
Batch: 2023/3370	Loss:0.086
Batch: 2360/3370	Loss:0.083
Batch: 2697/3370	Loss:1.069
Batch: 3034/3370	Loss:0.355
Batch: 3370/3370	Loss:0.869
Epoch: 5	Train Loss: 0.413	Val F1: 0.697
Best Epoch: 3	Best Epoch Val F1: 0.718

******************************Epoch: 6******************************
Batch: 1/3370	Loss:0.036
Batch: 338/3370	Loss:0.193
Batch: 675/3370	Loss:0.392
Batch: 1012/3370	Loss:0.155
Batch: 1349/3370	Loss:0.088
Batch: 1686/3370	Loss:0.606
Batch: 2023/3370	Loss:0.012
Batch: 2360/3370	Loss:0.364
Batch: 2697/3370	Loss:0.123
Batch: 3034/3370	Loss:0.916
Batch: 3370/3370	Loss:0.005
Epoch: 6	Train Loss: 0.372	Val F1: 0.713
Best Epoch: 3	Best Epoch Val F1: 0.718

******************************Epoch: 7******************************
Batch: 1/3370	Loss:0.361
Batch: 338/3370	Loss:0.174
Batch: 675/3370	Loss:0.111
Batch: 1012/3370	Loss:0.057
Batch: 1349/3370	Loss:0.064
Batch: 1686/3370	Loss:1.411
Batch: 2023/3370	Loss:0.364
Batch: 2360/3370	Loss:0.320
Batch: 2697/3370	Loss:0.393
Batch: 3034/3370	Loss:0.135
Batch: 3370/3370	Loss:0.010
Epoch: 7	Train Loss: 0.336	Val F1: 0.674
Best Epoch: 3	Best Epoch Val F1: 0.718

******************************Epoch: 8******************************
Batch: 1/3370	Loss:0.266
Batch: 338/3370	Loss:0.613
Batch: 675/3370	Loss:0.008
Batch: 1012/3370	Loss:0.442
Batch: 1349/3370	Loss:0.151
Batch: 1686/3370	Loss:0.180
Batch: 2023/3370	Loss:0.570
Batch: 2360/3370	Loss:0.217
Batch: 2697/3370	Loss:0.069
Batch: 3034/3370	Loss:0.100
Batch: 3370/3370	Loss:0.028
Epoch: 8	Train Loss: 0.305	Val F1: 0.670
Best Epoch: 3	Best Epoch Val F1: 0.718

Saving the best checkpoint....
Inference...
Test F1: 0.750	Test F1_Few: 0.760	Test F1_Zero: 0.738
Starting training with config: {'batch_size': 4, 'epochs': 25, 'l2_reg': 8.400875134714341e-05, 'lr': 4.526948693044074e-05, 'n_layers_freeze': 4, 'patience': 5}
Let's use 1 GPUs!
Preparing data....
Training data....
# of train examples: 13477
max len: 512, max len wiki: 1
Val data....
# of val examples: 2062
max len: 512, max len wiki: 1
Test data....
# of test examples: 3006
max len: 512, max len wiki: 1
Done

Initializing model....
******************************Epoch: 1******************************
Batch: 1/3370	Loss:1.322
Batch: 338/3370	Loss:1.255
Batch: 675/3370	Loss:1.077
Batch: 1012/3370	Loss:1.153
Batch: 1349/3370	Loss:0.944
Batch: 1686/3370	Loss:1.450
Batch: 2023/3370	Loss:0.476
Batch: 2360/3370	Loss:1.408
Batch: 2697/3370	Loss:0.687
Batch: 3034/3370	Loss:0.558
Batch: 3370/3370	Loss:0.782
Epoch: 1	Train Loss: 0.932	Val F1: 0.653
Best Epoch: 1	Best Epoch Val F1: 0.653

******************************Epoch: 2******************************
Batch: 1/3370	Loss:0.694
Batch: 338/3370	Loss:0.834
Batch: 675/3370	Loss:0.644
Batch: 1012/3370	Loss:0.614
Batch: 1349/3370	Loss:0.743
Batch: 1686/3370	Loss:0.504
Batch: 2023/3370	Loss:0.599
Batch: 2360/3370	Loss:0.569
Batch: 2697/3370	Loss:1.126
Batch: 3034/3370	Loss:0.506
Batch: 3370/3370	Loss:0.016
Epoch: 2	Train Loss: 0.668	Val F1: 0.692
Best Epoch: 2	Best Epoch Val F1: 0.692

******************************Epoch: 3******************************
Batch: 1/3370	Loss:0.302
Batch: 338/3370	Loss:1.165
Batch: 675/3370	Loss:0.943
Batch: 1012/3370	Loss:0.446
Batch: 1349/3370	Loss:0.443
Batch: 1686/3370	Loss:1.700
Batch: 2023/3370	Loss:0.365
Batch: 2360/3370	Loss:0.214
Batch: 2697/3370	Loss:0.168
Batch: 3034/3370	Loss:0.224
Batch: 3370/3370	Loss:0.610
Epoch: 3	Train Loss: 0.576	Val F1: 0.707
Best Epoch: 3	Best Epoch Val F1: 0.707

******************************Epoch: 4******************************
Batch: 1/3370	Loss:0.154
Batch: 338/3370	Loss:1.023
Batch: 675/3370	Loss:0.234
Batch: 1012/3370	Loss:0.539
Batch: 1349/3370	Loss:0.212
Batch: 1686/3370	Loss:0.386
Batch: 2023/3370	Loss:0.626
Batch: 2360/3370	Loss:0.412
Batch: 2697/3370	Loss:0.618
Batch: 3034/3370	Loss:1.319
Batch: 3370/3370	Loss:0.001
Epoch: 4	Train Loss: 0.505	Val F1: 0.673
Best Epoch: 3	Best Epoch Val F1: 0.707

******************************Epoch: 5******************************
Batch: 1/3370	Loss:0.771
Batch: 338/3370	Loss:0.749
Batch: 675/3370	Loss:0.306
Batch: 1012/3370	Loss:0.175
Batch: 1349/3370	Loss:0.039
Batch: 1686/3370	Loss:0.388
Batch: 2023/3370	Loss:0.208
Batch: 2360/3370	Loss:0.110
Batch: 2697/3370	Loss:0.288
Batch: 3034/3370	Loss:0.341
Batch: 3370/3370	Loss:0.809
Epoch: 5	Train Loss: 0.464	Val F1: 0.667
Best Epoch: 3	Best Epoch Val F1: 0.707

******************************Epoch: 6******************************
Batch: 1/3370	Loss:0.088
Batch: 338/3370	Loss:0.117
Batch: 675/3370	Loss:0.611
Batch: 1012/3370	Loss:0.336
Batch: 1349/3370	Loss:0.190
Batch: 1686/3370	Loss:0.586
Batch: 2023/3370	Loss:0.147
Batch: 2360/3370	Loss:0.371
Batch: 2697/3370	Loss:0.339
Batch: 3034/3370	Loss:1.026
Batch: 3370/3370	Loss:0.000
Epoch: 6	Train Loss: 0.427	Val F1: 0.684
Best Epoch: 3	Best Epoch Val F1: 0.707

******************************Epoch: 7******************************
Batch: 1/3370	Loss:0.193
Batch: 338/3370	Loss:0.254
Batch: 675/3370	Loss:0.370
Batch: 1012/3370	Loss:0.050
Batch: 1349/3370	Loss:0.229
Batch: 1686/3370	Loss:2.358
Batch: 2023/3370	Loss:0.631
Batch: 2360/3370	Loss:0.655
Batch: 2697/3370	Loss:0.310
Batch: 3034/3370	Loss:0.205
Batch: 3370/3370	Loss:0.005
Epoch: 7	Train Loss: 0.398	Val F1: 0.680
Best Epoch: 3	Best Epoch Val F1: 0.707

******************************Epoch: 8******************************
Batch: 1/3370	Loss:0.281
Batch: 338/3370	Loss:1.242
Batch: 675/3370	Loss:0.004
Batch: 1012/3370	Loss:0.180
Batch: 1349/3370	Loss:0.036
Batch: 1686/3370	Loss:0.252
Batch: 2023/3370	Loss:0.237
Batch: 2360/3370	Loss:0.393
Batch: 2697/3370	Loss:0.144
Batch: 3034/3370	Loss:0.333
Batch: 3370/3370	Loss:0.066
Epoch: 8	Train Loss: 0.378	Val F1: 0.650
Best Epoch: 3	Best Epoch Val F1: 0.707

Saving the best checkpoint....
Inference...
Test F1: 0.706	Test F1_Few: 0.720	Test F1_Zero: 0.691
Starting training with config: {'batch_size': 64, 'epochs': 25, 'l2_reg': 2.1328433048321957e-05, 'lr': 4.0415450740325454e-05, 'n_layers_freeze': 4, 'patience': 10}
Let's use 1 GPUs!
Preparing data....
Training data....
# of train examples: 13477
max len: 512, max len wiki: 1
Val data....
# of val examples: 2062
max len: 512, max len wiki: 1
Test data....
# of test examples: 3006
max len: 512, max len wiki: 1
Done

Initializing model....
******************************Epoch: 1******************************
Batch: 1/211	Loss:1.300
Batch: 22/211	Loss:1.042
Batch: 43/211	Loss:1.134
Batch: 64/211	Loss:1.006
Batch: 85/211	Loss:1.042
Batch: 106/211	Loss:0.860
Batch: 127/211	Loss:0.728
Batch: 148/211	Loss:0.719
Batch: 169/211	Loss:0.796
Batch: 190/211	Loss:0.587
Batch: 211/211	Loss:0.806
Epoch: 1	Train Loss: 0.874	Val F1: 0.681
Best Epoch: 1	Best Epoch Val F1: 0.681

******************************Epoch: 2******************************
Batch: 1/211	Loss:0.693
Batch: 22/211	Loss:0.710
Batch: 43/211	Loss:0.705
Batch: 64/211	Loss:0.656
Batch: 85/211	Loss:0.652
Batch: 106/211	Loss:0.734
Batch: 127/211	Loss:0.707
Batch: 148/211	Loss:0.647
Batch: 169/211	Loss:0.598
Batch: 190/211	Loss:0.547
Batch: 211/211	Loss:0.450
Epoch: 2	Train Loss: 0.606	Val F1: 0.703
Best Epoch: 2	Best Epoch Val F1: 0.703

******************************Epoch: 3******************************
Batch: 1/211	Loss:0.536
Batch: 22/211	Loss:0.540
Batch: 43/211	Loss:0.544
Batch: 64/211	Loss:0.482
Batch: 85/211	Loss:0.501
Batch: 106/211	Loss:0.612
Batch: 127/211	Loss:0.417
Batch: 148/211	Loss:0.576
Batch: 169/211	Loss:0.525
Batch: 190/211	Loss:0.519
Batch: 211/211	Loss:0.368
Epoch: 3	Train Loss: 0.502	Val F1: 0.739
Best Epoch: 3	Best Epoch Val F1: 0.739

******************************Epoch: 4******************************
Batch: 1/211	Loss:0.347
Batch: 22/211	Loss:0.443
Batch: 43/211	Loss:0.380
Batch: 64/211	Loss:0.392
Batch: 85/211	Loss:0.465
Batch: 106/211	Loss:0.396
Batch: 127/211	Loss:0.388
Batch: 148/211	Loss:0.348
Batch: 169/211	Loss:0.510
Batch: 190/211	Loss:0.482
Batch: 211/211	Loss:0.374
Epoch: 4	Train Loss: 0.430	Val F1: 0.678
Best Epoch: 3	Best Epoch Val F1: 0.739

******************************Epoch: 5******************************
Batch: 1/211	Loss:0.369
Batch: 22/211	Loss:0.411
Batch: 43/211	Loss:0.235
Batch: 64/211	Loss:0.326
Batch: 85/211	Loss:0.371
Batch: 106/211	Loss:0.356
Batch: 127/211	Loss:0.325
Batch: 148/211	Loss:0.461
Batch: 169/211	Loss:0.324
Batch: 190/211	Loss:0.497
Batch: 211/211	Loss:0.420
Epoch: 5	Train Loss: 0.375	Val F1: 0.707
Best Epoch: 3	Best Epoch Val F1: 0.739

******************************Epoch: 6******************************
Batch: 1/211	Loss:0.272
Batch: 22/211	Loss:0.243
Batch: 43/211	Loss:0.295
Batch: 64/211	Loss:0.323
Batch: 85/211	Loss:0.338
Batch: 106/211	Loss:0.421
Batch: 127/211	Loss:0.386
Batch: 148/211	Loss:0.242
Batch: 169/211	Loss:0.402
Batch: 190/211	Loss:0.315
Batch: 211/211	Loss:0.253
Epoch: 6	Train Loss: 0.329	Val F1: 0.723
Best Epoch: 3	Best Epoch Val F1: 0.739

******************************Epoch: 7******************************
Batch: 1/211	Loss:0.329
Batch: 22/211	Loss:0.181
Batch: 43/211	Loss:0.269
Batch: 64/211	Loss:0.258
Batch: 85/211	Loss:0.390
Batch: 106/211	Loss:0.308
Batch: 127/211	Loss:0.361
Batch: 148/211	Loss:0.329
Batch: 169/211	Loss:0.437
Batch: 190/211	Loss:0.380
Batch: 211/211	Loss:0.373
Epoch: 7	Train Loss: 0.290	Val F1: 0.725
Best Epoch: 3	Best Epoch Val F1: 0.739

******************************Epoch: 8******************************
Batch: 1/211	Loss:0.150
Batch: 22/211	Loss:0.194
Batch: 43/211	Loss:0.162
Batch: 64/211	Loss:0.191
Batch: 85/211	Loss:0.298
Batch: 106/211	Loss:0.222
Batch: 127/211	Loss:0.274
Batch: 148/211	Loss:0.224
Batch: 169/211	Loss:0.279
Batch: 190/211	Loss:0.358
Batch: 211/211	Loss:0.342
Epoch: 8	Train Loss: 0.258	Val F1: 0.710
Best Epoch: 3	Best Epoch Val F1: 0.739

******************************Epoch: 9******************************
Batch: 1/211	Loss:0.211
Batch: 22/211	Loss:0.235
Batch: 43/211	Loss:0.296
Batch: 64/211	Loss:0.381
Batch: 85/211	Loss:0.280
Batch: 106/211	Loss:0.160
Batch: 127/211	Loss:0.190
Batch: 148/211	Loss:0.227
Batch: 169/211	Loss:0.141
Batch: 190/211	Loss:0.219
Batch: 211/211	Loss:0.191
Epoch: 9	Train Loss: 0.229	Val F1: 0.710
Best Epoch: 3	Best Epoch Val F1: 0.739

******************************Epoch: 10******************************
Batch: 1/211	Loss:0.180
Batch: 22/211	Loss:0.190
Batch: 43/211	Loss:0.226
Batch: 64/211	Loss:0.128
Batch: 85/211	Loss:0.176
Batch: 106/211	Loss:0.133
Batch: 127/211	Loss:0.281
Batch: 148/211	Loss:0.150
Batch: 169/211	Loss:0.153
Batch: 190/211	Loss:0.268
Batch: 211/211	Loss:0.184
Epoch: 10	Train Loss: 0.209	Val F1: 0.725
Best Epoch: 3	Best Epoch Val F1: 0.739

******************************Epoch: 11******************************
Batch: 1/211	Loss:0.094
Batch: 22/211	Loss:0.237
Batch: 43/211	Loss:0.137
Batch: 64/211	Loss:0.145
Batch: 85/211	Loss:0.136
Batch: 106/211	Loss:0.190
Batch: 127/211	Loss:0.280
Batch: 148/211	Loss:0.136
Batch: 169/211	Loss:0.299
Batch: 190/211	Loss:0.095
Batch: 211/211	Loss:0.148
Epoch: 11	Train Loss: 0.185	Val F1: 0.715
Best Epoch: 3	Best Epoch Val F1: 0.739

******************************Epoch: 12******************************
Batch: 1/211	Loss:0.102
Batch: 22/211	Loss:0.124
Batch: 43/211	Loss:0.111
Batch: 64/211	Loss:0.231
Batch: 85/211	Loss:0.081
Batch: 106/211	Loss:0.207
Batch: 127/211	Loss:0.161
Batch: 148/211	Loss:0.315
Batch: 169/211	Loss:0.119
Batch: 190/211	Loss:0.148
Batch: 211/211	Loss:0.068
Epoch: 12	Train Loss: 0.173	Val F1: 0.702
Best Epoch: 3	Best Epoch Val F1: 0.739

******************************Epoch: 13******************************
Batch: 1/211	Loss:0.193
Batch: 22/211	Loss:0.245
Batch: 43/211	Loss:0.098
Batch: 64/211	Loss:0.118
Batch: 85/211	Loss:0.041
Batch: 106/211	Loss:0.112
Batch: 127/211	Loss:0.261
Batch: 148/211	Loss:0.236
Batch: 169/211	Loss:0.127
Batch: 190/211	Loss:0.144
Batch: 211/211	Loss:0.148
Epoch: 13	Train Loss: 0.158	Val F1: 0.734
Best Epoch: 3	Best Epoch Val F1: 0.739

Saving the best checkpoint....
Inference...
Test F1: 0.734	Test F1_Few: 0.742	Test F1_Zero: 0.724
Starting training with config: {'batch_size': 4, 'epochs': 50, 'l2_reg': 6.651608243621372e-05, 'lr': 9.308482639980922e-06, 'n_layers_freeze': 1, 'patience': 10}
Let's use 1 GPUs!
Preparing data....
Training data....
# of train examples: 13477
max len: 512, max len wiki: 1
Val data....
# of val examples: 2062
max len: 512, max len wiki: 1
Test data....
# of test examples: 3006
max len: 512, max len wiki: 1
Done

Initializing model....
******************************Epoch: 1******************************
Batch: 1/3370	Loss:1.322
Batch: 338/3370	Loss:1.211
Batch: 675/3370	Loss:0.849
Batch: 1012/3370	Loss:0.641
Batch: 1349/3370	Loss:0.659
Batch: 1686/3370	Loss:1.510
Batch: 2023/3370	Loss:0.279
Batch: 2360/3370	Loss:1.388
Batch: 2697/3370	Loss:0.699
Batch: 3034/3370	Loss:0.526
Batch: 3370/3370	Loss:1.622
Epoch: 1	Train Loss: 0.760	Val F1: 0.671
Best Epoch: 1	Best Epoch Val F1: 0.671

******************************Epoch: 2******************************
Batch: 1/3370	Loss:0.631
Batch: 338/3370	Loss:0.834
Batch: 675/3370	Loss:0.489
Batch: 1012/3370	Loss:0.708
Batch: 1349/3370	Loss:0.434
Batch: 1686/3370	Loss:0.400
Batch: 2023/3370	Loss:0.484
Batch: 2360/3370	Loss:0.412
Batch: 2697/3370	Loss:0.698
Batch: 3034/3370	Loss:0.503
Batch: 3370/3370	Loss:0.013
Epoch: 2	Train Loss: 0.593	Val F1: 0.716
Best Epoch: 2	Best Epoch Val F1: 0.716

******************************Epoch: 3******************************
Batch: 1/3370	Loss:0.122
Batch: 338/3370	Loss:0.579
Batch: 675/3370	Loss:0.706
Batch: 1012/3370	Loss:0.753
Batch: 1349/3370	Loss:0.420
Batch: 1686/3370	Loss:0.913
Batch: 2023/3370	Loss:0.518
Batch: 2360/3370	Loss:0.289
Batch: 2697/3370	Loss:0.126
Batch: 3034/3370	Loss:0.141
Batch: 3370/3370	Loss:0.179
Epoch: 3	Train Loss: 0.499	Val F1: 0.722
Best Epoch: 3	Best Epoch Val F1: 0.722

******************************Epoch: 4******************************
Batch: 1/3370	Loss:0.124
Batch: 338/3370	Loss:0.456
Batch: 675/3370	Loss:0.118
Batch: 1012/3370	Loss:0.509
Batch: 1349/3370	Loss:0.232
Batch: 1686/3370	Loss:0.359
Batch: 2023/3370	Loss:0.544
Batch: 2360/3370	Loss:0.361
Batch: 2697/3370	Loss:0.695
Batch: 3034/3370	Loss:0.759
Batch: 3370/3370	Loss:0.004
Epoch: 4	Train Loss: 0.424	Val F1: 0.703
Best Epoch: 3	Best Epoch Val F1: 0.722

******************************Epoch: 5******************************
Batch: 1/3370	Loss:0.455
Batch: 338/3370	Loss:0.478
Batch: 675/3370	Loss:0.242
Batch: 1012/3370	Loss:0.230
Batch: 1349/3370	Loss:0.051
Batch: 1686/3370	Loss:0.223
Batch: 2023/3370	Loss:0.063
Batch: 2360/3370	Loss:0.043
Batch: 2697/3370	Loss:0.824
Batch: 3034/3370	Loss:0.213
Batch: 3370/3370	Loss:1.041
Epoch: 5	Train Loss: 0.375	Val F1: 0.693
Best Epoch: 3	Best Epoch Val F1: 0.722

******************************Epoch: 6******************************
Batch: 1/3370	Loss:0.059
Batch: 338/3370	Loss:0.097
Batch: 675/3370	Loss:0.312
Batch: 1012/3370	Loss:0.180
Batch: 1349/3370	Loss:0.068
Batch: 1686/3370	Loss:0.497
Batch: 2023/3370	Loss:0.013
Batch: 2360/3370	Loss:0.391
Batch: 2697/3370	Loss:0.034
Batch: 3034/3370	Loss:0.664
Batch: 3370/3370	Loss:0.001
Epoch: 6	Train Loss: 0.331	Val F1: 0.716
Best Epoch: 3	Best Epoch Val F1: 0.722

******************************Epoch: 7******************************
Batch: 1/3370	Loss:0.176
Batch: 338/3370	Loss:0.100
Batch: 675/3370	Loss:0.351
Batch: 1012/3370	Loss:0.046
Batch: 1349/3370	Loss:0.046
Batch: 1686/3370	Loss:1.019
Batch: 2023/3370	Loss:0.728
Batch: 2360/3370	Loss:0.476
Batch: 2697/3370	Loss:0.245
Batch: 3034/3370	Loss:0.109
Batch: 3370/3370	Loss:0.003
Epoch: 7	Train Loss: 0.290	Val F1: 0.700
Best Epoch: 3	Best Epoch Val F1: 0.722

******************************Epoch: 8******************************
Batch: 1/3370	Loss:0.217
Batch: 338/3370	Loss:0.426
Batch: 675/3370	Loss:0.004
Batch: 1012/3370	Loss:0.012
Batch: 1349/3370	Loss:0.020
Batch: 1686/3370	Loss:0.211
Batch: 2023/3370	Loss:0.410
Batch: 2360/3370	Loss:0.328
Batch: 2697/3370	Loss:0.015
Batch: 3034/3370	Loss:0.197
Batch: 3370/3370	Loss:0.005
Epoch: 8	Train Loss: 0.264	Val F1: 0.691
Best Epoch: 3	Best Epoch Val F1: 0.722

******************************Epoch: 9******************************
Batch: 1/3370	Loss:0.559
Batch: 338/3370	Loss:0.410
Batch: 675/3370	Loss:0.932
Batch: 1012/3370	Loss:0.103
Batch: 1349/3370	Loss:0.250
Batch: 1686/3370	Loss:0.751
Batch: 2023/3370	Loss:0.171
Batch: 2360/3370	Loss:0.325
Batch: 2697/3370	Loss:0.121
Batch: 3034/3370	Loss:0.134
Batch: 3370/3370	Loss:0.008
Epoch: 9	Train Loss: 0.227	Val F1: 0.702
Best Epoch: 3	Best Epoch Val F1: 0.722

******************************Epoch: 10******************************
Batch: 1/3370	Loss:0.018
Batch: 338/3370	Loss:0.486
Batch: 675/3370	Loss:0.114
Batch: 1012/3370	Loss:0.282
Batch: 1349/3370	Loss:0.005
Batch: 1686/3370	Loss:0.264
Batch: 2023/3370	Loss:0.140
Batch: 2360/3370	Loss:0.051
Batch: 2697/3370	Loss:0.742
Batch: 3034/3370	Loss:0.097
Batch: 3370/3370	Loss:0.014
Epoch: 10	Train Loss: 0.206	Val F1: 0.705
Best Epoch: 3	Best Epoch Val F1: 0.722

******************************Epoch: 11******************************
Batch: 1/3370	Loss:0.053
Batch: 338/3370	Loss:0.013
Batch: 675/3370	Loss:0.006
Batch: 1012/3370	Loss:0.083
Batch: 1349/3370	Loss:0.065
Batch: 1686/3370	Loss:0.006
Batch: 2023/3370	Loss:0.886
Batch: 2360/3370	Loss:0.003
Batch: 2697/3370	Loss:0.190
Batch: 3034/3370	Loss:0.090
Batch: 3370/3370	Loss:0.001
Epoch: 11	Train Loss: 0.187	Val F1: 0.721
Best Epoch: 3	Best Epoch Val F1: 0.722

******************************Epoch: 12******************************
Batch: 1/3370	Loss:0.577
Batch: 338/3370	Loss:0.001
Batch: 675/3370	Loss:0.041
Batch: 1012/3370	Loss:0.018
Batch: 1349/3370	Loss:0.006
Batch: 1686/3370	Loss:0.113
Batch: 2023/3370	Loss:0.006
Batch: 2360/3370	Loss:0.013
Batch: 2697/3370	Loss:0.009
Batch: 3034/3370	Loss:0.218
Batch: 3370/3370	Loss:0.001
Epoch: 12	Train Loss: 0.173	Val F1: 0.695
Best Epoch: 3	Best Epoch Val F1: 0.722

******************************Epoch: 13******************************
Batch: 1/3370	Loss:0.014
Batch: 338/3370	Loss:0.008
Batch: 675/3370	Loss:0.167
Batch: 1012/3370	Loss:0.015
Batch: 1349/3370	Loss:0.110
Batch: 1686/3370	Loss:0.457
Batch: 2023/3370	Loss:0.018
Batch: 2360/3370	Loss:0.050
Batch: 2697/3370	Loss:0.033
Batch: 3034/3370	Loss:0.002
Batch: 3370/3370	Loss:0.216
Epoch: 13	Train Loss: 0.164	Val F1: 0.698
Best Epoch: 3	Best Epoch Val F1: 0.722

Saving the best checkpoint....
Inference...
Test F1: 0.744	Test F1_Few: 0.758	Test F1_Zero: 0.730
Starting training with config: {'batch_size': 32, 'epochs': 50, 'l2_reg': 8.887074880686118e-05, 'lr': 1.701224133848983e-05, 'n_layers_freeze': 2, 'patience': 10}
Let's use 1 GPUs!
Preparing data....
Training data....
# of train examples: 13477
max len: 512, max len wiki: 1
Val data....
# of val examples: 2062
max len: 512, max len wiki: 1
Test data....
# of test examples: 3006
max len: 512, max len wiki: 1
Done

Initializing model....
******************************Epoch: 1******************************
Batch: 1/422	Loss:1.244
Batch: 43/422	Loss:1.096
Batch: 85/422	Loss:1.111
Batch: 127/422	Loss:1.027
Batch: 169/422	Loss:1.056
Batch: 211/422	Loss:1.006
Batch: 253/422	Loss:0.921
Batch: 295/422	Loss:0.776
Batch: 337/422	Loss:0.771
Batch: 379/422	Loss:0.557
Batch: 421/422	Loss:0.761
Batch: 422/422	Loss:0.580
Epoch: 1	Train Loss: 0.925	Val F1: 0.619
Best Epoch: 1	Best Epoch Val F1: 0.619

******************************Epoch: 2******************************
Batch: 1/422	Loss:0.740
Batch: 43/422	Loss:0.759
Batch: 85/422	Loss:0.731
Batch: 127/422	Loss:0.690
Batch: 169/422	Loss:0.550
Batch: 211/422	Loss:0.696
Batch: 253/422	Loss:0.652
Batch: 295/422	Loss:0.764
Batch: 337/422	Loss:0.747
Batch: 379/422	Loss:0.578
Batch: 421/422	Loss:0.502
Batch: 422/422	Loss:0.485
Epoch: 2	Train Loss: 0.628	Val F1: 0.735
Best Epoch: 2	Best Epoch Val F1: 0.735

******************************Epoch: 3******************************
Batch: 1/422	Loss:0.613
Batch: 43/422	Loss:0.471
Batch: 85/422	Loss:0.618
Batch: 127/422	Loss:0.460
Batch: 169/422	Loss:0.356
Batch: 211/422	Loss:0.801
Batch: 253/422	Loss:0.477
Batch: 295/422	Loss:0.764
Batch: 337/422	Loss:0.466
Batch: 379/422	Loss:0.568
Batch: 421/422	Loss:0.430
Batch: 422/422	Loss:0.626
Epoch: 3	Train Loss: 0.529	Val F1: 0.738
Best Epoch: 3	Best Epoch Val F1: 0.738

******************************Epoch: 4******************************
Batch: 1/422	Loss:0.414
Batch: 43/422	Loss:0.554
Batch: 85/422	Loss:0.632
Batch: 127/422	Loss:0.433
Batch: 169/422	Loss:0.483
Batch: 211/422	Loss:0.424
Batch: 253/422	Loss:0.403
Batch: 295/422	Loss:0.335
Batch: 337/422	Loss:0.629
Batch: 379/422	Loss:0.479
Batch: 421/422	Loss:0.432
Batch: 422/422	Loss:1.018
Epoch: 4	Train Loss: 0.459	Val F1: 0.710
Best Epoch: 3	Best Epoch Val F1: 0.738

******************************Epoch: 5******************************
Batch: 1/422	Loss:0.393
Batch: 43/422	Loss:0.387
Batch: 85/422	Loss:0.308
Batch: 127/422	Loss:0.356
Batch: 169/422	Loss:0.444
Batch: 211/422	Loss:0.454
Batch: 253/422	Loss:0.260
Batch: 295/422	Loss:0.417
Batch: 337/422	Loss:0.311
Batch: 379/422	Loss:0.256
Batch: 421/422	Loss:0.346
Batch: 422/422	Loss:0.423
Epoch: 5	Train Loss: 0.403	Val F1: 0.695
Best Epoch: 3	Best Epoch Val F1: 0.738

******************************Epoch: 6******************************
Batch: 1/422	Loss:0.284
Batch: 43/422	Loss:0.328
Batch: 85/422	Loss:0.395
Batch: 127/422	Loss:0.261
Batch: 169/422	Loss:0.343
Batch: 211/422	Loss:0.461
Batch: 253/422	Loss:0.278
Batch: 295/422	Loss:0.322
Batch: 337/422	Loss:0.529
Batch: 379/422	Loss:0.404
Batch: 421/422	Loss:0.216
Batch: 422/422	Loss:0.068
Epoch: 6	Train Loss: 0.358	Val F1: 0.709
Best Epoch: 3	Best Epoch Val F1: 0.738

******************************Epoch: 7******************************
Batch: 1/422	Loss:0.287
Batch: 43/422	Loss:0.237
Batch: 85/422	Loss:0.377
Batch: 127/422	Loss:0.283
Batch: 169/422	Loss:0.611
Batch: 211/422	Loss:0.435
Batch: 253/422	Loss:0.357
Batch: 295/422	Loss:0.293
Batch: 337/422	Loss:0.462
Batch: 379/422	Loss:0.493
Batch: 421/422	Loss:0.458
Batch: 422/422	Loss:0.223
Epoch: 7	Train Loss: 0.321	Val F1: 0.723
Best Epoch: 3	Best Epoch Val F1: 0.738

******************************Epoch: 8******************************
Batch: 1/422	Loss:0.210
Batch: 43/422	Loss:0.363
Batch: 85/422	Loss:0.156
Batch: 127/422	Loss:0.329
Batch: 169/422	Loss:0.438
Batch: 211/422	Loss:0.181
Batch: 253/422	Loss:0.439
Batch: 295/422	Loss:0.248
Batch: 337/422	Loss:0.264
Batch: 379/422	Loss:0.238
Batch: 421/422	Loss:0.445
Batch: 422/422	Loss:0.092
Epoch: 8	Train Loss: 0.284	Val F1: 0.700
Best Epoch: 3	Best Epoch Val F1: 0.738

******************************Epoch: 9******************************
Batch: 1/422	Loss:0.308
Batch: 43/422	Loss:0.226
Batch: 85/422	Loss:0.293
Batch: 127/422	Loss:0.292
Batch: 169/422	Loss:0.179
Batch: 211/422	Loss:0.249
Batch: 253/422	Loss:0.313
Batch: 295/422	Loss:0.284
Batch: 337/422	Loss:0.173
Batch: 379/422	Loss:0.112
Batch: 421/422	Loss:0.171
Batch: 422/422	Loss:0.298
Epoch: 9	Train Loss: 0.253	Val F1: 0.733
Best Epoch: 3	Best Epoch Val F1: 0.738

******************************Epoch: 10******************************
Batch: 1/422	Loss:0.237
Batch: 43/422	Loss:0.171
Batch: 85/422	Loss:0.268
Batch: 127/422	Loss:0.065
Batch: 169/422	Loss:0.216
Batch: 211/422	Loss:0.123
Batch: 253/422	Loss:0.251
Batch: 295/422	Loss:0.212
Batch: 337/422	Loss:0.057
Batch: 379/422	Loss:0.295
Batch: 421/422	Loss:0.070
Batch: 422/422	Loss:0.218
Epoch: 10	Train Loss: 0.231	Val F1: 0.721
Best Epoch: 3	Best Epoch Val F1: 0.738

******************************Epoch: 11******************************
Batch: 1/422	Loss:0.124
Batch: 43/422	Loss:0.318
Batch: 85/422	Loss:0.146
Batch: 127/422	Loss:0.357
Batch: 169/422	Loss:0.172
Batch: 211/422	Loss:0.411
Batch: 253/422	Loss:0.231
Batch: 295/422	Loss:0.061
Batch: 337/422	Loss:0.266
Batch: 379/422	Loss:0.092
Batch: 421/422	Loss:0.214
Batch: 422/422	Loss:0.022
Epoch: 11	Train Loss: 0.208	Val F1: 0.709
Best Epoch: 3	Best Epoch Val F1: 0.738

******************************Epoch: 12******************************
Batch: 1/422	Loss:0.209
Batch: 43/422	Loss:0.201
Batch: 85/422	Loss:0.223
Batch: 127/422	Loss:0.203
Batch: 169/422	Loss:0.204
Batch: 211/422	Loss:0.286
Batch: 253/422	Loss:0.219
Batch: 295/422	Loss:0.235
Batch: 337/422	Loss:0.078
Batch: 379/422	Loss:0.079
Batch: 421/422	Loss:0.207
Batch: 422/422	Loss:0.040
Epoch: 12	Train Loss: 0.193	Val F1: 0.714
Best Epoch: 3	Best Epoch Val F1: 0.738

******************************Epoch: 13******************************
Batch: 1/422	Loss:0.129
Batch: 43/422	Loss:0.133
Batch: 85/422	Loss:0.178
Batch: 127/422	Loss:0.148
Batch: 169/422	Loss:0.090
Batch: 211/422	Loss:0.106
Batch: 253/422	Loss:0.298
Batch: 295/422	Loss:0.270
Batch: 337/422	Loss:0.258
Batch: 379/422	Loss:0.238
Batch: 421/422	Loss:0.175
Batch: 422/422	Loss:0.145
Epoch: 13	Train Loss: 0.180	Val F1: 0.722
Best Epoch: 3	Best Epoch Val F1: 0.738

Saving the best checkpoint....
Inference...
Test F1: 0.742	Test F1_Few: 0.752	Test F1_Zero: 0.732
Starting training with config: {'batch_size': 64, 'epochs': 75, 'l2_reg': 6.0797661540434765e-05, 'lr': 9.58279615200579e-06, 'n_layers_freeze': 4, 'patience': 10}
Let's use 1 GPUs!
Preparing data....
Training data....
# of train examples: 13477
max len: 512, max len wiki: 1
Val data....
# of val examples: 2062
max len: 512, max len wiki: 1
Test data....
# of test examples: 3006
max len: 512, max len wiki: 1
Done

Initializing model....
******************************Epoch: 1******************************
Batch: 1/211	Loss:1.300
Batch: 22/211	Loss:1.019
Batch: 43/211	Loss:1.183
Batch: 64/211	Loss:1.020
Batch: 85/211	Loss:1.069
Batch: 106/211	Loss:1.027
Batch: 127/211	Loss:1.028
Batch: 148/211	Loss:1.012
Batch: 169/211	Loss:0.998
Batch: 190/211	Loss:1.124
Batch: 211/211	Loss:1.048
Epoch: 1	Train Loss: 1.043	Val F1: 0.310
Best Epoch: 1	Best Epoch Val F1: 0.310

******************************Epoch: 2******************************
Batch: 1/211	Loss:1.004
Batch: 22/211	Loss:0.923
Batch: 43/211	Loss:0.856
Batch: 64/211	Loss:0.761
Batch: 85/211	Loss:0.789
Batch: 106/211	Loss:0.874
Batch: 127/211	Loss:0.739
Batch: 148/211	Loss:0.729
Batch: 169/211	Loss:0.694
Batch: 190/211	Loss:0.639
Batch: 211/211	Loss:0.655
Epoch: 2	Train Loss: 0.766	Val F1: 0.687
Best Epoch: 2	Best Epoch Val F1: 0.687

******************************Epoch: 3******************************
Batch: 1/211	Loss:0.637
Batch: 22/211	Loss:0.658
Batch: 43/211	Loss:0.631
Batch: 64/211	Loss:0.620
Batch: 85/211	Loss:0.579
Batch: 106/211	Loss:0.592
Batch: 127/211	Loss:0.482
Batch: 148/211	Loss:0.663
Batch: 169/211	Loss:0.632
Batch: 190/211	Loss:0.641
Batch: 211/211	Loss:0.604
Epoch: 3	Train Loss: 0.629	Val F1: 0.719
Best Epoch: 3	Best Epoch Val F1: 0.719

******************************Epoch: 4******************************
Batch: 1/211	Loss:0.518
Batch: 22/211	Loss:0.640
Batch: 43/211	Loss:0.521
Batch: 64/211	Loss:0.564
Batch: 85/211	Loss:0.539
Batch: 106/211	Loss:0.486
Batch: 127/211	Loss:0.561
Batch: 148/211	Loss:0.553
Batch: 169/211	Loss:0.544
Batch: 190/211	Loss:0.628
Batch: 211/211	Loss:0.542
Epoch: 4	Train Loss: 0.577	Val F1: 0.647
Best Epoch: 3	Best Epoch Val F1: 0.719

******************************Epoch: 5******************************
Batch: 1/211	Loss:0.663
Batch: 22/211	Loss:0.512
Batch: 43/211	Loss:0.434
Batch: 64/211	Loss:0.487
Batch: 85/211	Loss:0.567
Batch: 106/211	Loss:0.440
Batch: 127/211	Loss:0.404
Batch: 148/211	Loss:0.469
Batch: 169/211	Loss:0.477
Batch: 190/211	Loss:0.521
Batch: 211/211	Loss:0.538
Epoch: 5	Train Loss: 0.526	Val F1: 0.685
Best Epoch: 3	Best Epoch Val F1: 0.719

******************************Epoch: 6******************************
Batch: 1/211	Loss:0.391
Batch: 22/211	Loss:0.483
Batch: 43/211	Loss:0.405
Batch: 64/211	Loss:0.400
Batch: 85/211	Loss:0.446
Batch: 106/211	Loss:0.556
Batch: 127/211	Loss:0.441
Batch: 148/211	Loss:0.455
Batch: 169/211	Loss:0.497
Batch: 190/211	Loss:0.467
Batch: 211/211	Loss:0.338
Epoch: 6	Train Loss: 0.480	Val F1: 0.700
Best Epoch: 3	Best Epoch Val F1: 0.719

******************************Epoch: 7******************************
Batch: 1/211	Loss:0.522
Batch: 22/211	Loss:0.372
Batch: 43/211	Loss:0.452
Batch: 64/211	Loss:0.386
Batch: 85/211	Loss:0.565
Batch: 106/211	Loss:0.452
Batch: 127/211	Loss:0.681
Batch: 148/211	Loss:0.530
Batch: 169/211	Loss:0.547
Batch: 190/211	Loss:0.541
Batch: 211/211	Loss:0.421
Epoch: 7	Train Loss: 0.435	Val F1: 0.695
Best Epoch: 3	Best Epoch Val F1: 0.719

******************************Epoch: 8******************************
Batch: 1/211	Loss:0.379
Batch: 22/211	Loss:0.427
Batch: 43/211	Loss:0.292
Batch: 64/211	Loss:0.402
Batch: 85/211	Loss:0.576
Batch: 106/211	Loss:0.412
Batch: 127/211	Loss:0.401
Batch: 148/211	Loss:0.440
Batch: 169/211	Loss:0.468
Batch: 190/211	Loss:0.328
Batch: 211/211	Loss:0.437
Epoch: 8	Train Loss: 0.407	Val F1: 0.693
Best Epoch: 3	Best Epoch Val F1: 0.719

******************************Epoch: 9******************************
Batch: 1/211	Loss:0.379
Batch: 22/211	Loss:0.369
Batch: 43/211	Loss:0.415
Batch: 64/211	Loss:0.561
Batch: 85/211	Loss:0.360
Batch: 106/211	Loss:0.309
Batch: 127/211	Loss:0.476
Batch: 148/211	Loss:0.411
Batch: 169/211	Loss:0.255
Batch: 190/211	Loss:0.277
Batch: 211/211	Loss:0.325
Epoch: 9	Train Loss: 0.379	Val F1: 0.683
Best Epoch: 3	Best Epoch Val F1: 0.719

******************************Epoch: 10******************************
Batch: 1/211	Loss:0.300
Batch: 22/211	Loss:0.303
Batch: 43/211	Loss:0.430
Batch: 64/211	Loss:0.267
Batch: 85/211	Loss:0.284
Batch: 106/211	Loss:0.333
Batch: 127/211	Loss:0.381
Batch: 148/211	Loss:0.268
Batch: 169/211	Loss:0.251
Batch: 190/211	Loss:0.398
Batch: 211/211	Loss:0.179
Epoch: 10	Train Loss: 0.355	Val F1: 0.695
Best Epoch: 3	Best Epoch Val F1: 0.719

******************************Epoch: 11******************************
Batch: 1/211	Loss:0.278
Batch: 22/211	Loss:0.391
Batch: 43/211	Loss:0.271
Batch: 64/211	Loss:0.322
Batch: 85/211	Loss:0.286
Batch: 106/211	Loss:0.361
Batch: 127/211	Loss:0.531
Batch: 148/211	Loss:0.245
Batch: 169/211	Loss:0.455
Batch: 190/211	Loss:0.385
Batch: 211/211	Loss:0.357
Epoch: 11	Train Loss: 0.338	Val F1: 0.698
Best Epoch: 3	Best Epoch Val F1: 0.719

******************************Epoch: 12******************************
Batch: 1/211	Loss:0.283
Batch: 22/211	Loss:0.235
Batch: 43/211	Loss:0.280
Batch: 64/211	Loss:0.422
Batch: 85/211	Loss:0.243
Batch: 106/211	Loss:0.375
Batch: 127/211	Loss:0.280
Batch: 148/211	Loss:0.422
Batch: 169/211	Loss:0.323
Batch: 190/211	Loss:0.309
Batch: 211/211	Loss:0.256
Epoch: 12	Train Loss: 0.316	Val F1: 0.704
Best Epoch: 3	Best Epoch Val F1: 0.719

******************************Epoch: 13******************************
Batch: 1/211	Loss:0.319
Batch: 22/211	Loss:0.344
Batch: 43/211	Loss:0.271
Batch: 64/211	Loss:0.201
Batch: 85/211	Loss:0.245
Batch: 106/211	Loss:0.311
Batch: 127/211	Loss:0.302
Batch: 148/211	Loss:0.423
Batch: 169/211	Loss:0.424
Batch: 190/211	Loss:0.325
Batch: 211/211	Loss:0.234
Epoch: 13	Train Loss: 0.295	Val F1: 0.693
Best Epoch: 3	Best Epoch Val F1: 0.719

Saving the best checkpoint....
Inference...
Test F1: 0.732	Test F1_Few: 0.728	Test F1_Zero: 0.736
Starting training with config: {'batch_size': 64, 'epochs': 25, 'l2_reg': 1.631828417507206e-05, 'lr': 5.030309512760153e-06, 'n_layers_freeze': 3, 'patience': 10}
Let's use 1 GPUs!
Preparing data....
Training data....
# of train examples: 13477
max len: 512, max len wiki: 1
Val data....
# of val examples: 2062
max len: 512, max len wiki: 1
Test data....
# of test examples: 3006
max len: 512, max len wiki: 1
Done

Initializing model....
******************************Epoch: 1******************************
Batch: 1/211	Loss:1.300
Batch: 22/211	Loss:1.008
Batch: 43/211	Loss:1.189
Batch: 64/211	Loss:1.054
Batch: 85/211	Loss:1.083
Batch: 106/211	Loss:1.031
Batch: 127/211	Loss:1.064
Batch: 148/211	Loss:1.031
Batch: 169/211	Loss:0.996
Batch: 190/211	Loss:1.138
Batch: 211/211	Loss:1.030
Epoch: 1	Train Loss: 1.059	Val F1: 0.281
Best Epoch: 1	Best Epoch Val F1: 0.281

******************************Epoch: 2******************************
Batch: 1/211	Loss:1.040
Batch: 22/211	Loss:0.963
Batch: 43/211	Loss:0.967
Batch: 64/211	Loss:1.030
Batch: 85/211	Loss:0.933
Batch: 106/211	Loss:1.011
Batch: 127/211	Loss:0.906
Batch: 148/211	Loss:0.971
Batch: 169/211	Loss:0.820
Batch: 190/211	Loss:0.768
Batch: 211/211	Loss:0.751
Epoch: 2	Train Loss: 0.928	Val F1: 0.653
Best Epoch: 2	Best Epoch Val F1: 0.653

******************************Epoch: 3******************************
Batch: 1/211	Loss:0.753
Batch: 22/211	Loss:0.751
Batch: 43/211	Loss:0.727
Batch: 64/211	Loss:0.674
Batch: 85/211	Loss:0.660
Batch: 106/211	Loss:0.630
Batch: 127/211	Loss:0.573
Batch: 148/211	Loss:0.791
Batch: 169/211	Loss:0.701
Batch: 190/211	Loss:0.653
Batch: 211/211	Loss:0.638
Epoch: 3	Train Loss: 0.703	Val F1: 0.689
Best Epoch: 3	Best Epoch Val F1: 0.689

******************************Epoch: 4******************************
Batch: 1/211	Loss:0.574
Batch: 22/211	Loss:0.674
Batch: 43/211	Loss:0.609
Batch: 64/211	Loss:0.629
Batch: 85/211	Loss:0.619
Batch: 106/211	Loss:0.533
Batch: 127/211	Loss:0.664
Batch: 148/211	Loss:0.626
Batch: 169/211	Loss:0.623
Batch: 190/211	Loss:0.682
Batch: 211/211	Loss:0.643
Epoch: 4	Train Loss: 0.636	Val F1: 0.663
Best Epoch: 3	Best Epoch Val F1: 0.689

******************************Epoch: 5******************************
Batch: 1/211	Loss:0.686
Batch: 22/211	Loss:0.560
Batch: 43/211	Loss:0.532
Batch: 64/211	Loss:0.491
Batch: 85/211	Loss:0.634
Batch: 106/211	Loss:0.502
Batch: 127/211	Loss:0.456
Batch: 148/211	Loss:0.530
Batch: 169/211	Loss:0.571
Batch: 190/211	Loss:0.617
Batch: 211/211	Loss:0.650
Epoch: 5	Train Loss: 0.597	Val F1: 0.715
Best Epoch: 5	Best Epoch Val F1: 0.715

******************************Epoch: 6******************************
Batch: 1/211	Loss:0.484
Batch: 22/211	Loss:0.575
Batch: 43/211	Loss:0.544
Batch: 64/211	Loss:0.464
Batch: 85/211	Loss:0.522
Batch: 106/211	Loss:0.617
Batch: 127/211	Loss:0.538
Batch: 148/211	Loss:0.596
Batch: 169/211	Loss:0.567
Batch: 190/211	Loss:0.515
Batch: 211/211	Loss:0.336
Epoch: 6	Train Loss: 0.560	Val F1: 0.705
Best Epoch: 5	Best Epoch Val F1: 0.715

******************************Epoch: 7******************************
Batch: 1/211	Loss:0.534
Batch: 22/211	Loss:0.609
Batch: 43/211	Loss:0.501
Batch: 64/211	Loss:0.463
Batch: 85/211	Loss:0.629
Batch: 106/211	Loss:0.531
Batch: 127/211	Loss:0.773
Batch: 148/211	Loss:0.601
Batch: 169/211	Loss:0.622
Batch: 190/211	Loss:0.573
Batch: 211/211	Loss:0.522
Epoch: 7	Train Loss: 0.524	Val F1: 0.679
Best Epoch: 5	Best Epoch Val F1: 0.715

******************************Epoch: 8******************************
Batch: 1/211	Loss:0.470
Batch: 22/211	Loss:0.575
Batch: 43/211	Loss:0.333
Batch: 64/211	Loss:0.484
Batch: 85/211	Loss:0.691
Batch: 106/211	Loss:0.463
Batch: 127/211	Loss:0.422
Batch: 148/211	Loss:0.544
Batch: 169/211	Loss:0.608
Batch: 190/211	Loss:0.387
Batch: 211/211	Loss:0.527
Epoch: 8	Train Loss: 0.490	Val F1: 0.695
Best Epoch: 5	Best Epoch Val F1: 0.715

******************************Epoch: 9******************************
Batch: 1/211	Loss:0.465
Batch: 22/211	Loss:0.395
Batch: 43/211	Loss:0.529
Batch: 64/211	Loss:0.576
Batch: 85/211	Loss:0.532
Batch: 106/211	Loss:0.419
Batch: 127/211	Loss:0.588
Batch: 148/211	Loss:0.485
Batch: 169/211	Loss:0.368
Batch: 190/211	Loss:0.410
Batch: 211/211	Loss:0.375
Epoch: 9	Train Loss: 0.465	Val F1: 0.693
Best Epoch: 5	Best Epoch Val F1: 0.715

******************************Epoch: 10******************************
Batch: 1/211	Loss:0.354
Batch: 22/211	Loss:0.422
Batch: 43/211	Loss:0.513
Batch: 64/211	Loss:0.364
Batch: 85/211	Loss:0.392
Batch: 106/211	Loss:0.418
Batch: 127/211	Loss:0.420
Batch: 148/211	Loss:0.361
Batch: 169/211	Loss:0.296
Batch: 190/211	Loss:0.412
Batch: 211/211	Loss:0.285
Epoch: 10	Train Loss: 0.432	Val F1: 0.704
Best Epoch: 5	Best Epoch Val F1: 0.715

******************************Epoch: 11******************************
Batch: 1/211	Loss:0.321
Batch: 22/211	Loss:0.433
Batch: 43/211	Loss:0.368
Batch: 64/211	Loss:0.462
Batch: 85/211	Loss:0.338
Batch: 106/211	Loss:0.453
Batch: 127/211	Loss:0.625
Batch: 148/211	Loss:0.341
Batch: 169/211	Loss:0.498
Batch: 190/211	Loss:0.475
Batch: 211/211	Loss:0.456
Epoch: 11	Train Loss: 0.411	Val F1: 0.680
Best Epoch: 5	Best Epoch Val F1: 0.715

******************************Epoch: 12******************************
Batch: 1/211	Loss:0.483
Batch: 22/211	Loss:0.355
Batch: 43/211	Loss:0.368
Batch: 64/211	Loss:0.442
Batch: 85/211	Loss:0.346
Batch: 106/211	Loss:0.448
Batch: 127/211	Loss:0.370
Batch: 148/211	Loss:0.480
Batch: 169/211	Loss:0.325
Batch: 190/211	Loss:0.342
Batch: 211/211	Loss:0.389
Epoch: 12	Train Loss: 0.387	Val F1: 0.697
Best Epoch: 5	Best Epoch Val F1: 0.715

******************************Epoch: 13******************************
Batch: 1/211	Loss:0.415
Batch: 22/211	Loss:0.441
Batch: 43/211	Loss:0.361
Batch: 64/211	Loss:0.254
Batch: 85/211	Loss:0.278
Batch: 106/211	Loss:0.412
Batch: 127/211	Loss:0.373
Batch: 148/211	Loss:0.481
Batch: 169/211	Loss:0.529
Batch: 190/211	Loss:0.325
Batch: 211/211	Loss:0.302
Epoch: 13	Train Loss: 0.366	Val F1: 0.688
Best Epoch: 5	Best Epoch Val F1: 0.715

******************************Epoch: 14******************************
Batch: 1/211	Loss:0.347
Batch: 22/211	Loss:0.368
Batch: 43/211	Loss:0.278
Batch: 64/211	Loss:0.336
Batch: 85/211	Loss:0.267
Batch: 106/211	Loss:0.258
Batch: 127/211	Loss:0.224
Batch: 148/211	Loss:0.306
Batch: 169/211	Loss:0.272
Batch: 190/211	Loss:0.314
Batch: 211/211	Loss:0.616
Epoch: 14	Train Loss: 0.356	Val F1: 0.689
Best Epoch: 5	Best Epoch Val F1: 0.715

******************************Epoch: 15******************************
Batch: 1/211	Loss:0.433
Batch: 22/211	Loss:0.152
Batch: 43/211	Loss:0.306
Batch: 64/211	Loss:0.334
Batch: 85/211	Loss:0.306
Batch: 106/211	Loss:0.271
Batch: 127/211	Loss:0.537
Batch: 148/211	Loss:0.362
Batch: 169/211	Loss:0.377
Batch: 190/211	Loss:0.371
Batch: 211/211	Loss:0.304
Epoch: 15	Train Loss: 0.339	Val F1: 0.686
Best Epoch: 5	Best Epoch Val F1: 0.715

Saving the best checkpoint....
Inference...
Test F1: 0.735	Test F1_Few: 0.734	Test F1_Zero: 0.737
Starting training with config: {'batch_size': 4, 'epochs': 25, 'l2_reg': 1.917659270959106e-05, 'lr': 8.237317403330602e-06, 'n_layers_freeze': 3, 'patience': 5}
Let's use 1 GPUs!
Preparing data....
Training data....
# of train examples: 13477
max len: 512, max len wiki: 1
Val data....
# of val examples: 2062
max len: 512, max len wiki: 1
Test data....
# of test examples: 3006
max len: 512, max len wiki: 1
Done

Initializing model....
******************************Epoch: 1******************************
Batch: 1/3370	Loss:1.322
Batch: 338/3370	Loss:1.223
Batch: 675/3370	Loss:0.911
Batch: 1012/3370	Loss:0.710
Batch: 1349/3370	Loss:0.685
Batch: 1686/3370	Loss:1.438
Batch: 2023/3370	Loss:0.277
Batch: 2360/3370	Loss:1.501
Batch: 2697/3370	Loss:0.711
Batch: 3034/3370	Loss:0.478
Batch: 3370/3370	Loss:1.415
Epoch: 1	Train Loss: 0.789	Val F1: 0.687
Best Epoch: 1	Best Epoch Val F1: 0.687

******************************Epoch: 2******************************
Batch: 1/3370	Loss:0.683
Batch: 338/3370	Loss:0.796
Batch: 675/3370	Loss:0.447
Batch: 1012/3370	Loss:0.623
Batch: 1349/3370	Loss:0.508
Batch: 1686/3370	Loss:0.383
Batch: 2023/3370	Loss:0.499
Batch: 2360/3370	Loss:0.388
Batch: 2697/3370	Loss:0.871
Batch: 3034/3370	Loss:0.436
Batch: 3370/3370	Loss:0.018
Epoch: 2	Train Loss: 0.599	Val F1: 0.707
Best Epoch: 2	Best Epoch Val F1: 0.707

******************************Epoch: 3******************************
Batch: 1/3370	Loss:0.190
Batch: 338/3370	Loss:0.352
Batch: 675/3370	Loss:0.675
Batch: 1012/3370	Loss:0.790
Batch: 1349/3370	Loss:0.426
Batch: 1686/3370	Loss:0.726
Batch: 2023/3370	Loss:0.517
Batch: 2360/3370	Loss:0.160
Batch: 2697/3370	Loss:0.110
Batch: 3034/3370	Loss:0.164
Batch: 3370/3370	Loss:0.071
Epoch: 3	Train Loss: 0.513	Val F1: 0.706
Best Epoch: 2	Best Epoch Val F1: 0.707

******************************Epoch: 4******************************
Batch: 1/3370	Loss:0.198
Batch: 338/3370	Loss:0.567
Batch: 675/3370	Loss:0.180
Batch: 1012/3370	Loss:0.479
Batch: 1349/3370	Loss:0.256
Batch: 1686/3370	Loss:0.483
Batch: 2023/3370	Loss:0.463
Batch: 2360/3370	Loss:0.400
Batch: 2697/3370	Loss:0.706
Batch: 3034/3370	Loss:0.911
Batch: 3370/3370	Loss:0.007
Epoch: 4	Train Loss: 0.443	Val F1: 0.700
Best Epoch: 2	Best Epoch Val F1: 0.707

******************************Epoch: 5******************************
Batch: 1/3370	Loss:0.615
Batch: 338/3370	Loss:0.585
Batch: 675/3370	Loss:0.277
Batch: 1012/3370	Loss:0.381
Batch: 1349/3370	Loss:0.077
Batch: 1686/3370	Loss:0.220
Batch: 2023/3370	Loss:0.088
Batch: 2360/3370	Loss:0.059
Batch: 2697/3370	Loss:0.927
Batch: 3034/3370	Loss:0.358
Batch: 3370/3370	Loss:0.469
Epoch: 5	Train Loss: 0.391	Val F1: 0.693
Best Epoch: 2	Best Epoch Val F1: 0.707

******************************Epoch: 6******************************
Batch: 1/3370	Loss:0.041
Batch: 338/3370	Loss:0.100
Batch: 675/3370	Loss:0.371
Batch: 1012/3370	Loss:0.160
Batch: 1349/3370	Loss:0.125
Batch: 1686/3370	Loss:0.473
Batch: 2023/3370	Loss:0.061
Batch: 2360/3370	Loss:0.317
Batch: 2697/3370	Loss:0.035
Batch: 3034/3370	Loss:0.649
Batch: 3370/3370	Loss:0.003
Epoch: 6	Train Loss: 0.350	Val F1: 0.717
Best Epoch: 6	Best Epoch Val F1: 0.717

******************************Epoch: 7******************************
Batch: 1/3370	Loss:0.149
Batch: 338/3370	Loss:0.306
Batch: 675/3370	Loss:0.312
Batch: 1012/3370	Loss:0.041
Batch: 1349/3370	Loss:0.074
Batch: 1686/3370	Loss:0.928
Batch: 2023/3370	Loss:0.579
Batch: 2360/3370	Loss:0.424
Batch: 2697/3370	Loss:0.189
Batch: 3034/3370	Loss:0.113
Batch: 3370/3370	Loss:0.004
Epoch: 7	Train Loss: 0.308	Val F1: 0.686
Best Epoch: 6	Best Epoch Val F1: 0.717

******************************Epoch: 8******************************
Batch: 1/3370	Loss:0.251
Batch: 338/3370	Loss:0.517
Batch: 675/3370	Loss:0.004
Batch: 1012/3370	Loss:0.108
Batch: 1349/3370	Loss:0.097
Batch: 1686/3370	Loss:0.050
Batch: 2023/3370	Loss:0.308
Batch: 2360/3370	Loss:0.400
Batch: 2697/3370	Loss:0.038
Batch: 3034/3370	Loss:0.065
Batch: 3370/3370	Loss:0.016
Epoch: 8	Train Loss: 0.281	Val F1: 0.681
Best Epoch: 6	Best Epoch Val F1: 0.717

******************************Epoch: 9******************************
Batch: 1/3370	Loss:0.743
Batch: 338/3370	Loss:0.494
Batch: 675/3370	Loss:0.997
Batch: 1012/3370	Loss:0.119
Batch: 1349/3370	Loss:0.608
Batch: 1686/3370	Loss:0.657
Batch: 2023/3370	Loss:0.054
Batch: 2360/3370	Loss:0.601
Batch: 2697/3370	Loss:0.248
Batch: 3034/3370	Loss:0.491
Batch: 3370/3370	Loss:0.387
Epoch: 9	Train Loss: 0.248	Val F1: 0.714
Best Epoch: 6	Best Epoch Val F1: 0.717

******************************Epoch: 10******************************
Batch: 1/3370	Loss:0.615
Batch: 338/3370	Loss:0.849
Batch: 675/3370	Loss:0.157
Batch: 1012/3370	Loss:0.182
Batch: 1349/3370	Loss:0.027
Batch: 1686/3370	Loss:0.164
Batch: 2023/3370	Loss:0.167
Batch: 2360/3370	Loss:0.016
Batch: 2697/3370	Loss:0.711
Batch: 3034/3370	Loss:0.423
Batch: 3370/3370	Loss:1.482
Epoch: 10	Train Loss: 0.227	Val F1: 0.714
Best Epoch: 6	Best Epoch Val F1: 0.717

******************************Epoch: 11******************************
Batch: 1/3370	Loss:0.085
Batch: 338/3370	Loss:0.031
Batch: 675/3370	Loss:0.112
Batch: 1012/3370	Loss:0.035
Batch: 1349/3370	Loss:0.019
Batch: 1686/3370	Loss:0.008
Batch: 2023/3370	Loss:0.687
Batch: 2360/3370	Loss:0.342
Batch: 2697/3370	Loss:0.103
Batch: 3034/3370	Loss:0.335
Batch: 3370/3370	Loss:0.001
Epoch: 11	Train Loss: 0.205	Val F1: 0.711
Best Epoch: 6	Best Epoch Val F1: 0.717

Saving the best checkpoint....
Inference...
Test F1: 0.736	Test F1_Few: 0.743	Test F1_Zero: 0.729
Starting training with config: {'batch_size': 32, 'epochs': 25, 'l2_reg': 8.1130180973738e-05, 'lr': 4.3318575472042456e-05, 'n_layers_freeze': 1, 'patience': 15}
Let's use 1 GPUs!
Preparing data....
Training data....
# of train examples: 13477
max len: 512, max len wiki: 1
Val data....
# of val examples: 2062
max len: 512, max len wiki: 1
Test data....
# of test examples: 3006
max len: 512, max len wiki: 1
Done

Initializing model....
******************************Epoch: 1******************************
Batch: 1/422	Loss:1.244
Batch: 43/422	Loss:1.087
Batch: 85/422	Loss:1.151
Batch: 127/422	Loss:1.054
Batch: 169/422	Loss:1.115
Batch: 211/422	Loss:0.803
Batch: 253/422	Loss:0.585
Batch: 295/422	Loss:0.860
Batch: 337/422	Loss:1.002
Batch: 379/422	Loss:0.649
Batch: 421/422	Loss:0.808
Batch: 422/422	Loss:0.740
Epoch: 1	Train Loss: 0.869	Val F1: 0.711
Best Epoch: 1	Best Epoch Val F1: 0.711

******************************Epoch: 2******************************
Batch: 1/422	Loss:0.731
Batch: 43/422	Loss:0.830
Batch: 85/422	Loss:0.698
Batch: 127/422	Loss:0.626
Batch: 169/422	Loss:0.679
Batch: 211/422	Loss:0.667
Batch: 253/422	Loss:0.553
Batch: 295/422	Loss:0.655
Batch: 337/422	Loss:0.733
Batch: 379/422	Loss:0.495
Batch: 421/422	Loss:0.513
Batch: 422/422	Loss:0.406
Epoch: 2	Train Loss: 0.591	Val F1: 0.691
Best Epoch: 1	Best Epoch Val F1: 0.711

******************************Epoch: 3******************************
Batch: 1/422	Loss:0.457
Batch: 43/422	Loss:0.473
Batch: 85/422	Loss:0.497
Batch: 127/422	Loss:0.428
Batch: 169/422	Loss:0.489
Batch: 211/422	Loss:0.765
Batch: 253/422	Loss:0.462
Batch: 295/422	Loss:0.671
Batch: 337/422	Loss:0.415
Batch: 379/422	Loss:0.513
Batch: 421/422	Loss:0.422
Batch: 422/422	Loss:0.319
Epoch: 3	Train Loss: 0.478	Val F1: 0.709
Best Epoch: 1	Best Epoch Val F1: 0.711

******************************Epoch: 4******************************
Batch: 1/422	Loss:0.396
Batch: 43/422	Loss:0.468
Batch: 85/422	Loss:0.399
Batch: 127/422	Loss:0.431
Batch: 169/422	Loss:0.417
Batch: 211/422	Loss:0.379
Batch: 253/422	Loss:0.338
Batch: 295/422	Loss:0.320
Batch: 337/422	Loss:0.494
Batch: 379/422	Loss:0.456
Batch: 421/422	Loss:0.295
Batch: 422/422	Loss:1.357
Epoch: 4	Train Loss: 0.409	Val F1: 0.690
Best Epoch: 1	Best Epoch Val F1: 0.711

******************************Epoch: 5******************************
Batch: 1/422	Loss:0.305
Batch: 43/422	Loss:0.296
Batch: 85/422	Loss:0.321
Batch: 127/422	Loss:0.237
Batch: 169/422	Loss:0.391
Batch: 211/422	Loss:0.316
Batch: 253/422	Loss:0.247
Batch: 295/422	Loss:0.327
Batch: 337/422	Loss:0.298
Batch: 379/422	Loss:0.481
Batch: 421/422	Loss:0.300
Batch: 422/422	Loss:0.393
Epoch: 5	Train Loss: 0.361	Val F1: 0.682
Best Epoch: 1	Best Epoch Val F1: 0.711

******************************Epoch: 6******************************
Batch: 1/422	Loss:0.226
Batch: 43/422	Loss:0.249
Batch: 85/422	Loss:0.378
Batch: 127/422	Loss:0.258
Batch: 169/422	Loss:0.306
Batch: 211/422	Loss:0.329
Batch: 253/422	Loss:0.202
Batch: 295/422	Loss:0.307
Batch: 337/422	Loss:0.443
Batch: 379/422	Loss:0.343
Batch: 421/422	Loss:0.378
Batch: 422/422	Loss:0.065
Epoch: 6	Train Loss: 0.310	Val F1: 0.726
Best Epoch: 6	Best Epoch Val F1: 0.726

******************************Epoch: 7******************************
Batch: 1/422	Loss:0.284
Batch: 43/422	Loss:0.197
Batch: 85/422	Loss:0.269
Batch: 127/422	Loss:0.152
Batch: 169/422	Loss:0.425
Batch: 211/422	Loss:0.359
Batch: 253/422	Loss:0.271
Batch: 295/422	Loss:0.316
Batch: 337/422	Loss:0.334
Batch: 379/422	Loss:0.373
Batch: 421/422	Loss:0.412
Batch: 422/422	Loss:0.279
Epoch: 7	Train Loss: 0.277	Val F1: 0.706
Best Epoch: 6	Best Epoch Val F1: 0.726

******************************Epoch: 8******************************
Batch: 1/422	Loss:0.237
Batch: 43/422	Loss:0.697
Batch: 85/422	Loss:0.116
Batch: 127/422	Loss:0.321
Batch: 169/422	Loss:0.285
Batch: 211/422	Loss:0.198
Batch: 253/422	Loss:0.352
Batch: 295/422	Loss:0.380
Batch: 337/422	Loss:0.295
Batch: 379/422	Loss:0.184
Batch: 421/422	Loss:0.456
Batch: 422/422	Loss:0.193
Epoch: 8	Train Loss: 0.253	Val F1: 0.704
Best Epoch: 6	Best Epoch Val F1: 0.726

******************************Epoch: 9******************************
Batch: 1/422	Loss:0.334
Batch: 43/422	Loss:0.201
Batch: 85/422	Loss:0.138
Batch: 127/422	Loss:0.297
Batch: 169/422	Loss:0.179
Batch: 211/422	Loss:0.354
Batch: 253/422	Loss:0.232
Batch: 295/422	Loss:0.216
Batch: 337/422	Loss:0.362
Batch: 379/422	Loss:0.167
Batch: 421/422	Loss:0.172
Batch: 422/422	Loss:0.247
Epoch: 9	Train Loss: 0.219	Val F1: 0.711
Best Epoch: 6	Best Epoch Val F1: 0.726

******************************Epoch: 10******************************
Batch: 1/422	Loss:0.218
Batch: 43/422	Loss:0.224
Batch: 85/422	Loss:0.160
Batch: 127/422	Loss:0.030
Batch: 169/422	Loss:0.180
Batch: 211/422	Loss:0.164
Batch: 253/422	Loss:0.198
Batch: 295/422	Loss:0.079
Batch: 337/422	Loss:0.105
Batch: 379/422	Loss:0.250
Batch: 421/422	Loss:0.304
Batch: 422/422	Loss:0.002
Epoch: 10	Train Loss: 0.200	Val F1: 0.707
Best Epoch: 6	Best Epoch Val F1: 0.726

******************************Epoch: 11******************************
Batch: 1/422	Loss:0.181
Batch: 43/422	Loss:0.227
Batch: 85/422	Loss:0.153
Batch: 127/422	Loss:0.227
Batch: 169/422	Loss:0.144
Batch: 211/422	Loss:0.212
Batch: 253/422	Loss:0.282
Batch: 295/422	Loss:0.096
Batch: 337/422	Loss:0.241
Batch: 379/422	Loss:0.137
Batch: 421/422	Loss:0.309
Batch: 422/422	Loss:0.003
Epoch: 11	Train Loss: 0.178	Val F1: 0.706
Best Epoch: 6	Best Epoch Val F1: 0.726

******************************Epoch: 12******************************
Batch: 1/422	Loss:0.239
Batch: 43/422	Loss:0.116
Batch: 85/422	Loss:0.190
Batch: 127/422	Loss:0.120
Batch: 169/422	Loss:0.153
Batch: 211/422	Loss:0.185
Batch: 253/422	Loss:0.300
Batch: 295/422	Loss:0.132
Batch: 337/422	Loss:0.051
Batch: 379/422	Loss:0.151
Batch: 421/422	Loss:0.096
Batch: 422/422	Loss:0.222
Epoch: 12	Train Loss: 0.172	Val F1: 0.731
Best Epoch: 12	Best Epoch Val F1: 0.731

******************************Epoch: 13******************************
Batch: 1/422	Loss:0.251
Batch: 43/422	Loss:0.190
Batch: 85/422	Loss:0.227
Batch: 127/422	Loss:0.149
Batch: 169/422	Loss:0.090
Batch: 211/422	Loss:0.080
Batch: 253/422	Loss:0.080
Batch: 295/422	Loss:0.142
Batch: 337/422	Loss:0.137
Batch: 379/422	Loss:0.239
Batch: 421/422	Loss:0.184
Batch: 422/422	Loss:0.103
Epoch: 13	Train Loss: 0.161	Val F1: 0.719
Best Epoch: 12	Best Epoch Val F1: 0.731

******************************Epoch: 14******************************
Batch: 1/422	Loss:0.152
Batch: 43/422	Loss:0.223
Batch: 85/422	Loss:0.084
Batch: 127/422	Loss:0.175
Batch: 169/422	Loss:0.149
Batch: 211/422	Loss:0.124
Batch: 253/422	Loss:0.060
Batch: 295/422	Loss:0.063
Batch: 337/422	Loss:0.138
Batch: 379/422	Loss:0.151
Batch: 421/422	Loss:0.215
Batch: 422/422	Loss:0.002
Epoch: 14	Train Loss: 0.153	Val F1: 0.713
Best Epoch: 12	Best Epoch Val F1: 0.731

******************************Epoch: 15******************************
Batch: 1/422	Loss:0.070
Batch: 43/422	Loss:0.048
Batch: 85/422	Loss:0.087
Batch: 127/422	Loss:0.096
Batch: 169/422	Loss:0.113
Batch: 211/422	Loss:0.033
Batch: 253/422	Loss:0.143
Batch: 295/422	Loss:0.170
Batch: 337/422	Loss:0.226
Batch: 379/422	Loss:0.151
Batch: 421/422	Loss:0.224
Batch: 422/422	Loss:0.004
Epoch: 15	Train Loss: 0.140	Val F1: 0.700
Best Epoch: 12	Best Epoch Val F1: 0.731

******************************Epoch: 16******************************
Batch: 1/422	Loss:0.065
Batch: 43/422	Loss:0.159
Batch: 85/422	Loss:0.103
Batch: 127/422	Loss:0.040
Batch: 169/422	Loss:0.120
Batch: 211/422	Loss:0.150
Batch: 253/422	Loss:0.233
Batch: 295/422	Loss:0.151
Batch: 337/422	Loss:0.074
Batch: 379/422	Loss:0.146
Batch: 421/422	Loss:0.314
Batch: 422/422	Loss:0.108
Epoch: 16	Train Loss: 0.136	Val F1: 0.687
Best Epoch: 12	Best Epoch Val F1: 0.731

******************************Epoch: 17******************************
Batch: 1/422	Loss:0.063
Batch: 43/422	Loss:0.209
Batch: 85/422	Loss:0.073
Batch: 127/422	Loss:0.046
Batch: 169/422	Loss:0.077
Batch: 211/422	Loss:0.080
Batch: 253/422	Loss:0.310
Batch: 295/422	Loss:0.086
Batch: 337/422	Loss:0.125
Batch: 379/422	Loss:0.198
Batch: 421/422	Loss:0.042
Batch: 422/422	Loss:0.001
Epoch: 17	Train Loss: 0.137	Val F1: 0.710
Best Epoch: 12	Best Epoch Val F1: 0.731

******************************Epoch: 18******************************
Batch: 1/422	Loss:0.141
Batch: 43/422	Loss:0.037
Batch: 85/422	Loss:0.092
Batch: 127/422	Loss:0.086
Batch: 169/422	Loss:0.199
Batch: 211/422	Loss:0.118
Batch: 253/422	Loss:0.145
Batch: 295/422	Loss:0.166
Batch: 337/422	Loss:0.040
Batch: 379/422	Loss:0.101
Batch: 421/422	Loss:0.233
Batch: 422/422	Loss:0.020
Epoch: 18	Train Loss: 0.121	Val F1: 0.691
Best Epoch: 12	Best Epoch Val F1: 0.731

******************************Epoch: 19******************************
Batch: 1/422	Loss:0.212
Batch: 43/422	Loss:0.257
Batch: 85/422	Loss:0.117
Batch: 127/422	Loss:0.254
Batch: 169/422	Loss:0.239
Batch: 211/422	Loss:0.300
Batch: 253/422	Loss:0.121
Batch: 295/422	Loss:0.145
Batch: 337/422	Loss:0.185
Batch: 379/422	Loss:0.087
Batch: 421/422	Loss:0.061
Batch: 422/422	Loss:0.006
Epoch: 19	Train Loss: 0.123	Val F1: 0.705
Best Epoch: 12	Best Epoch Val F1: 0.731

******************************Epoch: 20******************************
Batch: 1/422	Loss:0.049
Batch: 43/422	Loss:0.174
Batch: 85/422	Loss:0.080
Batch: 127/422	Loss:0.020
Batch: 169/422	Loss:0.080
Batch: 211/422	Loss:0.066
Batch: 253/422	Loss:0.276
Batch: 295/422	Loss:0.118
Batch: 337/422	Loss:0.311
Batch: 379/422	Loss:0.115
Batch: 421/422	Loss:0.098
Batch: 422/422	Loss:0.009
Epoch: 20	Train Loss: 0.123	Val F1: 0.704
Best Epoch: 12	Best Epoch Val F1: 0.731

******************************Epoch: 21******************************
Batch: 1/422	Loss:0.038
Batch: 43/422	Loss:0.056
Batch: 85/422	Loss:0.035
Batch: 127/422	Loss:0.036
Batch: 169/422	Loss:0.063
Batch: 211/422	Loss:0.242
Batch: 253/422	Loss:0.103
Batch: 295/422	Loss:0.017
Batch: 337/422	Loss:0.106
Batch: 379/422	Loss:0.144
Batch: 421/422	Loss:0.112
Batch: 422/422	Loss:0.197
Epoch: 21	Train Loss: 0.116	Val F1: 0.695
Best Epoch: 12	Best Epoch Val F1: 0.731

******************************Epoch: 22******************************
Batch: 1/422	Loss:0.065
Batch: 43/422	Loss:0.252
Batch: 85/422	Loss:0.024
Batch: 127/422	Loss:0.047
Batch: 169/422	Loss:0.143
Batch: 211/422	Loss:0.051
Batch: 253/422	Loss:0.151
Batch: 295/422	Loss:0.192
Batch: 337/422	Loss:0.159
Batch: 379/422	Loss:0.084
Batch: 421/422	Loss:0.143
Batch: 422/422	Loss:0.163
Epoch: 22	Train Loss: 0.105	Val F1: 0.703
Best Epoch: 12	Best Epoch Val F1: 0.731

******************************Epoch: 23******************************
Batch: 1/422	Loss:0.102
Batch: 43/422	Loss:0.023
Batch: 85/422	Loss:0.108
Batch: 127/422	Loss:0.058
Batch: 169/422	Loss:0.016
Batch: 211/422	Loss:0.057
Batch: 253/422	Loss:0.112
Batch: 295/422	Loss:0.190
Batch: 337/422	Loss:0.184
Batch: 379/422	Loss:0.088
Batch: 421/422	Loss:0.098
Batch: 422/422	Loss:0.159
Epoch: 23	Train Loss: 0.113	Val F1: 0.708
Best Epoch: 12	Best Epoch Val F1: 0.731

******************************Epoch: 24******************************
Batch: 1/422	Loss:0.106
Batch: 43/422	Loss:0.066
Batch: 85/422	Loss:0.045
Batch: 127/422	Loss:0.056
Batch: 169/422	Loss:0.108
Batch: 211/422	Loss:0.048
Batch: 253/422	Loss:0.144
Batch: 295/422	Loss:0.038
Batch: 337/422	Loss:0.065
Batch: 379/422	Loss:0.069
Batch: 421/422	Loss:0.070
Batch: 422/422	Loss:0.019
Epoch: 24	Train Loss: 0.116	Val F1: 0.705
Best Epoch: 12	Best Epoch Val F1: 0.731

******************************Epoch: 25******************************
Batch: 1/422	Loss:0.119
Batch: 43/422	Loss:0.068
Batch: 85/422	Loss:0.256
Batch: 127/422	Loss:0.109
Batch: 169/422	Loss:0.083
Batch: 211/422	Loss:0.076
Batch: 253/422	Loss:0.165
Batch: 295/422	Loss:0.100
Batch: 337/422	Loss:0.044
Batch: 379/422	Loss:0.042
Batch: 421/422	Loss:0.143
Batch: 422/422	Loss:0.008
Epoch: 25	Train Loss: 0.107	Val F1: 0.700
Best Epoch: 12	Best Epoch Val F1: 0.731

Saving the best checkpoint....
Inference...
Test F1: 0.732	Test F1_Few: 0.741	Test F1_Zero: 0.723
Starting training with config: {'batch_size': 16, 'epochs': 75, 'l2_reg': 9.890821998653755e-05, 'lr': 3.0376132163226627e-05, 'n_layers_freeze': 4, 'patience': 15}
Let's use 1 GPUs!
Preparing data....
Training data....
# of train examples: 13477
max len: 512, max len wiki: 1
Val data....
# of val examples: 2062
max len: 512, max len wiki: 1
Test data....
# of test examples: 3006
max len: 512, max len wiki: 1
Done

Initializing model....
******************************Epoch: 1******************************
Batch: 1/843	Loss:1.114
Batch: 85/843	Loss:1.163
Batch: 169/843	Loss:1.247
Batch: 253/843	Loss:0.707
Batch: 337/843	Loss:0.822
Batch: 421/843	Loss:0.754
Batch: 505/843	Loss:0.424
Batch: 589/843	Loss:0.512
Batch: 673/843	Loss:0.810
Batch: 757/843	Loss:0.633
Batch: 841/843	Loss:0.745
Batch: 843/843	Loss:0.785
Epoch: 1	Train Loss: 0.798	Val F1: 0.665
Best Epoch: 1	Best Epoch Val F1: 0.665

******************************Epoch: 2******************************
Batch: 1/843	Loss:0.682
Batch: 85/843	Loss:0.882
Batch: 169/843	Loss:0.881
Batch: 253/843	Loss:0.555
Batch: 337/843	Loss:0.537
Batch: 421/843	Loss:0.801
Batch: 505/843	Loss:0.626
Batch: 589/843	Loss:0.826
Batch: 673/843	Loss:0.669
Batch: 757/843	Loss:0.734
Batch: 841/843	Loss:0.761
Batch: 843/843	Loss:0.417
Epoch: 2	Train Loss: 0.595	Val F1: 0.717
Best Epoch: 2	Best Epoch Val F1: 0.717

******************************Epoch: 3******************************
Batch: 1/843	Loss:0.440
Batch: 85/843	Loss:0.542
Batch: 169/843	Loss:0.520
Batch: 253/843	Loss:0.383
Batch: 337/843	Loss:0.431
Batch: 421/843	Loss:0.753
Batch: 505/843	Loss:0.523
Batch: 589/843	Loss:0.592
Batch: 673/843	Loss:0.387
Batch: 757/843	Loss:0.651
Batch: 841/843	Loss:0.344
Batch: 843/843	Loss:0.117
Epoch: 3	Train Loss: 0.506	Val F1: 0.727
Best Epoch: 3	Best Epoch Val F1: 0.727

******************************Epoch: 4******************************
Batch: 1/843	Loss:0.327
Batch: 85/843	Loss:0.504
Batch: 169/843	Loss:0.370
Batch: 253/843	Loss:0.560
Batch: 337/843	Loss:0.325
Batch: 421/843	Loss:0.602
Batch: 505/843	Loss:0.466
Batch: 589/843	Loss:0.242
Batch: 673/843	Loss:0.688
Batch: 757/843	Loss:0.406
Batch: 841/843	Loss:0.138
Batch: 843/843	Loss:1.384
Epoch: 4	Train Loss: 0.436	Val F1: 0.686
Best Epoch: 3	Best Epoch Val F1: 0.727

******************************Epoch: 5******************************
Batch: 1/843	Loss:0.387
Batch: 85/843	Loss:0.539
Batch: 169/843	Loss:0.369
Batch: 253/843	Loss:0.208
Batch: 337/843	Loss:0.837
Batch: 421/843	Loss:0.525
Batch: 505/843	Loss:0.283
Batch: 589/843	Loss:0.807
Batch: 673/843	Loss:0.275
Batch: 757/843	Loss:0.290
Batch: 841/843	Loss:0.244
Batch: 843/843	Loss:0.416
Epoch: 5	Train Loss: 0.384	Val F1: 0.712
Best Epoch: 3	Best Epoch Val F1: 0.727

******************************Epoch: 6******************************
Batch: 1/843	Loss:0.173
Batch: 85/843	Loss:0.148
Batch: 169/843	Loss:0.349
Batch: 253/843	Loss:0.437
Batch: 337/843	Loss:0.344
Batch: 421/843	Loss:0.309
Batch: 505/843	Loss:0.379
Batch: 589/843	Loss:0.322
Batch: 673/843	Loss:0.318
Batch: 757/843	Loss:0.209
Batch: 841/843	Loss:0.470
Batch: 843/843	Loss:0.054
Epoch: 6	Train Loss: 0.348	Val F1: 0.719
Best Epoch: 3	Best Epoch Val F1: 0.727

******************************Epoch: 7******************************
Batch: 1/843	Loss:0.332
Batch: 85/843	Loss:0.196
Batch: 169/843	Loss:0.346
Batch: 253/843	Loss:0.325
Batch: 337/843	Loss:0.603
Batch: 421/843	Loss:0.132
Batch: 505/843	Loss:0.161
Batch: 589/843	Loss:0.101
Batch: 673/843	Loss:0.553
Batch: 757/843	Loss:0.369
Batch: 841/843	Loss:0.448
Batch: 843/843	Loss:0.183
Epoch: 7	Train Loss: 0.308	Val F1: 0.715
Best Epoch: 3	Best Epoch Val F1: 0.727

******************************Epoch: 8******************************
Batch: 1/843	Loss:0.160
Batch: 85/843	Loss:0.305
Batch: 169/843	Loss:0.061
Batch: 253/843	Loss:0.264
Batch: 337/843	Loss:0.142
Batch: 421/843	Loss:0.209
Batch: 505/843	Loss:0.422
Batch: 589/843	Loss:0.237
Batch: 673/843	Loss:0.264
Batch: 757/843	Loss:0.188
Batch: 841/843	Loss:0.334
Batch: 843/843	Loss:0.314
Epoch: 8	Train Loss: 0.270	Val F1: 0.699
Best Epoch: 3	Best Epoch Val F1: 0.727

******************************Epoch: 9******************************
Batch: 1/843	Loss:0.804
Batch: 85/843	Loss:0.369
Batch: 169/843	Loss:0.330
Batch: 253/843	Loss:0.533
Batch: 337/843	Loss:0.114
Batch: 421/843	Loss:0.496
Batch: 505/843	Loss:0.352
Batch: 589/843	Loss:0.212
Batch: 673/843	Loss:0.427
Batch: 757/843	Loss:0.223
Batch: 841/843	Loss:0.267
Batch: 843/843	Loss:0.079
Epoch: 9	Train Loss: 0.247	Val F1: 0.726
Best Epoch: 3	Best Epoch Val F1: 0.727

******************************Epoch: 10******************************
Batch: 1/843	Loss:0.364
Batch: 85/843	Loss:0.366
Batch: 169/843	Loss:0.194
Batch: 253/843	Loss:0.129
Batch: 337/843	Loss:0.438
Batch: 421/843	Loss:0.159
Batch: 505/843	Loss:0.206
Batch: 589/843	Loss:0.117
Batch: 673/843	Loss:0.063
Batch: 757/843	Loss:0.283
Batch: 841/843	Loss:0.037
Batch: 843/843	Loss:0.062
Epoch: 10	Train Loss: 0.230	Val F1: 0.706
Best Epoch: 3	Best Epoch Val F1: 0.727

******************************Epoch: 11******************************
Batch: 1/843	Loss:0.386
Batch: 85/843	Loss:0.379
Batch: 169/843	Loss:0.100
Batch: 253/843	Loss:0.235
Batch: 337/843	Loss:0.258
Batch: 421/843	Loss:0.276
Batch: 505/843	Loss:0.295
Batch: 589/843	Loss:0.063
Batch: 673/843	Loss:0.582
Batch: 757/843	Loss:0.120
Batch: 841/843	Loss:0.130
Batch: 843/843	Loss:0.046
Epoch: 11	Train Loss: 0.208	Val F1: 0.703
Best Epoch: 3	Best Epoch Val F1: 0.727

******************************Epoch: 12******************************
Batch: 1/843	Loss:0.255
Batch: 85/843	Loss:0.104
Batch: 169/843	Loss:0.167
Batch: 253/843	Loss:0.164
Batch: 337/843	Loss:0.121
Batch: 421/843	Loss:0.296
Batch: 505/843	Loss:0.239
Batch: 589/843	Loss:0.143
Batch: 673/843	Loss:0.305
Batch: 757/843	Loss:0.114
Batch: 841/843	Loss:0.426
Batch: 843/843	Loss:0.059
Epoch: 12	Train Loss: 0.191	Val F1: 0.720
Best Epoch: 3	Best Epoch Val F1: 0.727

******************************Epoch: 13******************************
Batch: 1/843	Loss:0.036
Batch: 85/843	Loss:0.248
Batch: 169/843	Loss:0.291
Batch: 253/843	Loss:0.043
Batch: 337/843	Loss:0.112
Batch: 421/843	Loss:0.049
Batch: 505/843	Loss:0.097
Batch: 589/843	Loss:0.202
Batch: 673/843	Loss:0.072
Batch: 757/843	Loss:0.245
Batch: 841/843	Loss:0.243
Batch: 843/843	Loss:0.116
Epoch: 13	Train Loss: 0.181	Val F1: 0.712
Best Epoch: 3	Best Epoch Val F1: 0.727

******************************Epoch: 14******************************
Batch: 1/843	Loss:0.137
Batch: 85/843	Loss:0.024
Batch: 169/843	Loss:0.025
Batch: 253/843	Loss:0.109
Batch: 337/843	Loss:0.339
Batch: 421/843	Loss:0.118
Batch: 505/843	Loss:0.070
Batch: 589/843	Loss:0.036
Batch: 673/843	Loss:0.059
Batch: 757/843	Loss:0.025
Batch: 841/843	Loss:0.217
Batch: 843/843	Loss:0.017
Epoch: 14	Train Loss: 0.171	Val F1: 0.707
Best Epoch: 3	Best Epoch Val F1: 0.727

******************************Epoch: 15******************************
Batch: 1/843	Loss:0.080
Batch: 85/843	Loss:0.020
Batch: 169/843	Loss:0.058
Batch: 253/843	Loss:0.117
Batch: 337/843	Loss:0.244
Batch: 421/843	Loss:0.062
Batch: 505/843	Loss:0.110
Batch: 589/843	Loss:0.142
Batch: 673/843	Loss:0.108
Batch: 757/843	Loss:0.085
Batch: 841/843	Loss:0.124
Batch: 843/843	Loss:0.006
Epoch: 15	Train Loss: 0.159	Val F1: 0.693
Best Epoch: 3	Best Epoch Val F1: 0.727

******************************Epoch: 16******************************
Batch: 1/843	Loss:0.218
Batch: 85/843	Loss:0.290
Batch: 169/843	Loss:0.172
Batch: 253/843	Loss:0.170
Batch: 337/843	Loss:0.253
Batch: 421/843	Loss:0.179
Batch: 505/843	Loss:0.108
Batch: 589/843	Loss:0.205
Batch: 673/843	Loss:0.068
Batch: 757/843	Loss:0.246
Batch: 841/843	Loss:0.163
Batch: 843/843	Loss:0.219
Epoch: 16	Train Loss: 0.158	Val F1: 0.708
Best Epoch: 3	Best Epoch Val F1: 0.727

******************************Epoch: 17******************************
Batch: 1/843	Loss:0.118
Batch: 85/843	Loss:0.217
Batch: 169/843	Loss:0.054
Batch: 253/843	Loss:0.096
Batch: 337/843	Loss:0.142
Batch: 421/843	Loss:0.021
Batch: 505/843	Loss:0.738
Batch: 589/843	Loss:0.108
Batch: 673/843	Loss:0.446
Batch: 757/843	Loss:0.256
Batch: 841/843	Loss:0.082
Batch: 843/843	Loss:0.012
Epoch: 17	Train Loss: 0.147	Val F1: 0.707
Best Epoch: 3	Best Epoch Val F1: 0.727

******************************Epoch: 18******************************
Batch: 1/843	Loss:0.126
Batch: 85/843	Loss:0.041
Batch: 169/843	Loss:0.206
Batch: 253/843	Loss:0.090
Batch: 337/843	Loss:0.164
Batch: 421/843	Loss:0.116
Batch: 505/843	Loss:0.041
Batch: 589/843	Loss:0.114
Batch: 673/843	Loss:0.068
Batch: 757/843	Loss:0.092
Batch: 841/843	Loss:0.140
Batch: 843/843	Loss:0.312
Epoch: 18	Train Loss: 0.140	Val F1: 0.719
Best Epoch: 3	Best Epoch Val F1: 0.727

Saving the best checkpoint....
Inference...
Test F1: 0.731	Test F1_Few: 0.742	Test F1_Zero: 0.718
Starting training with config: {'batch_size': 32, 'epochs': 25, 'l2_reg': 7.208583790616237e-05, 'lr': 3.0787416389760645e-05, 'n_layers_freeze': 0, 'patience': 15}
Let's use 1 GPUs!
Preparing data....
Training data....
# of train examples: 13477
max len: 512, max len wiki: 1
Val data....
# of val examples: 2062
max len: 512, max len wiki: 1
Test data....
# of test examples: 3006
max len: 512, max len wiki: 1
Done

Initializing model....
******************************Epoch: 1******************************
Batch: 1/422	Loss:1.244
Batch: 43/422	Loss:1.092
Batch: 85/422	Loss:1.155
Batch: 127/422	Loss:1.052
Batch: 169/422	Loss:1.102
Batch: 211/422	Loss:0.736
Batch: 253/422	Loss:0.424
Batch: 295/422	Loss:0.785
Batch: 337/422	Loss:0.819
Batch: 379/422	Loss:0.536
Batch: 421/422	Loss:0.836
Batch: 422/422	Loss:0.656
Epoch: 1	Train Loss: 0.855	Val F1: 0.698
Best Epoch: 1	Best Epoch Val F1: 0.698

******************************Epoch: 2******************************
Batch: 1/422	Loss:0.586
Batch: 43/422	Loss:0.769
Batch: 85/422	Loss:0.650
Batch: 127/422	Loss:0.640
Batch: 169/422	Loss:0.526
Batch: 211/422	Loss:0.696
Batch: 253/422	Loss:0.503
Batch: 295/422	Loss:0.593
Batch: 337/422	Loss:0.738
Batch: 379/422	Loss:0.492
Batch: 421/422	Loss:0.523
Batch: 422/422	Loss:0.307
Epoch: 2	Train Loss: 0.566	Val F1: 0.703
Best Epoch: 2	Best Epoch Val F1: 0.703

******************************Epoch: 3******************************
Batch: 1/422	Loss:0.484
Batch: 43/422	Loss:0.492
Batch: 85/422	Loss:0.514
Batch: 127/422	Loss:0.467
Batch: 169/422	Loss:0.442
Batch: 211/422	Loss:0.617
Batch: 253/422	Loss:0.416
Batch: 295/422	Loss:0.778
Batch: 337/422	Loss:0.418
Batch: 379/422	Loss:0.537
Batch: 421/422	Loss:0.385
Batch: 422/422	Loss:0.152
Epoch: 3	Train Loss: 0.457	Val F1: 0.713
Best Epoch: 3	Best Epoch Val F1: 0.713

******************************Epoch: 4******************************
Batch: 1/422	Loss:0.297
Batch: 43/422	Loss:0.363
Batch: 85/422	Loss:0.415
Batch: 127/422	Loss:0.427
Batch: 169/422	Loss:0.459
Batch: 211/422	Loss:0.320
Batch: 253/422	Loss:0.291
Batch: 295/422	Loss:0.284
Batch: 337/422	Loss:0.454
Batch: 379/422	Loss:0.481
Batch: 421/422	Loss:0.242
Batch: 422/422	Loss:1.282
Epoch: 4	Train Loss: 0.393	Val F1: 0.707
Best Epoch: 3	Best Epoch Val F1: 0.713

******************************Epoch: 5******************************
Batch: 1/422	Loss:0.258
Batch: 43/422	Loss:0.265
Batch: 85/422	Loss:0.222
Batch: 127/422	Loss:0.204
Batch: 169/422	Loss:0.489
Batch: 211/422	Loss:0.256
Batch: 253/422	Loss:0.291
Batch: 295/422	Loss:0.515
Batch: 337/422	Loss:0.409
Batch: 379/422	Loss:0.315
Batch: 421/422	Loss:0.362
Batch: 422/422	Loss:0.244
Epoch: 5	Train Loss: 0.342	Val F1: 0.675
Best Epoch: 3	Best Epoch Val F1: 0.713

******************************Epoch: 6******************************
Batch: 1/422	Loss:0.229
Batch: 43/422	Loss:0.260
Batch: 85/422	Loss:0.345
Batch: 127/422	Loss:0.211
Batch: 169/422	Loss:0.269
Batch: 211/422	Loss:0.328
Batch: 253/422	Loss:0.158
Batch: 295/422	Loss:0.292
Batch: 337/422	Loss:0.343
Batch: 379/422	Loss:0.312
Batch: 421/422	Loss:0.250
Batch: 422/422	Loss:0.030
Epoch: 6	Train Loss: 0.288	Val F1: 0.708
Best Epoch: 3	Best Epoch Val F1: 0.713

******************************Epoch: 7******************************
Batch: 1/422	Loss:0.217
Batch: 43/422	Loss:0.194
Batch: 85/422	Loss:0.312
Batch: 127/422	Loss:0.159
Batch: 169/422	Loss:0.431
Batch: 211/422	Loss:0.397
Batch: 253/422	Loss:0.170
Batch: 295/422	Loss:0.284
Batch: 337/422	Loss:0.408
Batch: 379/422	Loss:0.385
Batch: 421/422	Loss:0.408
Batch: 422/422	Loss:0.146
Epoch: 7	Train Loss: 0.244	Val F1: 0.706
Best Epoch: 3	Best Epoch Val F1: 0.713

******************************Epoch: 8******************************
Batch: 1/422	Loss:0.147
Batch: 43/422	Loss:0.192
Batch: 85/422	Loss:0.090
Batch: 127/422	Loss:0.271
Batch: 169/422	Loss:0.286
Batch: 211/422	Loss:0.207
Batch: 253/422	Loss:0.221
Batch: 295/422	Loss:0.335
Batch: 337/422	Loss:0.126
Batch: 379/422	Loss:0.197
Batch: 421/422	Loss:0.379
Batch: 422/422	Loss:0.130
Epoch: 8	Train Loss: 0.215	Val F1: 0.720
Best Epoch: 8	Best Epoch Val F1: 0.720

******************************Epoch: 9******************************
Batch: 1/422	Loss:0.291
Batch: 43/422	Loss:0.131
Batch: 85/422	Loss:0.168
Batch: 127/422	Loss:0.275
Batch: 169/422	Loss:0.161
Batch: 211/422	Loss:0.263
Batch: 253/422	Loss:0.286
Batch: 295/422	Loss:0.215
Batch: 337/422	Loss:0.145
Batch: 379/422	Loss:0.089
Batch: 421/422	Loss:0.175
Batch: 422/422	Loss:0.237
Epoch: 9	Train Loss: 0.192	Val F1: 0.705
Best Epoch: 8	Best Epoch Val F1: 0.720

******************************Epoch: 10******************************
Batch: 1/422	Loss:0.216
Batch: 43/422	Loss:0.247
Batch: 85/422	Loss:0.181
Batch: 127/422	Loss:0.015
Batch: 169/422	Loss:0.108
Batch: 211/422	Loss:0.093
Batch: 253/422	Loss:0.226
Batch: 295/422	Loss:0.092
Batch: 337/422	Loss:0.028
Batch: 379/422	Loss:0.176
Batch: 421/422	Loss:0.083
Batch: 422/422	Loss:0.003
Epoch: 10	Train Loss: 0.173	Val F1: 0.723
Best Epoch: 10	Best Epoch Val F1: 0.723

******************************Epoch: 11******************************
Batch: 1/422	Loss:0.216
Batch: 43/422	Loss:0.128
Batch: 85/422	Loss:0.067
Batch: 127/422	Loss:0.099
Batch: 169/422	Loss:0.183
Batch: 211/422	Loss:0.132
Batch: 253/422	Loss:0.183
Batch: 295/422	Loss:0.039
Batch: 337/422	Loss:0.271
Batch: 379/422	Loss:0.125
Batch: 421/422	Loss:0.075
Batch: 422/422	Loss:0.011
Epoch: 11	Train Loss: 0.150	Val F1: 0.702
Best Epoch: 10	Best Epoch Val F1: 0.723

******************************Epoch: 12******************************
Batch: 1/422	Loss:0.169
Batch: 43/422	Loss:0.045
Batch: 85/422	Loss:0.142
Batch: 127/422	Loss:0.242
Batch: 169/422	Loss:0.064
Batch: 211/422	Loss:0.173
Batch: 253/422	Loss:0.378
Batch: 295/422	Loss:0.083
Batch: 337/422	Loss:0.073
Batch: 379/422	Loss:0.163
Batch: 421/422	Loss:0.121
Batch: 422/422	Loss:0.000
Epoch: 12	Train Loss: 0.144	Val F1: 0.709
Best Epoch: 10	Best Epoch Val F1: 0.723

******************************Epoch: 13******************************
Batch: 1/422	Loss:0.267
Batch: 43/422	Loss:0.239
Batch: 85/422	Loss:0.104
Batch: 127/422	Loss:0.100
Batch: 169/422	Loss:0.101
Batch: 211/422	Loss:0.098
Batch: 253/422	Loss:0.375
Batch: 295/422	Loss:0.143
Batch: 337/422	Loss:0.166
Batch: 379/422	Loss:0.395
Batch: 421/422	Loss:0.092
Batch: 422/422	Loss:0.106
Epoch: 13	Train Loss: 0.136	Val F1: 0.721
Best Epoch: 10	Best Epoch Val F1: 0.723

******************************Epoch: 14******************************
Batch: 1/422	Loss:0.086
Batch: 43/422	Loss:0.069
Batch: 85/422	Loss:0.128
Batch: 127/422	Loss:0.073
Batch: 169/422	Loss:0.057
Batch: 211/422	Loss:0.081
Batch: 253/422	Loss:0.062
Batch: 295/422	Loss:0.016
Batch: 337/422	Loss:0.124
Batch: 379/422	Loss:0.194
Batch: 421/422	Loss:0.117
Batch: 422/422	Loss:0.016
Epoch: 14	Train Loss: 0.124	Val F1: 0.688
Best Epoch: 10	Best Epoch Val F1: 0.723

******************************Epoch: 15******************************
Batch: 1/422	Loss:0.025
Batch: 43/422	Loss:0.112
Batch: 85/422	Loss:0.079
Batch: 127/422	Loss:0.165
Batch: 169/422	Loss:0.093
Batch: 211/422	Loss:0.102
Batch: 253/422	Loss:0.234
Batch: 295/422	Loss:0.138
Batch: 337/422	Loss:0.172
Batch: 379/422	Loss:0.126
Batch: 421/422	Loss:0.338
Batch: 422/422	Loss:0.007
Epoch: 15	Train Loss: 0.122	Val F1: 0.714
Best Epoch: 10	Best Epoch Val F1: 0.723

******************************Epoch: 16******************************
Batch: 1/422	Loss:0.061
Batch: 43/422	Loss:0.106
Batch: 85/422	Loss:0.109
Batch: 127/422	Loss:0.062
Batch: 169/422	Loss:0.198
Batch: 211/422	Loss:0.049
Batch: 253/422	Loss:0.107
Batch: 295/422	Loss:0.058
Batch: 337/422	Loss:0.060
Batch: 379/422	Loss:0.138
Batch: 421/422	Loss:0.193
Batch: 422/422	Loss:0.097
Epoch: 16	Train Loss: 0.118	Val F1: 0.707
Best Epoch: 10	Best Epoch Val F1: 0.723

******************************Epoch: 17******************************
Batch: 1/422	Loss:0.056
Batch: 43/422	Loss:0.109
Batch: 85/422	Loss:0.081
Batch: 127/422	Loss:0.089
Batch: 169/422	Loss:0.046
Batch: 211/422	Loss:0.032
Batch: 253/422	Loss:0.151
Batch: 295/422	Loss:0.059
Batch: 337/422	Loss:0.123
Batch: 379/422	Loss:0.123
Batch: 421/422	Loss:0.081
Batch: 422/422	Loss:0.003
Epoch: 17	Train Loss: 0.119	Val F1: 0.715
Best Epoch: 10	Best Epoch Val F1: 0.723

******************************Epoch: 18******************************
Batch: 1/422	Loss:0.158
Batch: 43/422	Loss:0.042
Batch: 85/422	Loss:0.090
Batch: 127/422	Loss:0.075
Batch: 169/422	Loss:0.168
Batch: 211/422	Loss:0.137
Batch: 253/422	Loss:0.102
Batch: 295/422	Loss:0.089
Batch: 337/422	Loss:0.078
Batch: 379/422	Loss:0.070
Batch: 421/422	Loss:0.133
Batch: 422/422	Loss:0.097
Epoch: 18	Train Loss: 0.111	Val F1: 0.729
Best Epoch: 18	Best Epoch Val F1: 0.729

******************************Epoch: 19******************************
Batch: 1/422	Loss:0.083
Batch: 43/422	Loss:0.145
Batch: 85/422	Loss:0.116
Batch: 127/422	Loss:0.294
Batch: 169/422	Loss:0.229
Batch: 211/422	Loss:0.075
Batch: 253/422	Loss:0.073
Batch: 295/422	Loss:0.359
Batch: 337/422	Loss:0.131
Batch: 379/422	Loss:0.092
Batch: 421/422	Loss:0.117
Batch: 422/422	Loss:0.023
Epoch: 19	Train Loss: 0.118	Val F1: 0.703
Best Epoch: 18	Best Epoch Val F1: 0.729

******************************Epoch: 20******************************
Batch: 1/422	Loss:0.075
Batch: 43/422	Loss:0.127
Batch: 85/422	Loss:0.102
Batch: 127/422	Loss:0.061
Batch: 169/422	Loss:0.252
Batch: 211/422	Loss:0.077
Batch: 253/422	Loss:0.027
Batch: 295/422	Loss:0.080
Batch: 337/422	Loss:0.186
Batch: 379/422	Loss:0.084
Batch: 421/422	Loss:0.103
Batch: 422/422	Loss:0.018
Epoch: 20	Train Loss: 0.103	Val F1: 0.702
Best Epoch: 18	Best Epoch Val F1: 0.729

******************************Epoch: 21******************************
Batch: 1/422	Loss:0.034
Batch: 43/422	Loss:0.062
Batch: 85/422	Loss:0.041
Batch: 127/422	Loss:0.046
Batch: 169/422	Loss:0.045
Batch: 211/422	Loss:0.075
Batch: 253/422	Loss:0.072
Batch: 295/422	Loss:0.076
Batch: 337/422	Loss:0.117
Batch: 379/422	Loss:0.192
Batch: 421/422	Loss:0.089
Batch: 422/422	Loss:0.436
Epoch: 21	Train Loss: 0.100	Val F1: 0.696
Best Epoch: 18	Best Epoch Val F1: 0.729

******************************Epoch: 22******************************
Batch: 1/422	Loss:0.085
Batch: 43/422	Loss:0.044
Batch: 85/422	Loss:0.052
Batch: 127/422	Loss:0.067
Batch: 169/422	Loss:0.077
Batch: 211/422	Loss:0.105
Batch: 253/422	Loss:0.100
Batch: 295/422	Loss:0.206
Batch: 337/422	Loss:0.165
Batch: 379/422	Loss:0.158
Batch: 421/422	Loss:0.199
Batch: 422/422	Loss:0.501
Epoch: 22	Train Loss: 0.098	Val F1: 0.714
Best Epoch: 18	Best Epoch Val F1: 0.729

******************************Epoch: 23******************************
Batch: 1/422	Loss:0.098
Batch: 43/422	Loss:0.012
Batch: 85/422	Loss:0.178
Batch: 127/422	Loss:0.249
Batch: 169/422	Loss:0.013
Batch: 211/422	Loss:0.092
Batch: 253/422	Loss:0.114
Batch: 295/422	Loss:0.097
Batch: 337/422	Loss:0.198
Batch: 379/422	Loss:0.122
Batch: 421/422	Loss:0.116
Batch: 422/422	Loss:0.083
Epoch: 23	Train Loss: 0.103	Val F1: 0.696
Best Epoch: 18	Best Epoch Val F1: 0.729

******************************Epoch: 24******************************
Batch: 1/422	Loss:0.083
Batch: 43/422	Loss:0.026
Batch: 85/422	Loss:0.048
Batch: 127/422	Loss:0.189
Batch: 169/422	Loss:0.094
Batch: 211/422	Loss:0.053
Batch: 253/422	Loss:0.059
Batch: 295/422	Loss:0.052
Batch: 337/422	Loss:0.085
Batch: 379/422	Loss:0.060
Batch: 421/422	Loss:0.088
Batch: 422/422	Loss:0.047
Epoch: 24	Train Loss: 0.093	Val F1: 0.720
Best Epoch: 18	Best Epoch Val F1: 0.729

******************************Epoch: 25******************************
Batch: 1/422	Loss:0.092
Batch: 43/422	Loss:0.115
Batch: 85/422	Loss:0.124
Batch: 127/422	Loss:0.138
Batch: 169/422	Loss:0.071
Batch: 211/422	Loss:0.111
Batch: 253/422	Loss:0.072
Batch: 295/422	Loss:0.044
Batch: 337/422	Loss:0.046
Batch: 379/422	Loss:0.045
Batch: 421/422	Loss:0.593
Batch: 422/422	Loss:0.010
Epoch: 25	Train Loss: 0.088	Val F1: 0.700
Best Epoch: 18	Best Epoch Val F1: 0.729

Saving the best checkpoint....
Inference...
Test F1: 0.719	Test F1_Few: 0.732	Test F1_Zero: 0.704
Starting training with config: {'batch_size': 4, 'epochs': 75, 'l2_reg': 3.357797377886195e-05, 'lr': 3.231538452810784e-05, 'n_layers_freeze': 2, 'patience': 15}
Let's use 1 GPUs!
Preparing data....
Training data....
# of train examples: 13477
max len: 512, max len wiki: 1
Val data....
# of val examples: 2062
max len: 512, max len wiki: 1
Test data....
# of test examples: 3006
max len: 512, max len wiki: 1
Done

Initializing model....
******************************Epoch: 1******************************
Batch: 1/3370	Loss:1.322
Batch: 338/3370	Loss:1.249
Batch: 675/3370	Loss:1.211
Batch: 1012/3370	Loss:1.129
Batch: 1349/3370	Loss:0.895
Batch: 1686/3370	Loss:1.430
Batch: 2023/3370	Loss:1.024
Batch: 2360/3370	Loss:1.298
Batch: 2697/3370	Loss:0.877
Batch: 3034/3370	Loss:0.957
Batch: 3370/3370	Loss:1.251
Epoch: 1	Train Loss: 1.050	Val F1: 0.299
Best Epoch: 1	Best Epoch Val F1: 0.299

******************************Epoch: 2******************************
Batch: 1/3370	Loss:1.115
Batch: 338/3370	Loss:0.970
Batch: 675/3370	Loss:0.794
Batch: 1012/3370	Loss:0.934
Batch: 1349/3370	Loss:1.042
Batch: 1686/3370	Loss:0.708
Batch: 2023/3370	Loss:0.807
Batch: 2360/3370	Loss:0.924
Batch: 2697/3370	Loss:0.589
Batch: 3034/3370	Loss:0.571
Batch: 3370/3370	Loss:1.647
Epoch: 2	Train Loss: 1.016	Val F1: 0.298
Best Epoch: 1	Best Epoch Val F1: 0.299

******************************Epoch: 3******************************
Batch: 1/3370	Loss:0.976
Batch: 338/3370	Loss:1.177
Batch: 675/3370	Loss:0.916
Batch: 1012/3370	Loss:0.749
Batch: 1349/3370	Loss:0.926
Batch: 1686/3370	Loss:1.260
Batch: 2023/3370	Loss:1.242
Batch: 2360/3370	Loss:1.202
Batch: 2697/3370	Loss:0.441
Batch: 3034/3370	Loss:0.830
Batch: 3370/3370	Loss:0.397
Epoch: 3	Train Loss: 0.990	Val F1: 0.283
Best Epoch: 1	Best Epoch Val F1: 0.299

******************************Epoch: 4******************************
Batch: 1/3370	Loss:0.477
Batch: 338/3370	Loss:1.547
Batch: 675/3370	Loss:0.941
Batch: 1012/3370	Loss:0.909
Batch: 1349/3370	Loss:0.722
Batch: 1686/3370	Loss:1.009
Batch: 2023/3370	Loss:1.130
Batch: 2360/3370	Loss:0.809
Batch: 2697/3370	Loss:0.732
Batch: 3034/3370	Loss:1.164
Batch: 3370/3370	Loss:1.520
Epoch: 4	Train Loss: 0.957	Val F1: 0.256
Best Epoch: 1	Best Epoch Val F1: 0.299

******************************Epoch: 5******************************
Batch: 1/3370	Loss:1.691
Batch: 338/3370	Loss:1.098
Batch: 675/3370	Loss:0.591
Batch: 1012/3370	Loss:0.872
Batch: 1349/3370	Loss:0.308
Batch: 1686/3370	Loss:0.415
Batch: 2023/3370	Loss:1.143
Batch: 2360/3370	Loss:1.091
Batch: 2697/3370	Loss:1.157
Batch: 3034/3370	Loss:0.482
Batch: 3370/3370	Loss:1.270
Epoch: 5	Train Loss: 0.927	Val F1: 0.253
Best Epoch: 1	Best Epoch Val F1: 0.299

******************************Epoch: 6******************************
Batch: 1/3370	Loss:1.427
Batch: 338/3370	Loss:0.919
Batch: 675/3370	Loss:0.759
Batch: 1012/3370	Loss:1.167
Batch: 1349/3370	Loss:0.824
Batch: 1686/3370	Loss:1.076
Batch: 2023/3370	Loss:0.544
Batch: 2360/3370	Loss:0.769
Batch: 2697/3370	Loss:0.839
Batch: 3034/3370	Loss:1.007
Batch: 3370/3370	Loss:1.550
Epoch: 6	Train Loss: 0.919	Val F1: 0.294
Best Epoch: 1	Best Epoch Val F1: 0.299

******************************Epoch: 7******************************
Batch: 1/3370	Loss:0.739
Batch: 338/3370	Loss:0.807
Batch: 675/3370	Loss:0.797
Batch: 1012/3370	Loss:0.763
Batch: 1349/3370	Loss:0.483
Batch: 1686/3370	Loss:1.045
Batch: 2023/3370	Loss:1.482
Batch: 2360/3370	Loss:0.771
Batch: 2697/3370	Loss:0.596
Batch: 3034/3370	Loss:0.713
Batch: 3370/3370	Loss:1.886
Epoch: 7	Train Loss: 0.894	Val F1: 0.278
Best Epoch: 1	Best Epoch Val F1: 0.299

******************************Epoch: 8******************************
Batch: 1/3370	Loss:0.676
Batch: 338/3370	Loss:1.030
Batch: 675/3370	Loss:1.338
Batch: 1012/3370	Loss:0.773
Batch: 1349/3370	Loss:0.274
Batch: 1686/3370	Loss:0.606
Batch: 2023/3370	Loss:1.788
Batch: 2360/3370	Loss:0.738
Batch: 2697/3370	Loss:0.821
Batch: 3034/3370	Loss:0.788
Batch: 3370/3370	Loss:0.346
Epoch: 8	Train Loss: 0.783	Val F1: 0.575
Best Epoch: 8	Best Epoch Val F1: 0.575

******************************Epoch: 9******************************
Batch: 1/3370	Loss:1.490
Batch: 338/3370	Loss:0.955
Batch: 675/3370	Loss:1.417
Batch: 1012/3370	Loss:0.731
Batch: 1349/3370	Loss:0.705
Batch: 1686/3370	Loss:1.230
Batch: 2023/3370	Loss:0.604
Batch: 2360/3370	Loss:0.723
Batch: 2697/3370	Loss:0.776
Batch: 3034/3370	Loss:0.886
Batch: 3370/3370	Loss:0.728
Epoch: 9	Train Loss: 0.669	Val F1: 0.650
Best Epoch: 9	Best Epoch Val F1: 0.650

******************************Epoch: 10******************************
Batch: 1/3370	Loss:0.985
Batch: 338/3370	Loss:0.928
Batch: 675/3370	Loss:1.227
Batch: 1012/3370	Loss:1.247
Batch: 1349/3370	Loss:0.480
Batch: 1686/3370	Loss:0.483
Batch: 2023/3370	Loss:0.763
Batch: 2360/3370	Loss:0.157
Batch: 2697/3370	Loss:0.649
Batch: 3034/3370	Loss:0.864
Batch: 3370/3370	Loss:1.448
Epoch: 10	Train Loss: 0.631	Val F1: 0.625
Best Epoch: 9	Best Epoch Val F1: 0.650

******************************Epoch: 11******************************
Batch: 1/3370	Loss:0.150
Batch: 338/3370	Loss:0.517
Batch: 675/3370	Loss:0.462
Batch: 1012/3370	Loss:0.347
Batch: 1349/3370	Loss:1.027
Batch: 1686/3370	Loss:0.592
Batch: 2023/3370	Loss:0.408
Batch: 2360/3370	Loss:1.435
Batch: 2697/3370	Loss:0.539
Batch: 3034/3370	Loss:1.172
Batch: 3370/3370	Loss:1.413
Epoch: 11	Train Loss: 0.706	Val F1: 0.172
Best Epoch: 9	Best Epoch Val F1: 0.650

******************************Epoch: 12******************************
Batch: 1/3370	Loss:0.891
Batch: 338/3370	Loss:1.246
Batch: 675/3370	Loss:0.626
Batch: 1012/3370	Loss:1.263
Batch: 1349/3370	Loss:0.988
Batch: 1686/3370	Loss:0.894
Batch: 2023/3370	Loss:0.649
Batch: 2360/3370	Loss:0.800
Batch: 2697/3370	Loss:1.888
Batch: 3034/3370	Loss:0.664
Batch: 3370/3370	Loss:0.252
Epoch: 12	Train Loss: 0.926	Val F1: 0.641
Best Epoch: 9	Best Epoch Val F1: 0.650

******************************Epoch: 13******************************
Batch: 1/3370	Loss:1.183
Batch: 338/3370	Loss:0.827
Batch: 675/3370	Loss:0.288
Batch: 1012/3370	Loss:0.767
Batch: 1349/3370	Loss:0.899
Batch: 1686/3370	Loss:0.374
Batch: 2023/3370	Loss:0.321
Batch: 2360/3370	Loss:0.587
Batch: 2697/3370	Loss:1.088
Batch: 3034/3370	Loss:0.198
Batch: 3370/3370	Loss:0.592
Epoch: 13	Train Loss: 0.666	Val F1: 0.633
Best Epoch: 9	Best Epoch Val F1: 0.650

******************************Epoch: 14******************************
Batch: 1/3370	Loss:0.750
Batch: 338/3370	Loss:0.214
Batch: 675/3370	Loss:0.146
Batch: 1012/3370	Loss:0.444
Batch: 1349/3370	Loss:0.405
Batch: 1686/3370	Loss:1.328
Batch: 2023/3370	Loss:0.167
Batch: 2360/3370	Loss:0.140
Batch: 2697/3370	Loss:0.436
Batch: 3034/3370	Loss:1.030
Batch: 3370/3370	Loss:0.346
Epoch: 14	Train Loss: 0.583	Val F1: 0.660
Best Epoch: 14	Best Epoch Val F1: 0.660

******************************Epoch: 15******************************
Batch: 1/3370	Loss:0.185
Batch: 338/3370	Loss:0.542
Batch: 675/3370	Loss:0.281
Batch: 1012/3370	Loss:1.092
Batch: 1349/3370	Loss:0.372
Batch: 1686/3370	Loss:0.994
Batch: 2023/3370	Loss:0.923
Batch: 2360/3370	Loss:1.364
Batch: 2697/3370	Loss:1.088
Batch: 3034/3370	Loss:1.116
Batch: 3370/3370	Loss:0.830
Epoch: 15	Train Loss: 0.833	Val F1: 0.166
Best Epoch: 14	Best Epoch Val F1: 0.660

******************************Epoch: 16******************************
Batch: 1/3370	Loss:0.863
Batch: 338/3370	Loss:1.055
Batch: 675/3370	Loss:0.858
Batch: 1012/3370	Loss:1.256
Batch: 1349/3370	Loss:1.356
Batch: 1686/3370	Loss:1.099
Batch: 2023/3370	Loss:0.914
Batch: 2360/3370	Loss:1.116
Batch: 2697/3370	Loss:1.310
Batch: 3034/3370	Loss:0.940
Batch: 3370/3370	Loss:1.020
Epoch: 16	Train Loss: 1.052	Val F1: 0.166
Best Epoch: 14	Best Epoch Val F1: 0.660

******************************Epoch: 17******************************
Batch: 1/3370	Loss:1.207
Batch: 338/3370	Loss:1.392
Batch: 675/3370	Loss:1.137
Batch: 1012/3370	Loss:1.330
Batch: 1349/3370	Loss:1.249
Batch: 1686/3370	Loss:1.048
Batch: 2023/3370	Loss:1.106
Batch: 2360/3370	Loss:1.092
Batch: 2697/3370	Loss:0.999
Batch: 3034/3370	Loss:1.118
Batch: 3370/3370	Loss:0.865
Epoch: 17	Train Loss: 1.050	Val F1: 0.166
Best Epoch: 14	Best Epoch Val F1: 0.660

******************************Epoch: 18******************************
Batch: 1/3370	Loss:0.885
Batch: 338/3370	Loss:0.874
Batch: 675/3370	Loss:0.862
Batch: 1012/3370	Loss:0.924
Batch: 1349/3370	Loss:0.878
Batch: 1686/3370	Loss:0.915
Batch: 2023/3370	Loss:0.916
Batch: 2360/3370	Loss:0.883
Batch: 2697/3370	Loss:0.931
Batch: 3034/3370	Loss:1.073
Batch: 3370/3370	Loss:0.908
Epoch: 18	Train Loss: 1.050	Val F1: 0.166
Best Epoch: 14	Best Epoch Val F1: 0.660

******************************Epoch: 19******************************
Batch: 1/3370	Loss:1.102
Batch: 338/3370	Loss:1.148
Batch: 675/3370	Loss:0.920
Batch: 1012/3370	Loss:0.896
Batch: 1349/3370	Loss:0.923
Batch: 1686/3370	Loss:0.958
Batch: 2023/3370	Loss:1.083
Batch: 2360/3370	Loss:1.102
Batch: 2697/3370	Loss:0.950
Batch: 3034/3370	Loss:1.517
Batch: 3370/3370	Loss:0.952
Epoch: 19	Train Loss: 1.049	Val F1: 0.166
Best Epoch: 14	Best Epoch Val F1: 0.660

******************************Epoch: 20******************************
Batch: 1/3370	Loss:0.908
Batch: 338/3370	Loss:1.100
Batch: 675/3370	Loss:1.522
Batch: 1012/3370	Loss:1.136
Batch: 1349/3370	Loss:1.070
Batch: 1686/3370	Loss:1.140
Batch: 2023/3370	Loss:1.111
Batch: 2360/3370	Loss:0.868
Batch: 2697/3370	Loss:1.289
Batch: 3034/3370	Loss:1.085
Batch: 3370/3370	Loss:0.994
Epoch: 20	Train Loss: 1.049	Val F1: 0.166
Best Epoch: 14	Best Epoch Val F1: 0.660

******************************Epoch: 21******************************
Batch: 1/3370	Loss:1.049
Batch: 338/3370	Loss:0.954
Batch: 675/3370	Loss:1.149
Batch: 1012/3370	Loss:0.936
Batch: 1349/3370	Loss:0.888
Batch: 1686/3370	Loss:1.099
Batch: 2023/3370	Loss:0.896
Batch: 2360/3370	Loss:0.901
Batch: 2697/3370	Loss:1.284
Batch: 3034/3370	Loss:1.261
Batch: 3370/3370	Loss:1.628
Epoch: 21	Train Loss: 1.049	Val F1: 0.166
Best Epoch: 14	Best Epoch Val F1: 0.660

******************************Epoch: 22******************************
Batch: 1/3370	Loss:1.086
Batch: 338/3370	Loss:1.137
Batch: 675/3370	Loss:1.245
Batch: 1012/3370	Loss:0.900
Batch: 1349/3370	Loss:1.100
Batch: 1686/3370	Loss:1.251
Batch: 2023/3370	Loss:1.111
Batch: 2360/3370	Loss:0.907
Batch: 2697/3370	Loss:1.091
Batch: 3034/3370	Loss:0.983
Batch: 3370/3370	Loss:0.931
Epoch: 22	Train Loss: 1.049	Val F1: 0.166
Best Epoch: 14	Best Epoch Val F1: 0.660

******************************Epoch: 23******************************
Batch: 1/3370	Loss:0.887
Batch: 338/3370	Loss:1.096
Batch: 675/3370	Loss:0.909
Batch: 1012/3370	Loss:0.912
Batch: 1349/3370	Loss:0.931
Batch: 1686/3370	Loss:1.129
Batch: 2023/3370	Loss:1.105
Batch: 2360/3370	Loss:0.883
Batch: 2697/3370	Loss:0.948
Batch: 3034/3370	Loss:1.099
Batch: 3370/3370	Loss:0.939
Epoch: 23	Train Loss: 1.049	Val F1: 0.166
Best Epoch: 14	Best Epoch Val F1: 0.660

******************************Epoch: 24******************************
Batch: 1/3370	Loss:0.887
Batch: 338/3370	Loss:1.271
Batch: 675/3370	Loss:1.099
Batch: 1012/3370	Loss:0.891
Batch: 1349/3370	Loss:0.850
Batch: 1686/3370	Loss:0.901
Batch: 2023/3370	Loss:1.111
Batch: 2360/3370	Loss:0.916
Batch: 2697/3370	Loss:0.904
Batch: 3034/3370	Loss:0.889
Batch: 3370/3370	Loss:0.920
Epoch: 24	Train Loss: 1.049	Val F1: 0.166
Best Epoch: 14	Best Epoch Val F1: 0.660

******************************Epoch: 25******************************
Batch: 1/3370	Loss:1.303
Batch: 338/3370	Loss:1.117
Batch: 675/3370	Loss:0.916
Batch: 1012/3370	Loss:0.900
Batch: 1349/3370	Loss:1.081
Batch: 1686/3370	Loss:1.246
Batch: 2023/3370	Loss:1.097
Batch: 2360/3370	Loss:0.891
Batch: 2697/3370	Loss:1.092
Batch: 3034/3370	Loss:0.880
Batch: 3370/3370	Loss:0.895
Epoch: 25	Train Loss: 1.049	Val F1: 0.166
Best Epoch: 14	Best Epoch Val F1: 0.660

******************************Epoch: 26******************************
Batch: 1/3370	Loss:1.136
Batch: 338/3370	Loss:1.067
Batch: 675/3370	Loss:1.313
Batch: 1012/3370	Loss:0.858
Batch: 1349/3370	Loss:0.882
Batch: 1686/3370	Loss:1.318
Batch: 2023/3370	Loss:0.865
Batch: 2360/3370	Loss:0.914
Batch: 2697/3370	Loss:1.080
Batch: 3034/3370	Loss:0.949
Batch: 3370/3370	Loss:0.973
Epoch: 26	Train Loss: 1.048	Val F1: 0.166
Best Epoch: 14	Best Epoch Val F1: 0.660

******************************Epoch: 27******************************
Batch: 1/3370	Loss:1.450
Batch: 338/3370	Loss:1.224
Batch: 675/3370	Loss:1.274
Batch: 1012/3370	Loss:0.986
Batch: 1349/3370	Loss:1.090
Batch: 1686/3370	Loss:0.846
Batch: 2023/3370	Loss:1.120
Batch: 2360/3370	Loss:1.099
Batch: 2697/3370	Loss:0.925
Batch: 3034/3370	Loss:1.103
Batch: 3370/3370	Loss:1.509
Epoch: 27	Train Loss: 1.048	Val F1: 0.166
Best Epoch: 14	Best Epoch Val F1: 0.660

******************************Epoch: 28******************************
Batch: 1/3370	Loss:0.935
Batch: 338/3370	Loss:1.064
Batch: 675/3370	Loss:1.095
Batch: 1012/3370	Loss:0.899
Batch: 1349/3370	Loss:1.323
Batch: 1686/3370	Loss:0.953
Batch: 2023/3370	Loss:1.091
Batch: 2360/3370	Loss:1.347
Batch: 2697/3370	Loss:1.090
Batch: 3034/3370	Loss:1.072
Batch: 3370/3370	Loss:0.878
Epoch: 28	Train Loss: 1.049	Val F1: 0.166
Best Epoch: 14	Best Epoch Val F1: 0.660

******************************Epoch: 29******************************
Batch: 1/3370	Loss:1.121
Batch: 338/3370	Loss:1.272
Batch: 675/3370	Loss:1.317
Batch: 1012/3370	Loss:0.928
Batch: 1349/3370	Loss:1.269
Batch: 1686/3370	Loss:1.356
Batch: 2023/3370	Loss:1.294
Batch: 2360/3370	Loss:1.058
Batch: 2697/3370	Loss:1.101
Batch: 3034/3370	Loss:1.122
Batch: 3370/3370	Loss:0.817
Epoch: 29	Train Loss: 1.048	Val F1: 0.166
Best Epoch: 14	Best Epoch Val F1: 0.660

Saving the best checkpoint....
Inference...
Test F1: 0.680	Test F1_Few: 0.695	Test F1_Zero: 0.661
Starting training with config: {'batch_size': 32, 'epochs': 25, 'l2_reg': 3.6911910394855015e-05, 'lr': 4.310505505333836e-05, 'n_layers_freeze': 2, 'patience': 5}
Let's use 1 GPUs!
Preparing data....
Training data....
# of train examples: 13477
max len: 512, max len wiki: 1
Val data....
# of val examples: 2062
max len: 512, max len wiki: 1
Test data....
# of test examples: 3006
max len: 512, max len wiki: 1
Done

Initializing model....
******************************Epoch: 1******************************
Batch: 1/422	Loss:1.244
Batch: 43/422	Loss:1.088
Batch: 85/422	Loss:1.143
Batch: 127/422	Loss:1.059
Batch: 169/422	Loss:1.002
Batch: 211/422	Loss:0.702
Batch: 253/422	Loss:0.471
Batch: 295/422	Loss:0.692
Batch: 337/422	Loss:0.916
Batch: 379/422	Loss:0.519
Batch: 421/422	Loss:0.773
Batch: 422/422	Loss:0.645
Epoch: 1	Train Loss: 0.844	Val F1: 0.712
Best Epoch: 1	Best Epoch Val F1: 0.712

******************************Epoch: 2******************************
Batch: 1/422	Loss:0.698
Batch: 43/422	Loss:0.875
Batch: 85/422	Loss:0.718
Batch: 127/422	Loss:0.618
Batch: 169/422	Loss:0.528
Batch: 211/422	Loss:0.644
Batch: 253/422	Loss:0.631
Batch: 295/422	Loss:0.622
Batch: 337/422	Loss:0.699
Batch: 379/422	Loss:0.571
Batch: 421/422	Loss:0.499
Batch: 422/422	Loss:0.553
Epoch: 2	Train Loss: 0.591	Val F1: 0.700
Best Epoch: 1	Best Epoch Val F1: 0.712

******************************Epoch: 3******************************
Batch: 1/422	Loss:0.530
Batch: 43/422	Loss:0.553
Batch: 85/422	Loss:0.535
Batch: 127/422	Loss:0.412
Batch: 169/422	Loss:0.378
Batch: 211/422	Loss:0.881
Batch: 253/422	Loss:0.439
Batch: 295/422	Loss:0.732
Batch: 337/422	Loss:0.453
Batch: 379/422	Loss:0.498
Batch: 421/422	Loss:0.519
Batch: 422/422	Loss:0.333
Epoch: 3	Train Loss: 0.486	Val F1: 0.707
Best Epoch: 1	Best Epoch Val F1: 0.712

******************************Epoch: 4******************************
Batch: 1/422	Loss:0.375
Batch: 43/422	Loss:0.457
Batch: 85/422	Loss:0.446
Batch: 127/422	Loss:0.527
Batch: 169/422	Loss:0.505
Batch: 211/422	Loss:0.362
Batch: 253/422	Loss:0.438
Batch: 295/422	Loss:0.355
Batch: 337/422	Loss:0.543
Batch: 379/422	Loss:0.615
Batch: 421/422	Loss:0.254
Batch: 422/422	Loss:0.739
Epoch: 4	Train Loss: 0.429	Val F1: 0.697
Best Epoch: 1	Best Epoch Val F1: 0.712

******************************Epoch: 5******************************
Batch: 1/422	Loss:0.407
Batch: 43/422	Loss:0.312
Batch: 85/422	Loss:0.324
Batch: 127/422	Loss:0.335
Batch: 169/422	Loss:0.553
Batch: 211/422	Loss:0.462
Batch: 253/422	Loss:0.262
Batch: 295/422	Loss:0.385
Batch: 337/422	Loss:0.325
Batch: 379/422	Loss:0.283
Batch: 421/422	Loss:0.302
Batch: 422/422	Loss:0.531
Epoch: 5	Train Loss: 0.375	Val F1: 0.708
Best Epoch: 1	Best Epoch Val F1: 0.712

******************************Epoch: 6******************************
Batch: 1/422	Loss:0.203
Batch: 43/422	Loss:0.200
Batch: 85/422	Loss:0.359
Batch: 127/422	Loss:0.231
Batch: 169/422	Loss:0.356
Batch: 211/422	Loss:0.406
Batch: 253/422	Loss:0.271
Batch: 295/422	Loss:0.253
Batch: 337/422	Loss:0.457
Batch: 379/422	Loss:0.298
Batch: 421/422	Loss:0.239
Batch: 422/422	Loss:0.084
Epoch: 6	Train Loss: 0.327	Val F1: 0.711
Best Epoch: 1	Best Epoch Val F1: 0.712

Saving the best checkpoint....
Inference...
Test F1: 0.695	Test F1_Few: 0.687	Test F1_Zero: 0.704
Starting training with config: {'batch_size': 32, 'epochs': 25, 'l2_reg': 9.82154541407499e-05, 'lr': 3.192676594132771e-05, 'n_layers_freeze': 4, 'patience': 15}
Let's use 1 GPUs!
Preparing data....
Training data....
# of train examples: 13477
max len: 512, max len wiki: 1
Val data....
# of val examples: 2062
max len: 512, max len wiki: 1
Test data....
# of test examples: 3006
max len: 512, max len wiki: 1
Done

Initializing model....
******************************Epoch: 1******************************
Batch: 1/422	Loss:1.244
Batch: 43/422	Loss:1.092
Batch: 85/422	Loss:1.144
Batch: 127/422	Loss:1.063
Batch: 169/422	Loss:1.110
Batch: 211/422	Loss:0.950
Batch: 253/422	Loss:0.651
Batch: 295/422	Loss:0.687
Batch: 337/422	Loss:0.737
Batch: 379/422	Loss:0.515
Batch: 421/422	Loss:0.719
Batch: 422/422	Loss:0.732
Epoch: 1	Train Loss: 0.893	Val F1: 0.691
Best Epoch: 1	Best Epoch Val F1: 0.691

******************************Epoch: 2******************************
Batch: 1/422	Loss:0.639
Batch: 43/422	Loss:0.851
Batch: 85/422	Loss:0.592
Batch: 127/422	Loss:0.653
Batch: 169/422	Loss:0.554
Batch: 211/422	Loss:0.700
Batch: 253/422	Loss:0.585
Batch: 295/422	Loss:0.680
Batch: 337/422	Loss:0.782
Batch: 379/422	Loss:0.565
Batch: 421/422	Loss:0.491
Batch: 422/422	Loss:0.345
Epoch: 2	Train Loss: 0.584	Val F1: 0.729
Best Epoch: 2	Best Epoch Val F1: 0.729

******************************Epoch: 3******************************
Batch: 1/422	Loss:0.612
Batch: 43/422	Loss:0.561
Batch: 85/422	Loss:0.520
Batch: 127/422	Loss:0.450
Batch: 169/422	Loss:0.381
Batch: 211/422	Loss:0.724
Batch: 253/422	Loss:0.431
Batch: 295/422	Loss:0.745
Batch: 337/422	Loss:0.438
Batch: 379/422	Loss:0.518
Batch: 421/422	Loss:0.379
Batch: 422/422	Loss:0.234
Epoch: 3	Train Loss: 0.487	Val F1: 0.750
Best Epoch: 3	Best Epoch Val F1: 0.750

******************************Epoch: 4******************************
Batch: 1/422	Loss:0.336
Batch: 43/422	Loss:0.408
Batch: 85/422	Loss:0.408
Batch: 127/422	Loss:0.362
Batch: 169/422	Loss:0.478
Batch: 211/422	Loss:0.439
Batch: 253/422	Loss:0.355
Batch: 295/422	Loss:0.250
Batch: 337/422	Loss:0.569
Batch: 379/422	Loss:0.432
Batch: 421/422	Loss:0.358
Batch: 422/422	Loss:0.742
Epoch: 4	Train Loss: 0.420	Val F1: 0.707
Best Epoch: 3	Best Epoch Val F1: 0.750

******************************Epoch: 5******************************
Batch: 1/422	Loss:0.322
Batch: 43/422	Loss:0.279
Batch: 85/422	Loss:0.329
Batch: 127/422	Loss:0.266
Batch: 169/422	Loss:0.439
Batch: 211/422	Loss:0.470
Batch: 253/422	Loss:0.263
Batch: 295/422	Loss:0.361
Batch: 337/422	Loss:0.367
Batch: 379/422	Loss:0.208
Batch: 421/422	Loss:0.401
Batch: 422/422	Loss:0.584
Epoch: 5	Train Loss: 0.368	Val F1: 0.699
Best Epoch: 3	Best Epoch Val F1: 0.750

******************************Epoch: 6******************************
Batch: 1/422	Loss:0.215
Batch: 43/422	Loss:0.320
Batch: 85/422	Loss:0.544
Batch: 127/422	Loss:0.281
Batch: 169/422	Loss:0.300
Batch: 211/422	Loss:0.498
Batch: 253/422	Loss:0.215
Batch: 295/422	Loss:0.254
Batch: 337/422	Loss:0.414
Batch: 379/422	Loss:0.354
Batch: 421/422	Loss:0.253
Batch: 422/422	Loss:0.065
Epoch: 6	Train Loss: 0.323	Val F1: 0.722
Best Epoch: 3	Best Epoch Val F1: 0.750

******************************Epoch: 7******************************
Batch: 1/422	Loss:0.324
Batch: 43/422	Loss:0.277
Batch: 85/422	Loss:0.311
Batch: 127/422	Loss:0.129
Batch: 169/422	Loss:0.800
Batch: 211/422	Loss:0.492
Batch: 253/422	Loss:0.339
Batch: 295/422	Loss:0.259
Batch: 337/422	Loss:0.570
Batch: 379/422	Loss:0.443
Batch: 421/422	Loss:0.408
Batch: 422/422	Loss:0.179
Epoch: 7	Train Loss: 0.291	Val F1: 0.708
Best Epoch: 3	Best Epoch Val F1: 0.750

******************************Epoch: 8******************************
Batch: 1/422	Loss:0.116
Batch: 43/422	Loss:0.325
Batch: 85/422	Loss:0.127
Batch: 127/422	Loss:0.308
Batch: 169/422	Loss:0.209
Batch: 211/422	Loss:0.200
Batch: 253/422	Loss:0.419
Batch: 295/422	Loss:0.254
Batch: 337/422	Loss:0.183
Batch: 379/422	Loss:0.288
Batch: 421/422	Loss:0.367
Batch: 422/422	Loss:0.149
Epoch: 8	Train Loss: 0.255	Val F1: 0.702
Best Epoch: 3	Best Epoch Val F1: 0.750

******************************Epoch: 9******************************
Batch: 1/422	Loss:0.387
Batch: 43/422	Loss:0.231
Batch: 85/422	Loss:0.198
Batch: 127/422	Loss:0.331
Batch: 169/422	Loss:0.237
Batch: 211/422	Loss:0.283
Batch: 253/422	Loss:0.178
Batch: 295/422	Loss:0.302
Batch: 337/422	Loss:0.250
Batch: 379/422	Loss:0.118
Batch: 421/422	Loss:0.277
Batch: 422/422	Loss:0.451
Epoch: 9	Train Loss: 0.225	Val F1: 0.706
Best Epoch: 3	Best Epoch Val F1: 0.750

******************************Epoch: 10******************************
Batch: 1/422	Loss:0.242
Batch: 43/422	Loss:0.314
Batch: 85/422	Loss:0.283
Batch: 127/422	Loss:0.033
Batch: 169/422	Loss:0.148
Batch: 211/422	Loss:0.233
Batch: 253/422	Loss:0.205
Batch: 295/422	Loss:0.157
Batch: 337/422	Loss:0.046
Batch: 379/422	Loss:0.485
Batch: 421/422	Loss:0.067
Batch: 422/422	Loss:0.012
Epoch: 10	Train Loss: 0.207	Val F1: 0.708
Best Epoch: 3	Best Epoch Val F1: 0.750

******************************Epoch: 11******************************
Batch: 1/422	Loss:0.194
Batch: 43/422	Loss:0.281
Batch: 85/422	Loss:0.134
Batch: 127/422	Loss:0.221
Batch: 169/422	Loss:0.223
Batch: 211/422	Loss:0.172
Batch: 253/422	Loss:0.262
Batch: 295/422	Loss:0.132
Batch: 337/422	Loss:0.276
Batch: 379/422	Loss:0.061
Batch: 421/422	Loss:0.262
Batch: 422/422	Loss:0.001
Epoch: 11	Train Loss: 0.186	Val F1: 0.714
Best Epoch: 3	Best Epoch Val F1: 0.750

******************************Epoch: 12******************************
Batch: 1/422	Loss:0.137
Batch: 43/422	Loss:0.114
Batch: 85/422	Loss:0.120
Batch: 127/422	Loss:0.241
Batch: 169/422	Loss:0.082
Batch: 211/422	Loss:0.171
Batch: 253/422	Loss:0.226
Batch: 295/422	Loss:0.109
Batch: 337/422	Loss:0.148
Batch: 379/422	Loss:0.107
Batch: 421/422	Loss:0.159
Batch: 422/422	Loss:0.009
Epoch: 12	Train Loss: 0.170	Val F1: 0.732
Best Epoch: 3	Best Epoch Val F1: 0.750

******************************Epoch: 13******************************
Batch: 1/422	Loss:0.144
Batch: 43/422	Loss:0.159
Batch: 85/422	Loss:0.237
Batch: 127/422	Loss:0.114
Batch: 169/422	Loss:0.098
Batch: 211/422	Loss:0.106
Batch: 253/422	Loss:0.236
Batch: 295/422	Loss:0.131
Batch: 337/422	Loss:0.240
Batch: 379/422	Loss:0.360
Batch: 421/422	Loss:0.212
Batch: 422/422	Loss:0.101
Epoch: 13	Train Loss: 0.165	Val F1: 0.709
Best Epoch: 3	Best Epoch Val F1: 0.750

******************************Epoch: 14******************************
Batch: 1/422	Loss:0.141
Batch: 43/422	Loss:0.098
Batch: 85/422	Loss:0.069
Batch: 127/422	Loss:0.124
Batch: 169/422	Loss:0.312
Batch: 211/422	Loss:0.130
Batch: 253/422	Loss:0.060
Batch: 295/422	Loss:0.054
Batch: 337/422	Loss:0.144
Batch: 379/422	Loss:0.156
Batch: 421/422	Loss:0.187
Batch: 422/422	Loss:0.006
Epoch: 14	Train Loss: 0.146	Val F1: 0.710
Best Epoch: 3	Best Epoch Val F1: 0.750

******************************Epoch: 15******************************
Batch: 1/422	Loss:0.063
Batch: 43/422	Loss:0.029
Batch: 85/422	Loss:0.073
Batch: 127/422	Loss:0.074
Batch: 169/422	Loss:0.086
Batch: 211/422	Loss:0.071
Batch: 253/422	Loss:0.207
Batch: 295/422	Loss:0.220
Batch: 337/422	Loss:0.141
Batch: 379/422	Loss:0.080
Batch: 421/422	Loss:0.183
Batch: 422/422	Loss:0.001
Epoch: 15	Train Loss: 0.139	Val F1: 0.710
Best Epoch: 3	Best Epoch Val F1: 0.750

******************************Epoch: 16******************************
Batch: 1/422	Loss:0.070
Batch: 43/422	Loss:0.133
Batch: 85/422	Loss:0.091
Batch: 127/422	Loss:0.105
Batch: 169/422	Loss:0.176
Batch: 211/422	Loss:0.067
Batch: 253/422	Loss:0.177
Batch: 295/422	Loss:0.058
Batch: 337/422	Loss:0.077
Batch: 379/422	Loss:0.265
Batch: 421/422	Loss:0.184
Batch: 422/422	Loss:0.193
Epoch: 16	Train Loss: 0.142	Val F1: 0.708
Best Epoch: 3	Best Epoch Val F1: 0.750

******************************Epoch: 17******************************
Batch: 1/422	Loss:0.082
Batch: 43/422	Loss:0.129
Batch: 85/422	Loss:0.034
Batch: 127/422	Loss:0.085
Batch: 169/422	Loss:0.104
Batch: 211/422	Loss:0.052
Batch: 253/422	Loss:0.176
Batch: 295/422	Loss:0.117
Batch: 337/422	Loss:0.173
Batch: 379/422	Loss:0.106
Batch: 421/422	Loss:0.070
Batch: 422/422	Loss:0.001
Epoch: 17	Train Loss: 0.129	Val F1: 0.717
Best Epoch: 3	Best Epoch Val F1: 0.750

******************************Epoch: 18******************************
Batch: 1/422	Loss:0.110
Batch: 43/422	Loss:0.200
Batch: 85/422	Loss:0.079
Batch: 127/422	Loss:0.213
Batch: 169/422	Loss:0.167
Batch: 211/422	Loss:0.187
Batch: 253/422	Loss:0.169
Batch: 295/422	Loss:0.125
Batch: 337/422	Loss:0.020
Batch: 379/422	Loss:0.083
Batch: 421/422	Loss:0.121
Batch: 422/422	Loss:0.148
Epoch: 18	Train Loss: 0.130	Val F1: 0.719
Best Epoch: 3	Best Epoch Val F1: 0.750

Saving the best checkpoint....
Inference...
Test F1: 0.739	Test F1_Few: 0.752	Test F1_Zero: 0.725
Starting training with config: {'batch_size': 32, 'epochs': 25, 'l2_reg': 2.200829254912727e-05, 'lr': 3.477700355739651e-05, 'n_layers_freeze': 4, 'patience': 15}
Let's use 1 GPUs!
Preparing data....
Training data....
# of train examples: 13477
max len: 512, max len wiki: 1
Val data....
# of val examples: 2062
max len: 512, max len wiki: 1
Test data....
# of test examples: 3006
max len: 512, max len wiki: 1
Done

Initializing model....
******************************Epoch: 1******************************
Batch: 1/422	Loss:1.244
Batch: 43/422	Loss:1.096
Batch: 85/422	Loss:1.146
Batch: 127/422	Loss:1.063
Batch: 169/422	Loss:1.118
Batch: 211/422	Loss:0.930
Batch: 253/422	Loss:0.504
Batch: 295/422	Loss:0.640
Batch: 337/422	Loss:0.833
Batch: 379/422	Loss:0.538
Batch: 421/422	Loss:0.670
Batch: 422/422	Loss:0.770
Epoch: 1	Train Loss: 0.891	Val F1: 0.719
Best Epoch: 1	Best Epoch Val F1: 0.719

******************************Epoch: 2******************************
Batch: 1/422	Loss:0.622
Batch: 43/422	Loss:0.895
Batch: 85/422	Loss:0.558
Batch: 127/422	Loss:0.620
Batch: 169/422	Loss:0.593
Batch: 211/422	Loss:0.740
Batch: 253/422	Loss:0.615
Batch: 295/422	Loss:0.638
Batch: 337/422	Loss:0.722
Batch: 379/422	Loss:0.576
Batch: 421/422	Loss:0.586
Batch: 422/422	Loss:0.354
Epoch: 2	Train Loss: 0.586	Val F1: 0.726
Best Epoch: 2	Best Epoch Val F1: 0.726

******************************Epoch: 3******************************
Batch: 1/422	Loss:0.604
Batch: 43/422	Loss:0.493
Batch: 85/422	Loss:0.475
Batch: 127/422	Loss:0.470
Batch: 169/422	Loss:0.318
Batch: 211/422	Loss:0.859
Batch: 253/422	Loss:0.470
Batch: 295/422	Loss:0.634
Batch: 337/422	Loss:0.336
Batch: 379/422	Loss:0.528
Batch: 421/422	Loss:0.379
Batch: 422/422	Loss:0.540
Epoch: 3	Train Loss: 0.490	Val F1: 0.730
Best Epoch: 3	Best Epoch Val F1: 0.730

******************************Epoch: 4******************************
Batch: 1/422	Loss:0.342
Batch: 43/422	Loss:0.419
Batch: 85/422	Loss:0.460
Batch: 127/422	Loss:0.486
Batch: 169/422	Loss:0.485
Batch: 211/422	Loss:0.474
Batch: 253/422	Loss:0.360
Batch: 295/422	Loss:0.298
Batch: 337/422	Loss:0.527
Batch: 379/422	Loss:0.501
Batch: 421/422	Loss:0.341
Batch: 422/422	Loss:0.438
Epoch: 4	Train Loss: 0.418	Val F1: 0.705
Best Epoch: 3	Best Epoch Val F1: 0.730

******************************Epoch: 5******************************
Batch: 1/422	Loss:0.321
Batch: 43/422	Loss:0.284
Batch: 85/422	Loss:0.321
Batch: 127/422	Loss:0.330
Batch: 169/422	Loss:0.544
Batch: 211/422	Loss:0.424
Batch: 253/422	Loss:0.255
Batch: 295/422	Loss:0.488
Batch: 337/422	Loss:0.257
Batch: 379/422	Loss:0.265
Batch: 421/422	Loss:0.427
Batch: 422/422	Loss:0.679
Epoch: 5	Train Loss: 0.369	Val F1: 0.707
Best Epoch: 3	Best Epoch Val F1: 0.730

******************************Epoch: 6******************************
Batch: 1/422	Loss:0.193
Batch: 43/422	Loss:0.259
Batch: 85/422	Loss:0.391
Batch: 127/422	Loss:0.322
Batch: 169/422	Loss:0.321
Batch: 211/422	Loss:0.334
Batch: 253/422	Loss:0.320
Batch: 295/422	Loss:0.291
Batch: 337/422	Loss:0.452
Batch: 379/422	Loss:0.360
Batch: 421/422	Loss:0.265
Batch: 422/422	Loss:0.077
Epoch: 6	Train Loss: 0.322	Val F1: 0.722
Best Epoch: 3	Best Epoch Val F1: 0.730

******************************Epoch: 7******************************
Batch: 1/422	Loss:0.306
Batch: 43/422	Loss:0.221
Batch: 85/422	Loss:0.243
Batch: 127/422	Loss:0.161
Batch: 169/422	Loss:0.820
Batch: 211/422	Loss:0.387
Batch: 253/422	Loss:0.371
Batch: 295/422	Loss:0.326
Batch: 337/422	Loss:0.493
Batch: 379/422	Loss:0.499
Batch: 421/422	Loss:0.448
Batch: 422/422	Loss:0.207
Epoch: 7	Train Loss: 0.284	Val F1: 0.733
Best Epoch: 7	Best Epoch Val F1: 0.733

******************************Epoch: 8******************************
Batch: 1/422	Loss:0.172
Batch: 43/422	Loss:0.277
Batch: 85/422	Loss:0.142
Batch: 127/422	Loss:0.312
Batch: 169/422	Loss:0.182
Batch: 211/422	Loss:0.207
Batch: 253/422	Loss:0.392
Batch: 295/422	Loss:0.219
Batch: 337/422	Loss:0.213
Batch: 379/422	Loss:0.245
Batch: 421/422	Loss:0.336
Batch: 422/422	Loss:0.071
Epoch: 8	Train Loss: 0.256	Val F1: 0.727
Best Epoch: 7	Best Epoch Val F1: 0.733

******************************Epoch: 9******************************
Batch: 1/422	Loss:0.301
Batch: 43/422	Loss:0.292
Batch: 85/422	Loss:0.368
Batch: 127/422	Loss:0.294
Batch: 169/422	Loss:0.198
Batch: 211/422	Loss:0.461
Batch: 253/422	Loss:0.249
Batch: 295/422	Loss:0.231
Batch: 337/422	Loss:0.153
Batch: 379/422	Loss:0.151
Batch: 421/422	Loss:0.134
Batch: 422/422	Loss:0.578
Epoch: 9	Train Loss: 0.225	Val F1: 0.706
Best Epoch: 7	Best Epoch Val F1: 0.733

******************************Epoch: 10******************************
Batch: 1/422	Loss:0.290
Batch: 43/422	Loss:0.170
Batch: 85/422	Loss:0.153
Batch: 127/422	Loss:0.055
Batch: 169/422	Loss:0.069
Batch: 211/422	Loss:0.133
Batch: 253/422	Loss:0.428
Batch: 295/422	Loss:0.141
Batch: 337/422	Loss:0.089
Batch: 379/422	Loss:0.310
Batch: 421/422	Loss:0.109
Batch: 422/422	Loss:0.018
Epoch: 10	Train Loss: 0.204	Val F1: 0.722
Best Epoch: 7	Best Epoch Val F1: 0.733

******************************Epoch: 11******************************
Batch: 1/422	Loss:0.120
Batch: 43/422	Loss:0.248
Batch: 85/422	Loss:0.193
Batch: 127/422	Loss:0.167
Batch: 169/422	Loss:0.188
Batch: 211/422	Loss:0.130
Batch: 253/422	Loss:0.157
Batch: 295/422	Loss:0.168
Batch: 337/422	Loss:0.370
Batch: 379/422	Loss:0.086
Batch: 421/422	Loss:0.150
Batch: 422/422	Loss:0.003
Epoch: 11	Train Loss: 0.183	Val F1: 0.718
Best Epoch: 7	Best Epoch Val F1: 0.733

******************************Epoch: 12******************************
Batch: 1/422	Loss:0.138
Batch: 43/422	Loss:0.074
Batch: 85/422	Loss:0.184
Batch: 127/422	Loss:0.224
Batch: 169/422	Loss:0.163
Batch: 211/422	Loss:0.184
Batch: 253/422	Loss:0.174
Batch: 295/422	Loss:0.150
Batch: 337/422	Loss:0.122
Batch: 379/422	Loss:0.141
Batch: 421/422	Loss:0.213
Batch: 422/422	Loss:0.001
Epoch: 12	Train Loss: 0.170	Val F1: 0.705
Best Epoch: 7	Best Epoch Val F1: 0.733

******************************Epoch: 13******************************
Batch: 1/422	Loss:0.126
Batch: 43/422	Loss:0.425
Batch: 85/422	Loss:0.155
Batch: 127/422	Loss:0.056
Batch: 169/422	Loss:0.086
Batch: 211/422	Loss:0.090
Batch: 253/422	Loss:0.119
Batch: 295/422	Loss:0.195
Batch: 337/422	Loss:0.239
Batch: 379/422	Loss:0.271
Batch: 421/422	Loss:0.130
Batch: 422/422	Loss:0.187
Epoch: 13	Train Loss: 0.159	Val F1: 0.709
Best Epoch: 7	Best Epoch Val F1: 0.733

******************************Epoch: 14******************************
Batch: 1/422	Loss:0.076
Batch: 43/422	Loss:0.090
Batch: 85/422	Loss:0.132
Batch: 127/422	Loss:0.131
Batch: 169/422	Loss:0.087
Batch: 211/422	Loss:0.101
Batch: 253/422	Loss:0.067
Batch: 295/422	Loss:0.066
Batch: 337/422	Loss:0.103
Batch: 379/422	Loss:0.142
Batch: 421/422	Loss:0.142
Batch: 422/422	Loss:0.010
Epoch: 14	Train Loss: 0.147	Val F1: 0.704
Best Epoch: 7	Best Epoch Val F1: 0.733

******************************Epoch: 15******************************
Batch: 1/422	Loss:0.028
Batch: 43/422	Loss:0.058
Batch: 85/422	Loss:0.100
Batch: 127/422	Loss:0.236
Batch: 169/422	Loss:0.102
Batch: 211/422	Loss:0.073
Batch: 253/422	Loss:0.280
Batch: 295/422	Loss:0.107
Batch: 337/422	Loss:0.205
Batch: 379/422	Loss:0.095
Batch: 421/422	Loss:0.185
Batch: 422/422	Loss:0.001
Epoch: 15	Train Loss: 0.140	Val F1: 0.725
Best Epoch: 7	Best Epoch Val F1: 0.733

******************************Epoch: 16******************************
Batch: 1/422	Loss:0.066
Batch: 43/422	Loss:0.251
Batch: 85/422	Loss:0.184
Batch: 127/422	Loss:0.050
Batch: 169/422	Loss:0.156
Batch: 211/422	Loss:0.039
Batch: 253/422	Loss:0.126
Batch: 295/422	Loss:0.024
Batch: 337/422	Loss:0.253
Batch: 379/422	Loss:0.269
Batch: 421/422	Loss:0.197
Batch: 422/422	Loss:0.123
Epoch: 16	Train Loss: 0.137	Val F1: 0.691
Best Epoch: 7	Best Epoch Val F1: 0.733

******************************Epoch: 17******************************
Batch: 1/422	Loss:0.040
Batch: 43/422	Loss:0.138
Batch: 85/422	Loss:0.055
Batch: 127/422	Loss:0.042
Batch: 169/422	Loss:0.080
Batch: 211/422	Loss:0.040
Batch: 253/422	Loss:0.271
Batch: 295/422	Loss:0.089
Batch: 337/422	Loss:0.086
Batch: 379/422	Loss:0.275
Batch: 421/422	Loss:0.127
Batch: 422/422	Loss:0.001
Epoch: 17	Train Loss: 0.127	Val F1: 0.720
Best Epoch: 7	Best Epoch Val F1: 0.733

******************************Epoch: 18******************************
Batch: 1/422	Loss:0.097
Batch: 43/422	Loss:0.039
Batch: 85/422	Loss:0.095
Batch: 127/422	Loss:0.084
Batch: 169/422	Loss:0.283
Batch: 211/422	Loss:0.187
Batch: 253/422	Loss:0.193
Batch: 295/422	Loss:0.099
Batch: 337/422	Loss:0.052
Batch: 379/422	Loss:0.131
Batch: 421/422	Loss:0.103
Batch: 422/422	Loss:0.020
Epoch: 18	Train Loss: 0.122	Val F1: 0.720
Best Epoch: 7	Best Epoch Val F1: 0.733

******************************Epoch: 19******************************
Batch: 1/422	Loss:0.061
Batch: 43/422	Loss:0.254
Batch: 85/422	Loss:0.137
Batch: 127/422	Loss:0.183
Batch: 169/422	Loss:0.224
Batch: 211/422	Loss:0.073
Batch: 253/422	Loss:0.061
Batch: 295/422	Loss:0.196
Batch: 337/422	Loss:0.236
Batch: 379/422	Loss:0.090
Batch: 421/422	Loss:0.080
Batch: 422/422	Loss:0.187
Epoch: 19	Train Loss: 0.122	Val F1: 0.720
Best Epoch: 7	Best Epoch Val F1: 0.733

******************************Epoch: 20******************************
Batch: 1/422	Loss:0.041
Batch: 43/422	Loss:0.154
Batch: 85/422	Loss:0.065
Batch: 127/422	Loss:0.016
Batch: 169/422	Loss:0.157
Batch: 211/422	Loss:0.061
Batch: 253/422	Loss:0.079
Batch: 295/422	Loss:0.124
Batch: 337/422	Loss:0.140
Batch: 379/422	Loss:0.156
Batch: 421/422	Loss:0.068
Batch: 422/422	Loss:0.046
Epoch: 20	Train Loss: 0.116	Val F1: 0.710
Best Epoch: 7	Best Epoch Val F1: 0.733

******************************Epoch: 21******************************
Batch: 1/422	Loss:0.075
Batch: 43/422	Loss:0.059
Batch: 85/422	Loss:0.067
Batch: 127/422	Loss:0.059
Batch: 169/422	Loss:0.050
Batch: 211/422	Loss:0.044
Batch: 253/422	Loss:0.139
Batch: 295/422	Loss:0.036
Batch: 337/422	Loss:0.094
Batch: 379/422	Loss:0.174
Batch: 421/422	Loss:0.080
Batch: 422/422	Loss:0.365
Epoch: 21	Train Loss: 0.116	Val F1: 0.705
Best Epoch: 7	Best Epoch Val F1: 0.733

******************************Epoch: 22******************************
Batch: 1/422	Loss:0.115
Batch: 43/422	Loss:0.038
Batch: 85/422	Loss:0.047
Batch: 127/422	Loss:0.094
Batch: 169/422	Loss:0.183
Batch: 211/422	Loss:0.047
Batch: 253/422	Loss:0.156
Batch: 295/422	Loss:0.145
Batch: 337/422	Loss:0.180
Batch: 379/422	Loss:0.112
Batch: 421/422	Loss:0.131
Batch: 422/422	Loss:0.160
Epoch: 22	Train Loss: 0.114	Val F1: 0.719
Best Epoch: 7	Best Epoch Val F1: 0.733

Saving the best checkpoint....
Inference...
Test F1: 0.732	Test F1_Few: 0.746	Test F1_Zero: 0.717
Starting training with config: {'batch_size': 64, 'epochs': 75, 'l2_reg': 9.093382981394632e-05, 'lr': 1.9293679848045277e-05, 'n_layers_freeze': 4, 'patience': 15}
Let's use 1 GPUs!
Preparing data....
Training data....
# of train examples: 13477
max len: 512, max len wiki: 1
Val data....
# of val examples: 2062
max len: 512, max len wiki: 1
Test data....
# of test examples: 3006
max len: 512, max len wiki: 1
Done

Initializing model....
******************************Epoch: 1******************************
Batch: 1/211	Loss:1.300
Batch: 22/211	Loss:1.031
Batch: 43/211	Loss:1.168
Batch: 64/211	Loss:1.007
Batch: 85/211	Loss:1.064
Batch: 106/211	Loss:0.997
Batch: 127/211	Loss:1.067
Batch: 148/211	Loss:1.051
Batch: 169/211	Loss:0.932
Batch: 190/211	Loss:0.882
Batch: 211/211	Loss:0.837
Epoch: 1	Train Loss: 0.997	Val F1: 0.680
Best Epoch: 1	Best Epoch Val F1: 0.680

******************************Epoch: 2******************************
Batch: 1/211	Loss:0.802
Batch: 22/211	Loss:0.828
Batch: 43/211	Loss:0.693
Batch: 64/211	Loss:0.630
Batch: 85/211	Loss:0.733
Batch: 106/211	Loss:0.801
Batch: 127/211	Loss:0.720
Batch: 148/211	Loss:0.683
Batch: 169/211	Loss:0.657
Batch: 190/211	Loss:0.575
Batch: 211/211	Loss:0.546
Epoch: 2	Train Loss: 0.672	Val F1: 0.726
Best Epoch: 2	Best Epoch Val F1: 0.726

******************************Epoch: 3******************************
Batch: 1/211	Loss:0.638
Batch: 22/211	Loss:0.623
Batch: 43/211	Loss:0.574
Batch: 64/211	Loss:0.495
Batch: 85/211	Loss:0.481
Batch: 106/211	Loss:0.561
Batch: 127/211	Loss:0.450
Batch: 148/211	Loss:0.579
Batch: 169/211	Loss:0.604
Batch: 190/211	Loss:0.487
Batch: 211/211	Loss:0.449
Epoch: 3	Train Loss: 0.561	Val F1: 0.704
Best Epoch: 2	Best Epoch Val F1: 0.726

******************************Epoch: 4******************************
Batch: 1/211	Loss:0.444
Batch: 22/211	Loss:0.575
Batch: 43/211	Loss:0.417
Batch: 64/211	Loss:0.452
Batch: 85/211	Loss:0.471
Batch: 106/211	Loss:0.388
Batch: 127/211	Loss:0.423
Batch: 148/211	Loss:0.493
Batch: 169/211	Loss:0.525
Batch: 190/211	Loss:0.539
Batch: 211/211	Loss:0.484
Epoch: 4	Train Loss: 0.488	Val F1: 0.656
Best Epoch: 2	Best Epoch Val F1: 0.726

******************************Epoch: 5******************************
Batch: 1/211	Loss:0.514
Batch: 22/211	Loss:0.445
Batch: 43/211	Loss:0.304
Batch: 64/211	Loss:0.537
Batch: 85/211	Loss:0.501
Batch: 106/211	Loss:0.347
Batch: 127/211	Loss:0.381
Batch: 148/211	Loss:0.419
Batch: 169/211	Loss:0.422
Batch: 190/211	Loss:0.442
Batch: 211/211	Loss:0.481
Epoch: 5	Train Loss: 0.432	Val F1: 0.693
Best Epoch: 2	Best Epoch Val F1: 0.726

******************************Epoch: 6******************************
Batch: 1/211	Loss:0.292
Batch: 22/211	Loss:0.386
Batch: 43/211	Loss:0.348
Batch: 64/211	Loss:0.374
Batch: 85/211	Loss:0.362
Batch: 106/211	Loss:0.574
Batch: 127/211	Loss:0.382
Batch: 148/211	Loss:0.341
Batch: 169/211	Loss:0.445
Batch: 190/211	Loss:0.416
Batch: 211/211	Loss:0.266
Epoch: 6	Train Loss: 0.383	Val F1: 0.710
Best Epoch: 2	Best Epoch Val F1: 0.726

******************************Epoch: 7******************************
Batch: 1/211	Loss:0.433
Batch: 22/211	Loss:0.305
Batch: 43/211	Loss:0.388
Batch: 64/211	Loss:0.323
Batch: 85/211	Loss:0.481
Batch: 106/211	Loss:0.359
Batch: 127/211	Loss:0.515
Batch: 148/211	Loss:0.447
Batch: 169/211	Loss:0.456
Batch: 190/211	Loss:0.521
Batch: 211/211	Loss:0.409
Epoch: 7	Train Loss: 0.345	Val F1: 0.713
Best Epoch: 2	Best Epoch Val F1: 0.726

******************************Epoch: 8******************************
Batch: 1/211	Loss:0.222
Batch: 22/211	Loss:0.329
Batch: 43/211	Loss:0.255
Batch: 64/211	Loss:0.357
Batch: 85/211	Loss:0.362
Batch: 106/211	Loss:0.263
Batch: 127/211	Loss:0.395
Batch: 148/211	Loss:0.310
Batch: 169/211	Loss:0.334
Batch: 190/211	Loss:0.340
Batch: 211/211	Loss:0.480
Epoch: 8	Train Loss: 0.313	Val F1: 0.700
Best Epoch: 2	Best Epoch Val F1: 0.726

******************************Epoch: 9******************************
Batch: 1/211	Loss:0.259
Batch: 22/211	Loss:0.313
Batch: 43/211	Loss:0.331
Batch: 64/211	Loss:0.416
Batch: 85/211	Loss:0.303
Batch: 106/211	Loss:0.282
Batch: 127/211	Loss:0.345
Batch: 148/211	Loss:0.302
Batch: 169/211	Loss:0.192
Batch: 190/211	Loss:0.222
Batch: 211/211	Loss:0.234
Epoch: 9	Train Loss: 0.291	Val F1: 0.696
Best Epoch: 2	Best Epoch Val F1: 0.726

******************************Epoch: 10******************************
Batch: 1/211	Loss:0.197
Batch: 22/211	Loss:0.187
Batch: 43/211	Loss:0.301
Batch: 64/211	Loss:0.173
Batch: 85/211	Loss:0.249
Batch: 106/211	Loss:0.228
Batch: 127/211	Loss:0.323
Batch: 148/211	Loss:0.203
Batch: 169/211	Loss:0.208
Batch: 190/211	Loss:0.272
Batch: 211/211	Loss:0.093
Epoch: 10	Train Loss: 0.266	Val F1: 0.709
Best Epoch: 2	Best Epoch Val F1: 0.726

******************************Epoch: 11******************************
Batch: 1/211	Loss:0.174
Batch: 22/211	Loss:0.248
Batch: 43/211	Loss:0.163
Batch: 64/211	Loss:0.300
Batch: 85/211	Loss:0.211
Batch: 106/211	Loss:0.275
Batch: 127/211	Loss:0.437
Batch: 148/211	Loss:0.223
Batch: 169/211	Loss:0.332
Batch: 190/211	Loss:0.148
Batch: 211/211	Loss:0.171
Epoch: 11	Train Loss: 0.248	Val F1: 0.700
Best Epoch: 2	Best Epoch Val F1: 0.726

******************************Epoch: 12******************************
Batch: 1/211	Loss:0.188
Batch: 22/211	Loss:0.190
Batch: 43/211	Loss:0.177
Batch: 64/211	Loss:0.296
Batch: 85/211	Loss:0.117
Batch: 106/211	Loss:0.255
Batch: 127/211	Loss:0.238
Batch: 148/211	Loss:0.383
Batch: 169/211	Loss:0.216
Batch: 190/211	Loss:0.220
Batch: 211/211	Loss:0.189
Epoch: 12	Train Loss: 0.231	Val F1: 0.705
Best Epoch: 2	Best Epoch Val F1: 0.726

******************************Epoch: 13******************************
Batch: 1/211	Loss:0.265
Batch: 22/211	Loss:0.250
Batch: 43/211	Loss:0.147
Batch: 64/211	Loss:0.109
Batch: 85/211	Loss:0.137
Batch: 106/211	Loss:0.181
Batch: 127/211	Loss:0.289
Batch: 148/211	Loss:0.274
Batch: 169/211	Loss:0.214
Batch: 190/211	Loss:0.223
Batch: 211/211	Loss:0.214
Epoch: 13	Train Loss: 0.207	Val F1: 0.695
Best Epoch: 2	Best Epoch Val F1: 0.726

******************************Epoch: 14******************************
Batch: 1/211	Loss:0.148
Batch: 22/211	Loss:0.225
Batch: 43/211	Loss:0.127
Batch: 64/211	Loss:0.197
Batch: 85/211	Loss:0.185
Batch: 106/211	Loss:0.070
Batch: 127/211	Loss:0.122
Batch: 148/211	Loss:0.223
Batch: 169/211	Loss:0.167
Batch: 190/211	Loss:0.173
Batch: 211/211	Loss:0.305
Epoch: 14	Train Loss: 0.190	Val F1: 0.695
Best Epoch: 2	Best Epoch Val F1: 0.726

******************************Epoch: 15******************************
Batch: 1/211	Loss:0.125
Batch: 22/211	Loss:0.063
Batch: 43/211	Loss:0.146
Batch: 64/211	Loss:0.136
Batch: 85/211	Loss:0.135
Batch: 106/211	Loss:0.115
Batch: 127/211	Loss:0.351
Batch: 148/211	Loss:0.210
Batch: 169/211	Loss:0.185
Batch: 190/211	Loss:0.148
Batch: 211/211	Loss:0.223
Epoch: 15	Train Loss: 0.183	Val F1: 0.697
Best Epoch: 2	Best Epoch Val F1: 0.726

******************************Epoch: 16******************************
Batch: 1/211	Loss:0.166
Batch: 22/211	Loss:0.248
Batch: 43/211	Loss:0.118
Batch: 64/211	Loss:0.074
Batch: 85/211	Loss:0.077
Batch: 106/211	Loss:0.157
Batch: 127/211	Loss:0.218
Batch: 148/211	Loss:0.071
Batch: 169/211	Loss:0.088
Batch: 190/211	Loss:0.265
Batch: 211/211	Loss:0.191
Epoch: 16	Train Loss: 0.168	Val F1: 0.691
Best Epoch: 2	Best Epoch Val F1: 0.726

******************************Epoch: 17******************************
Batch: 1/211	Loss:0.092
Batch: 22/211	Loss:0.122
Batch: 43/211	Loss:0.105
Batch: 64/211	Loss:0.095
Batch: 85/211	Loss:0.077
Batch: 106/211	Loss:0.174
Batch: 127/211	Loss:0.262
Batch: 148/211	Loss:0.111
Batch: 169/211	Loss:0.134
Batch: 190/211	Loss:0.210
Batch: 211/211	Loss:0.082
Epoch: 17	Train Loss: 0.162	Val F1: 0.703
Best Epoch: 2	Best Epoch Val F1: 0.726

Saving the best checkpoint....
Inference...
Test F1: 0.745	Test F1_Few: 0.742	Test F1_Zero: 0.747
Starting training with config: {'batch_size': 64, 'epochs': 50, 'l2_reg': 5.973255929891731e-05, 'lr': 4.728288725780223e-05, 'n_layers_freeze': 4, 'patience': 10}
Let's use 1 GPUs!
Preparing data....
Training data....
# of train examples: 13477
max len: 512, max len wiki: 1
Val data....
# of val examples: 2062
max len: 512, max len wiki: 1
Test data....
# of test examples: 3006
max len: 512, max len wiki: 1
Done

Initializing model....
******************************Epoch: 1******************************
Batch: 1/211	Loss:1.300
Batch: 22/211	Loss:1.045
Batch: 43/211	Loss:1.135
Batch: 64/211	Loss:1.012
Batch: 85/211	Loss:1.019
Batch: 106/211	Loss:0.711
Batch: 127/211	Loss:0.668
Batch: 148/211	Loss:0.744
Batch: 169/211	Loss:0.769
Batch: 190/211	Loss:0.698
Batch: 211/211	Loss:0.712
Epoch: 1	Train Loss: 0.850	Val F1: 0.637
Best Epoch: 1	Best Epoch Val F1: 0.637

******************************Epoch: 2******************************
Batch: 1/211	Loss:0.765
Batch: 22/211	Loss:0.651
Batch: 43/211	Loss:0.696
Batch: 64/211	Loss:0.601
Batch: 85/211	Loss:0.669
Batch: 106/211	Loss:0.732
Batch: 127/211	Loss:0.695
Batch: 148/211	Loss:0.605
Batch: 169/211	Loss:0.644
Batch: 190/211	Loss:0.520
Batch: 211/211	Loss:0.506
Epoch: 2	Train Loss: 0.589	Val F1: 0.694
Best Epoch: 2	Best Epoch Val F1: 0.694

******************************Epoch: 3******************************
Batch: 1/211	Loss:0.539
Batch: 22/211	Loss:0.481
Batch: 43/211	Loss:0.490
Batch: 64/211	Loss:0.355
Batch: 85/211	Loss:0.515
Batch: 106/211	Loss:0.539
Batch: 127/211	Loss:0.417
Batch: 148/211	Loss:0.546
Batch: 169/211	Loss:0.534
Batch: 190/211	Loss:0.489
Batch: 211/211	Loss:0.322
Epoch: 3	Train Loss: 0.485	Val F1: 0.736
Best Epoch: 3	Best Epoch Val F1: 0.736

******************************Epoch: 4******************************
Batch: 1/211	Loss:0.327
Batch: 22/211	Loss:0.388
Batch: 43/211	Loss:0.457
Batch: 64/211	Loss:0.372
Batch: 85/211	Loss:0.364
Batch: 106/211	Loss:0.367
Batch: 127/211	Loss:0.344
Batch: 148/211	Loss:0.348
Batch: 169/211	Loss:0.414
Batch: 190/211	Loss:0.469
Batch: 211/211	Loss:0.385
Epoch: 4	Train Loss: 0.421	Val F1: 0.638
Best Epoch: 3	Best Epoch Val F1: 0.736

******************************Epoch: 5******************************
Batch: 1/211	Loss:0.379
Batch: 22/211	Loss:0.376
Batch: 43/211	Loss:0.230
Batch: 64/211	Loss:0.405
Batch: 85/211	Loss:0.444
Batch: 106/211	Loss:0.415
Batch: 127/211	Loss:0.309
Batch: 148/211	Loss:0.369
Batch: 169/211	Loss:0.388
Batch: 190/211	Loss:0.415
Batch: 211/211	Loss:0.439
Epoch: 5	Train Loss: 0.373	Val F1: 0.716
Best Epoch: 3	Best Epoch Val F1: 0.736

******************************Epoch: 6******************************
Batch: 1/211	Loss:0.294
Batch: 22/211	Loss:0.217
Batch: 43/211	Loss:0.376
Batch: 64/211	Loss:0.301
Batch: 85/211	Loss:0.265
Batch: 106/211	Loss:0.510
Batch: 127/211	Loss:0.348
Batch: 148/211	Loss:0.275
Batch: 169/211	Loss:0.319
Batch: 190/211	Loss:0.334
Batch: 211/211	Loss:0.228
Epoch: 6	Train Loss: 0.324	Val F1: 0.718
Best Epoch: 3	Best Epoch Val F1: 0.736

******************************Epoch: 7******************************
Batch: 1/211	Loss:0.301
Batch: 22/211	Loss:0.182
Batch: 43/211	Loss:0.297
Batch: 64/211	Loss:0.273
Batch: 85/211	Loss:0.319
Batch: 106/211	Loss:0.336
Batch: 127/211	Loss:0.338
Batch: 148/211	Loss:0.300
Batch: 169/211	Loss:0.389
Batch: 190/211	Loss:0.274
Batch: 211/211	Loss:0.390
Epoch: 7	Train Loss: 0.288	Val F1: 0.717
Best Epoch: 3	Best Epoch Val F1: 0.736

******************************Epoch: 8******************************
Batch: 1/211	Loss:0.201
Batch: 22/211	Loss:0.208
Batch: 43/211	Loss:0.211
Batch: 64/211	Loss:0.257
Batch: 85/211	Loss:0.316
Batch: 106/211	Loss:0.154
Batch: 127/211	Loss:0.320
Batch: 148/211	Loss:0.201
Batch: 169/211	Loss:0.301
Batch: 190/211	Loss:0.258
Batch: 211/211	Loss:0.352
Epoch: 8	Train Loss: 0.252	Val F1: 0.715
Best Epoch: 3	Best Epoch Val F1: 0.736

******************************Epoch: 9******************************
Batch: 1/211	Loss:0.220
Batch: 22/211	Loss:0.246
Batch: 43/211	Loss:0.213
Batch: 64/211	Loss:0.302
Batch: 85/211	Loss:0.265
Batch: 106/211	Loss:0.168
Batch: 127/211	Loss:0.203
Batch: 148/211	Loss:0.227
Batch: 169/211	Loss:0.111
Batch: 190/211	Loss:0.241
Batch: 211/211	Loss:0.116
Epoch: 9	Train Loss: 0.225	Val F1: 0.706
Best Epoch: 3	Best Epoch Val F1: 0.736

******************************Epoch: 10******************************
Batch: 1/211	Loss:0.133
Batch: 22/211	Loss:0.236
Batch: 43/211	Loss:0.327
Batch: 64/211	Loss:0.090
Batch: 85/211	Loss:0.132
Batch: 106/211	Loss:0.148
Batch: 127/211	Loss:0.256
Batch: 148/211	Loss:0.157
Batch: 169/211	Loss:0.144
Batch: 190/211	Loss:0.176
Batch: 211/211	Loss:0.101
Epoch: 10	Train Loss: 0.201	Val F1: 0.713
Best Epoch: 3	Best Epoch Val F1: 0.736

******************************Epoch: 11******************************
Batch: 1/211	Loss:0.141
Batch: 22/211	Loss:0.295
Batch: 43/211	Loss:0.142
Batch: 64/211	Loss:0.164
Batch: 85/211	Loss:0.158
Batch: 106/211	Loss:0.186
Batch: 127/211	Loss:0.186
Batch: 148/211	Loss:0.083
Batch: 169/211	Loss:0.272
Batch: 190/211	Loss:0.064
Batch: 211/211	Loss:0.153
Epoch: 11	Train Loss: 0.187	Val F1: 0.705
Best Epoch: 3	Best Epoch Val F1: 0.736

******************************Epoch: 12******************************
Batch: 1/211	Loss:0.109
Batch: 22/211	Loss:0.130
Batch: 43/211	Loss:0.117
Batch: 64/211	Loss:0.175
Batch: 85/211	Loss:0.138
Batch: 106/211	Loss:0.166
Batch: 127/211	Loss:0.176
Batch: 148/211	Loss:0.303
Batch: 169/211	Loss:0.227
Batch: 190/211	Loss:0.146
Batch: 211/211	Loss:0.085
Epoch: 12	Train Loss: 0.173	Val F1: 0.715
Best Epoch: 3	Best Epoch Val F1: 0.736

******************************Epoch: 13******************************
Batch: 1/211	Loss:0.170
Batch: 22/211	Loss:0.223
Batch: 43/211	Loss:0.226
Batch: 64/211	Loss:0.116
Batch: 85/211	Loss:0.076
Batch: 106/211	Loss:0.112
Batch: 127/211	Loss:0.192
Batch: 148/211	Loss:0.249
Batch: 169/211	Loss:0.104
Batch: 190/211	Loss:0.118
Batch: 211/211	Loss:0.073
Epoch: 13	Train Loss: 0.155	Val F1: 0.711
Best Epoch: 3	Best Epoch Val F1: 0.736

Saving the best checkpoint....
Inference...
Test F1: 0.747	Test F1_Few: 0.764	Test F1_Zero: 0.728
Starting training with config: {'batch_size': 64, 'epochs': 50, 'l2_reg': 9.896234117049388e-05, 'lr': 3.430545421945512e-05, 'n_layers_freeze': 2, 'patience': 10}
Let's use 1 GPUs!
Preparing data....
Training data....
# of train examples: 13477
max len: 512, max len wiki: 1
Val data....
# of val examples: 2062
max len: 512, max len wiki: 1
Test data....
# of test examples: 3006
max len: 512, max len wiki: 1
Done

Initializing model....
******************************Epoch: 1******************************
Batch: 1/211	Loss:1.300
Batch: 22/211	Loss:1.034
Batch: 43/211	Loss:1.151
Batch: 64/211	Loss:1.010
Batch: 85/211	Loss:1.017
Batch: 106/211	Loss:0.868
Batch: 127/211	Loss:0.696
Batch: 148/211	Loss:0.796
Batch: 169/211	Loss:0.730
Batch: 190/211	Loss:0.643
Batch: 211/211	Loss:0.759
Epoch: 1	Train Loss: 0.881	Val F1: 0.680
Best Epoch: 1	Best Epoch Val F1: 0.680

******************************Epoch: 2******************************
Batch: 1/211	Loss:0.748
Batch: 22/211	Loss:0.657
Batch: 43/211	Loss:0.692
Batch: 64/211	Loss:0.557
Batch: 85/211	Loss:0.601
Batch: 106/211	Loss:0.783
Batch: 127/211	Loss:0.682
Batch: 148/211	Loss:0.619
Batch: 169/211	Loss:0.585
Batch: 190/211	Loss:0.567
Batch: 211/211	Loss:0.445
Epoch: 2	Train Loss: 0.594	Val F1: 0.713
Best Epoch: 2	Best Epoch Val F1: 0.713

******************************Epoch: 3******************************
Batch: 1/211	Loss:0.534
Batch: 22/211	Loss:0.480
Batch: 43/211	Loss:0.518
Batch: 64/211	Loss:0.419
Batch: 85/211	Loss:0.438
Batch: 106/211	Loss:0.519
Batch: 127/211	Loss:0.355
Batch: 148/211	Loss:0.590
Batch: 169/211	Loss:0.517
Batch: 190/211	Loss:0.436
Batch: 211/211	Loss:0.425
Epoch: 3	Train Loss: 0.484	Val F1: 0.726
Best Epoch: 3	Best Epoch Val F1: 0.726

******************************Epoch: 4******************************
Batch: 1/211	Loss:0.329
Batch: 22/211	Loss:0.437
Batch: 43/211	Loss:0.380
Batch: 64/211	Loss:0.399
Batch: 85/211	Loss:0.441
Batch: 106/211	Loss:0.383
Batch: 127/211	Loss:0.335
Batch: 148/211	Loss:0.448
Batch: 169/211	Loss:0.435
Batch: 190/211	Loss:0.427
Batch: 211/211	Loss:0.359
Epoch: 4	Train Loss: 0.419	Val F1: 0.651
Best Epoch: 3	Best Epoch Val F1: 0.726

******************************Epoch: 5******************************
Batch: 1/211	Loss:0.441
Batch: 22/211	Loss:0.416
Batch: 43/211	Loss:0.266
Batch: 64/211	Loss:0.307
Batch: 85/211	Loss:0.468
Batch: 106/211	Loss:0.321
Batch: 127/211	Loss:0.346
Batch: 148/211	Loss:0.393
Batch: 169/211	Loss:0.320
Batch: 190/211	Loss:0.427
Batch: 211/211	Loss:0.394
Epoch: 5	Train Loss: 0.361	Val F1: 0.706
Best Epoch: 3	Best Epoch Val F1: 0.726

******************************Epoch: 6******************************
Batch: 1/211	Loss:0.271
Batch: 22/211	Loss:0.244
Batch: 43/211	Loss:0.310
Batch: 64/211	Loss:0.273
Batch: 85/211	Loss:0.288
Batch: 106/211	Loss:0.513
Batch: 127/211	Loss:0.377
Batch: 148/211	Loss:0.293
Batch: 169/211	Loss:0.340
Batch: 190/211	Loss:0.329
Batch: 211/211	Loss:0.239
Epoch: 6	Train Loss: 0.321	Val F1: 0.708
Best Epoch: 3	Best Epoch Val F1: 0.726

******************************Epoch: 7******************************
Batch: 1/211	Loss:0.348
Batch: 22/211	Loss:0.209
Batch: 43/211	Loss:0.300
Batch: 64/211	Loss:0.336
Batch: 85/211	Loss:0.341
Batch: 106/211	Loss:0.338
Batch: 127/211	Loss:0.346
Batch: 148/211	Loss:0.366
Batch: 169/211	Loss:0.346
Batch: 190/211	Loss:0.402
Batch: 211/211	Loss:0.395
Epoch: 7	Train Loss: 0.282	Val F1: 0.731
Best Epoch: 7	Best Epoch Val F1: 0.731

******************************Epoch: 8******************************
Batch: 1/211	Loss:0.196
Batch: 22/211	Loss:0.239
Batch: 43/211	Loss:0.180
Batch: 64/211	Loss:0.213
Batch: 85/211	Loss:0.279
Batch: 106/211	Loss:0.143
Batch: 127/211	Loss:0.351
Batch: 148/211	Loss:0.479
Batch: 169/211	Loss:0.376
Batch: 190/211	Loss:0.277
Batch: 211/211	Loss:0.435
Epoch: 8	Train Loss: 0.248	Val F1: 0.700
Best Epoch: 7	Best Epoch Val F1: 0.731

******************************Epoch: 9******************************
Batch: 1/211	Loss:0.198
Batch: 22/211	Loss:0.218
Batch: 43/211	Loss:0.214
Batch: 64/211	Loss:0.419
Batch: 85/211	Loss:0.294
Batch: 106/211	Loss:0.201
Batch: 127/211	Loss:0.207
Batch: 148/211	Loss:0.258
Batch: 169/211	Loss:0.145
Batch: 190/211	Loss:0.236
Batch: 211/211	Loss:0.141
Epoch: 9	Train Loss: 0.219	Val F1: 0.713
Best Epoch: 7	Best Epoch Val F1: 0.731

******************************Epoch: 10******************************
Batch: 1/211	Loss:0.148
Batch: 22/211	Loss:0.191
Batch: 43/211	Loss:0.221
Batch: 64/211	Loss:0.091
Batch: 85/211	Loss:0.127
Batch: 106/211	Loss:0.100
Batch: 127/211	Loss:0.271
Batch: 148/211	Loss:0.114
Batch: 169/211	Loss:0.105
Batch: 190/211	Loss:0.222
Batch: 211/211	Loss:0.125
Epoch: 10	Train Loss: 0.195	Val F1: 0.701
Best Epoch: 7	Best Epoch Val F1: 0.731

******************************Epoch: 11******************************
Batch: 1/211	Loss:0.134
Batch: 22/211	Loss:0.148
Batch: 43/211	Loss:0.124
Batch: 64/211	Loss:0.206
Batch: 85/211	Loss:0.140
Batch: 106/211	Loss:0.136
Batch: 127/211	Loss:0.255
Batch: 148/211	Loss:0.097
Batch: 169/211	Loss:0.193
Batch: 190/211	Loss:0.108
Batch: 211/211	Loss:0.153
Epoch: 11	Train Loss: 0.182	Val F1: 0.705
Best Epoch: 7	Best Epoch Val F1: 0.731

******************************Epoch: 12******************************
Batch: 1/211	Loss:0.115
Batch: 22/211	Loss:0.114
Batch: 43/211	Loss:0.143
Batch: 64/211	Loss:0.193
Batch: 85/211	Loss:0.078
Batch: 106/211	Loss:0.116
Batch: 127/211	Loss:0.208
Batch: 148/211	Loss:0.292
Batch: 169/211	Loss:0.154
Batch: 190/211	Loss:0.186
Batch: 211/211	Loss:0.106
Epoch: 12	Train Loss: 0.164	Val F1: 0.710
Best Epoch: 7	Best Epoch Val F1: 0.731

******************************Epoch: 13******************************
Batch: 1/211	Loss:0.165
Batch: 22/211	Loss:0.211
Batch: 43/211	Loss:0.095
Batch: 64/211	Loss:0.092
Batch: 85/211	Loss:0.157
Batch: 106/211	Loss:0.146
Batch: 127/211	Loss:0.143
Batch: 148/211	Loss:0.178
Batch: 169/211	Loss:0.151
Batch: 190/211	Loss:0.107
Batch: 211/211	Loss:0.244
Epoch: 13	Train Loss: 0.152	Val F1: 0.704
Best Epoch: 7	Best Epoch Val F1: 0.731

******************************Epoch: 14******************************
Batch: 1/211	Loss:0.111
Batch: 22/211	Loss:0.176
Batch: 43/211	Loss:0.055
Batch: 64/211	Loss:0.186
Batch: 85/211	Loss:0.090
Batch: 106/211	Loss:0.066
Batch: 127/211	Loss:0.083
Batch: 148/211	Loss:0.095
Batch: 169/211	Loss:0.185
Batch: 190/211	Loss:0.217
Batch: 211/211	Loss:0.167
Epoch: 14	Train Loss: 0.144	Val F1: 0.700
Best Epoch: 7	Best Epoch Val F1: 0.731

******************************Epoch: 15******************************
Batch: 1/211	Loss:0.122
Batch: 22/211	Loss:0.043
Batch: 43/211	Loss:0.062
Batch: 64/211	Loss:0.168
Batch: 85/211	Loss:0.100
Batch: 106/211	Loss:0.064
Batch: 127/211	Loss:0.202
Batch: 148/211	Loss:0.230
Batch: 169/211	Loss:0.094
Batch: 190/211	Loss:0.167
Batch: 211/211	Loss:0.179
Epoch: 15	Train Loss: 0.140	Val F1: 0.701
Best Epoch: 7	Best Epoch Val F1: 0.731

******************************Epoch: 16******************************
Batch: 1/211	Loss:0.116
Batch: 22/211	Loss:0.222
Batch: 43/211	Loss:0.066
Batch: 64/211	Loss:0.052
Batch: 85/211	Loss:0.147
Batch: 106/211	Loss:0.068
Batch: 127/211	Loss:0.114
Batch: 148/211	Loss:0.143
Batch: 169/211	Loss:0.099
Batch: 190/211	Loss:0.158
Batch: 211/211	Loss:0.205
Epoch: 16	Train Loss: 0.135	Val F1: 0.693
Best Epoch: 7	Best Epoch Val F1: 0.731

******************************Epoch: 17******************************
Batch: 1/211	Loss:0.040
Batch: 22/211	Loss:0.150
Batch: 43/211	Loss:0.139
Batch: 64/211	Loss:0.079
Batch: 85/211	Loss:0.071
Batch: 106/211	Loss:0.096
Batch: 127/211	Loss:0.211
Batch: 148/211	Loss:0.064
Batch: 169/211	Loss:0.155
Batch: 190/211	Loss:0.203
Batch: 211/211	Loss:0.051
Epoch: 17	Train Loss: 0.124	Val F1: 0.701
Best Epoch: 7	Best Epoch Val F1: 0.731

Saving the best checkpoint....
Inference...
Test F1: 0.738	Test F1_Few: 0.752	Test F1_Zero: 0.723
Starting training with config: {'batch_size': 32, 'epochs': 75, 'l2_reg': 3.12909630679384e-05, 'lr': 7.855904738630978e-06, 'n_layers_freeze': 1, 'patience': 5}
Let's use 1 GPUs!
Preparing data....
Training data....
# of train examples: 13477
max len: 512, max len wiki: 1
Val data....
# of val examples: 2062
max len: 512, max len wiki: 1
Test data....
# of test examples: 3006
max len: 512, max len wiki: 1
Done

Initializing model....
******************************Epoch: 1******************************
Batch: 1/422	Loss:1.244
Batch: 43/422	Loss:1.095
Batch: 85/422	Loss:1.133
Batch: 127/422	Loss:1.067
Batch: 169/422	Loss:1.100
Batch: 211/422	Loss:1.038
Batch: 253/422	Loss:1.109
Batch: 295/422	Loss:1.052
Batch: 337/422	Loss:1.054
Batch: 379/422	Loss:0.884
Batch: 421/422	Loss:0.937
Batch: 422/422	Loss:0.937
Epoch: 1	Train Loss: 1.019	Val F1: 0.623
Best Epoch: 1	Best Epoch Val F1: 0.623

******************************Epoch: 2******************************
Batch: 1/422	Loss:0.883
Batch: 43/422	Loss:0.825
Batch: 85/422	Loss:0.707
Batch: 127/422	Loss:0.687
Batch: 169/422	Loss:0.667
Batch: 211/422	Loss:0.766
Batch: 253/422	Loss:0.710
Batch: 295/422	Loss:0.705
Batch: 337/422	Loss:0.750
Batch: 379/422	Loss:0.613
Batch: 421/422	Loss:0.517
Batch: 422/422	Loss:0.530
Epoch: 2	Train Loss: 0.689	Val F1: 0.699
Best Epoch: 2	Best Epoch Val F1: 0.699

******************************Epoch: 3******************************
Batch: 1/422	Loss:0.674
Batch: 43/422	Loss:0.596
Batch: 85/422	Loss:0.652
Batch: 127/422	Loss:0.546
Batch: 169/422	Loss:0.544
Batch: 211/422	Loss:0.643
Batch: 253/422	Loss:0.485
Batch: 295/422	Loss:0.666
Batch: 337/422	Loss:0.481
Batch: 379/422	Loss:0.610
Batch: 421/422	Loss:0.453
Batch: 422/422	Loss:0.835
Epoch: 3	Train Loss: 0.585	Val F1: 0.710
Best Epoch: 3	Best Epoch Val F1: 0.710

******************************Epoch: 4******************************
Batch: 1/422	Loss:0.500
Batch: 43/422	Loss:0.686
Batch: 85/422	Loss:0.575
Batch: 127/422	Loss:0.534
Batch: 169/422	Loss:0.578
Batch: 211/422	Loss:0.466
Batch: 253/422	Loss:0.520
Batch: 295/422	Loss:0.427
Batch: 337/422	Loss:0.733
Batch: 379/422	Loss:0.597
Batch: 421/422	Loss:0.386
Batch: 422/422	Loss:1.413
Epoch: 4	Train Loss: 0.517	Val F1: 0.691
Best Epoch: 3	Best Epoch Val F1: 0.710

******************************Epoch: 5******************************
Batch: 1/422	Loss:0.537
Batch: 43/422	Loss:0.385
Batch: 85/422	Loss:0.335
Batch: 127/422	Loss:0.454
Batch: 169/422	Loss:0.473
Batch: 211/422	Loss:0.430
Batch: 253/422	Loss:0.436
Batch: 295/422	Loss:0.296
Batch: 337/422	Loss:0.448
Batch: 379/422	Loss:0.429
Batch: 421/422	Loss:0.433
Batch: 422/422	Loss:0.431
Epoch: 5	Train Loss: 0.460	Val F1: 0.689
Best Epoch: 3	Best Epoch Val F1: 0.710

******************************Epoch: 6******************************
Batch: 1/422	Loss:0.260
Batch: 43/422	Loss:0.432
Batch: 85/422	Loss:0.574
Batch: 127/422	Loss:0.397
Batch: 169/422	Loss:0.464
Batch: 211/422	Loss:0.424
Batch: 253/422	Loss:0.403
Batch: 295/422	Loss:0.340
Batch: 337/422	Loss:0.503
Batch: 379/422	Loss:0.537
Batch: 421/422	Loss:0.333
Batch: 422/422	Loss:0.078
Epoch: 6	Train Loss: 0.417	Val F1: 0.705
Best Epoch: 3	Best Epoch Val F1: 0.710

******************************Epoch: 7******************************
Batch: 1/422	Loss:0.448
Batch: 43/422	Loss:0.302
Batch: 85/422	Loss:0.377
Batch: 127/422	Loss:0.330
Batch: 169/422	Loss:0.722
Batch: 211/422	Loss:0.468
Batch: 253/422	Loss:0.464
Batch: 295/422	Loss:0.390
Batch: 337/422	Loss:0.621
Batch: 379/422	Loss:0.540
Batch: 421/422	Loss:0.471
Batch: 422/422	Loss:0.145
Epoch: 7	Train Loss: 0.384	Val F1: 0.705
Best Epoch: 3	Best Epoch Val F1: 0.710

******************************Epoch: 8******************************
Batch: 1/422	Loss:0.353
Batch: 43/422	Loss:0.287
Batch: 85/422	Loss:0.259
Batch: 127/422	Loss:0.371
Batch: 169/422	Loss:0.424
Batch: 211/422	Loss:0.332
Batch: 253/422	Loss:0.468
Batch: 295/422	Loss:0.331
Batch: 337/422	Loss:0.264
Batch: 379/422	Loss:0.229
Batch: 421/422	Loss:0.462
Batch: 422/422	Loss:0.162
Epoch: 8	Train Loss: 0.350	Val F1: 0.685
Best Epoch: 3	Best Epoch Val F1: 0.710

Saving the best checkpoint....
Inference...
Test F1: 0.756	Test F1_Few: 0.763	Test F1_Zero: 0.748
Starting training with config: {'batch_size': 8, 'epochs': 75, 'l2_reg': 1.3875163102073824e-05, 'lr': 3.3745076156447505e-05, 'n_layers_freeze': 4, 'patience': 10}
Let's use 1 GPUs!
Preparing data....
Training data....
# of train examples: 13477
max len: 512, max len wiki: 1
Val data....
# of val examples: 2062
max len: 512, max len wiki: 1
Test data....
# of test examples: 3006
max len: 512, max len wiki: 1
Done

Initializing model....
******************************Epoch: 1******************************
Batch: 1/1685	Loss:1.082
Batch: 169/1685	Loss:1.100
Batch: 337/1685	Loss:1.133
Batch: 505/1685	Loss:1.058
Batch: 673/1685	Loss:0.448
Batch: 841/1685	Loss:0.527
Batch: 1009/1685	Loss:0.419
Batch: 1177/1685	Loss:0.493
Batch: 1345/1685	Loss:0.996
Batch: 1513/1685	Loss:0.861
Batch: 1681/1685	Loss:0.866
Batch: 1685/1685	Loss:0.863
Epoch: 1	Train Loss: 0.764	Val F1: 0.661
Best Epoch: 1	Best Epoch Val F1: 0.661

******************************Epoch: 2******************************
Batch: 1/1685	Loss:0.387
Batch: 169/1685	Loss:1.155
Batch: 337/1685	Loss:0.807
Batch: 505/1685	Loss:0.415
Batch: 673/1685	Loss:0.428
Batch: 841/1685	Loss:0.924
Batch: 1009/1685	Loss:0.447
Batch: 1177/1685	Loss:0.378
Batch: 1345/1685	Loss:0.492
Batch: 1513/1685	Loss:0.790
Batch: 1681/1685	Loss:0.173
Batch: 1685/1685	Loss:0.356
Epoch: 2	Train Loss: 0.586	Val F1: 0.712
Best Epoch: 2	Best Epoch Val F1: 0.712

******************************Epoch: 3******************************
Batch: 1/1685	Loss:0.248
Batch: 169/1685	Loss:0.591
Batch: 337/1685	Loss:0.292
Batch: 505/1685	Loss:0.179
Batch: 673/1685	Loss:0.623
Batch: 841/1685	Loss:1.354
Batch: 1009/1685	Loss:0.533
Batch: 1177/1685	Loss:0.564
Batch: 1345/1685	Loss:0.172
Batch: 1513/1685	Loss:0.542
Batch: 1681/1685	Loss:0.332
Batch: 1685/1685	Loss:0.318
Epoch: 3	Train Loss: 0.504	Val F1: 0.707
Best Epoch: 2	Best Epoch Val F1: 0.712

******************************Epoch: 4******************************
Batch: 1/1685	Loss:0.243
Batch: 169/1685	Loss:0.605
Batch: 337/1685	Loss:0.568
Batch: 505/1685	Loss:0.657
Batch: 673/1685	Loss:0.471
Batch: 841/1685	Loss:0.450
Batch: 1009/1685	Loss:0.611
Batch: 1177/1685	Loss:0.402
Batch: 1345/1685	Loss:0.391
Batch: 1513/1685	Loss:0.249
Batch: 1681/1685	Loss:0.300
Batch: 1685/1685	Loss:1.494
Epoch: 4	Train Loss: 0.447	Val F1: 0.692
Best Epoch: 2	Best Epoch Val F1: 0.712

******************************Epoch: 5******************************
Batch: 1/1685	Loss:0.761
Batch: 169/1685	Loss:0.389
Batch: 337/1685	Loss:0.457
Batch: 505/1685	Loss:0.133
Batch: 673/1685	Loss:1.008
Batch: 841/1685	Loss:0.412
Batch: 1009/1685	Loss:0.406
Batch: 1177/1685	Loss:0.515
Batch: 1345/1685	Loss:0.675
Batch: 1513/1685	Loss:0.281
Batch: 1681/1685	Loss:0.393
Batch: 1685/1685	Loss:0.600
Epoch: 5	Train Loss: 0.396	Val F1: 0.692
Best Epoch: 2	Best Epoch Val F1: 0.712

******************************Epoch: 6******************************
Batch: 1/1685	Loss:0.139
Batch: 169/1685	Loss:0.069
Batch: 337/1685	Loss:0.081
Batch: 505/1685	Loss:0.359
Batch: 673/1685	Loss:0.172
Batch: 841/1685	Loss:0.607
Batch: 1009/1685	Loss:0.320
Batch: 1177/1685	Loss:0.291
Batch: 1345/1685	Loss:0.498
Batch: 1513/1685	Loss:0.216
Batch: 1681/1685	Loss:0.292
Batch: 1685/1685	Loss:0.021
Epoch: 6	Train Loss: 0.364	Val F1: 0.720
Best Epoch: 6	Best Epoch Val F1: 0.720

******************************Epoch: 7******************************
Batch: 1/1685	Loss:0.410
Batch: 169/1685	Loss:0.122
Batch: 337/1685	Loss:0.417
Batch: 505/1685	Loss:0.137
Batch: 673/1685	Loss:0.379
Batch: 841/1685	Loss:0.300
Batch: 1009/1685	Loss:0.160
Batch: 1177/1685	Loss:0.264
Batch: 1345/1685	Loss:0.314
Batch: 1513/1685	Loss:0.573
Batch: 1681/1685	Loss:0.179
Batch: 1685/1685	Loss:0.224
Epoch: 7	Train Loss: 0.328	Val F1: 0.688
Best Epoch: 6	Best Epoch Val F1: 0.720

******************************Epoch: 8******************************
Batch: 1/1685	Loss:0.201
Batch: 169/1685	Loss:0.670
Batch: 337/1685	Loss:0.011
Batch: 505/1685	Loss:0.523
Batch: 673/1685	Loss:0.422
Batch: 841/1685	Loss:0.341
Batch: 1009/1685	Loss:0.579
Batch: 1177/1685	Loss:0.514
Batch: 1345/1685	Loss:0.078
Batch: 1513/1685	Loss:0.316
Batch: 1681/1685	Loss:0.163
Batch: 1685/1685	Loss:0.374
Epoch: 8	Train Loss: 0.296	Val F1: 0.659
Best Epoch: 6	Best Epoch Val F1: 0.720

******************************Epoch: 9******************************
Batch: 1/1685	Loss:0.379
Batch: 169/1685	Loss:0.305
Batch: 337/1685	Loss:0.838
Batch: 505/1685	Loss:0.760
Batch: 673/1685	Loss:0.201
Batch: 841/1685	Loss:0.840
Batch: 1009/1685	Loss:0.422
Batch: 1177/1685	Loss:0.229
Batch: 1345/1685	Loss:0.699
Batch: 1513/1685	Loss:0.451
Batch: 1681/1685	Loss:0.295
Batch: 1685/1685	Loss:0.725
Epoch: 9	Train Loss: 0.275	Val F1: 0.695
Best Epoch: 6	Best Epoch Val F1: 0.720

******************************Epoch: 10******************************
Batch: 1/1685	Loss:0.292
Batch: 169/1685	Loss:0.277
Batch: 337/1685	Loss:0.392
Batch: 505/1685	Loss:0.013
Batch: 673/1685	Loss:0.152
Batch: 841/1685	Loss:0.227
Batch: 1009/1685	Loss:0.303
Batch: 1177/1685	Loss:0.100
Batch: 1345/1685	Loss:0.097
Batch: 1513/1685	Loss:0.173
Batch: 1681/1685	Loss:0.014
Batch: 1685/1685	Loss:0.165
Epoch: 10	Train Loss: 0.250	Val F1: 0.694
Best Epoch: 6	Best Epoch Val F1: 0.720

******************************Epoch: 11******************************
Batch: 1/1685	Loss:0.200
Batch: 169/1685	Loss:0.445
Batch: 337/1685	Loss:0.279
Batch: 505/1685	Loss:0.098
Batch: 673/1685	Loss:0.074
Batch: 841/1685	Loss:0.357
Batch: 1009/1685	Loss:0.667
Batch: 1177/1685	Loss:0.121
Batch: 1345/1685	Loss:0.628
Batch: 1513/1685	Loss:0.068
Batch: 1681/1685	Loss:0.228
Batch: 1685/1685	Loss:0.017
Epoch: 11	Train Loss: 0.231	Val F1: 0.695
Best Epoch: 6	Best Epoch Val F1: 0.720

******************************Epoch: 12******************************
Batch: 1/1685	Loss:0.278
Batch: 169/1685	Loss:0.043
Batch: 337/1685	Loss:0.247
Batch: 505/1685	Loss:0.508
Batch: 673/1685	Loss:0.038
Batch: 841/1685	Loss:0.365
Batch: 1009/1685	Loss:0.422
Batch: 1177/1685	Loss:0.238
Batch: 1345/1685	Loss:0.047
Batch: 1513/1685	Loss:0.091
Batch: 1681/1685	Loss:0.534
Batch: 1685/1685	Loss:0.001
Epoch: 12	Train Loss: 0.218	Val F1: 0.703
Best Epoch: 6	Best Epoch Val F1: 0.720

******************************Epoch: 13******************************
Batch: 1/1685	Loss:0.120
Batch: 169/1685	Loss:0.033
Batch: 337/1685	Loss:0.437
Batch: 505/1685	Loss:0.137
Batch: 673/1685	Loss:0.108
Batch: 841/1685	Loss:0.034
Batch: 1009/1685	Loss:0.276
Batch: 1177/1685	Loss:0.194
Batch: 1345/1685	Loss:0.159
Batch: 1513/1685	Loss:0.174
Batch: 1681/1685	Loss:0.175
Batch: 1685/1685	Loss:0.059
Epoch: 13	Train Loss: 0.205	Val F1: 0.709
Best Epoch: 6	Best Epoch Val F1: 0.720

******************************Epoch: 14******************************
Batch: 1/1685	Loss:0.403
Batch: 169/1685	Loss:0.035
Batch: 337/1685	Loss:0.017
Batch: 505/1685	Loss:0.126
Batch: 673/1685	Loss:0.233
Batch: 841/1685	Loss:0.417
Batch: 1009/1685	Loss:0.141
Batch: 1177/1685	Loss:0.097
Batch: 1345/1685	Loss:0.295
Batch: 1513/1685	Loss:0.001
Batch: 1681/1685	Loss:0.246
Batch: 1685/1685	Loss:0.091
Epoch: 14	Train Loss: 0.189	Val F1: 0.683
Best Epoch: 6	Best Epoch Val F1: 0.720

******************************Epoch: 15******************************
Batch: 1/1685	Loss:0.082
Batch: 169/1685	Loss:0.010
Batch: 337/1685	Loss:0.154
Batch: 505/1685	Loss:0.255
Batch: 673/1685	Loss:0.124
Batch: 841/1685	Loss:0.004
Batch: 1009/1685	Loss:0.177
Batch: 1177/1685	Loss:0.069
Batch: 1345/1685	Loss:0.136
Batch: 1513/1685	Loss:0.157
Batch: 1681/1685	Loss:0.103
Batch: 1685/1685	Loss:0.001
Epoch: 15	Train Loss: 0.180	Val F1: 0.660
Best Epoch: 6	Best Epoch Val F1: 0.720

******************************Epoch: 16******************************
Batch: 1/1685	Loss:0.114
Batch: 169/1685	Loss:0.109
Batch: 337/1685	Loss:0.243
Batch: 505/1685	Loss:0.537
Batch: 673/1685	Loss:0.347
Batch: 841/1685	Loss:0.237
Batch: 1009/1685	Loss:0.208
Batch: 1177/1685	Loss:0.008
Batch: 1345/1685	Loss:0.039
Batch: 1513/1685	Loss:0.155
Batch: 1681/1685	Loss:0.068
Batch: 1685/1685	Loss:0.151
Epoch: 16	Train Loss: 0.172	Val F1: 0.673
Best Epoch: 6	Best Epoch Val F1: 0.720

Saving the best checkpoint....
Inference...
Test F1: 0.728	Test F1_Few: 0.750	Test F1_Zero: 0.705
Starting training with config: {'batch_size': 4, 'epochs': 75, 'l2_reg': 6.94114686869385e-05, 'lr': 1.616917069832221e-05, 'n_layers_freeze': 0, 'patience': 10}
Let's use 1 GPUs!
Preparing data....
Training data....
# of train examples: 13477
max len: 512, max len wiki: 1
Val data....
# of val examples: 2062
max len: 512, max len wiki: 1
Test data....
# of test examples: 3006
max len: 512, max len wiki: 1
Done

Initializing model....
******************************Epoch: 1******************************
Batch: 1/3370	Loss:1.322
Batch: 338/3370	Loss:1.301
Batch: 675/3370	Loss:0.703
Batch: 1012/3370	Loss:0.634
Batch: 1349/3370	Loss:0.721
Batch: 1686/3370	Loss:1.722
Batch: 2023/3370	Loss:0.188
Batch: 2360/3370	Loss:1.430
Batch: 2697/3370	Loss:0.723
Batch: 3034/3370	Loss:0.533
Batch: 3370/3370	Loss:1.524
Epoch: 1	Train Loss: 0.745	Val F1: 0.688
Best Epoch: 1	Best Epoch Val F1: 0.688

******************************Epoch: 2******************************
Batch: 1/3370	Loss:0.574
Batch: 338/3370	Loss:1.079
Batch: 675/3370	Loss:0.403
Batch: 1012/3370	Loss:0.556
Batch: 1349/3370	Loss:0.407
Batch: 1686/3370	Loss:0.293
Batch: 2023/3370	Loss:0.426
Batch: 2360/3370	Loss:0.550
Batch: 2697/3370	Loss:0.761
Batch: 3034/3370	Loss:0.365
Batch: 3370/3370	Loss:0.013
Epoch: 2	Train Loss: 0.565	Val F1: 0.700
Best Epoch: 2	Best Epoch Val F1: 0.700

******************************Epoch: 3******************************
Batch: 1/3370	Loss:0.104
Batch: 338/3370	Loss:0.871
Batch: 675/3370	Loss:0.589
Batch: 1012/3370	Loss:0.494
Batch: 1349/3370	Loss:0.395
Batch: 1686/3370	Loss:1.011
Batch: 2023/3370	Loss:0.341
Batch: 2360/3370	Loss:0.507
Batch: 2697/3370	Loss:0.080
Batch: 3034/3370	Loss:0.157
Batch: 3370/3370	Loss:0.184
Epoch: 3	Train Loss: 0.470	Val F1: 0.716
Best Epoch: 3	Best Epoch Val F1: 0.716

******************************Epoch: 4******************************
Batch: 1/3370	Loss:0.095
Batch: 338/3370	Loss:0.151
Batch: 675/3370	Loss:0.204
Batch: 1012/3370	Loss:0.498
Batch: 1349/3370	Loss:0.223
Batch: 1686/3370	Loss:0.268
Batch: 2023/3370	Loss:0.599
Batch: 2360/3370	Loss:0.346
Batch: 2697/3370	Loss:0.638
Batch: 3034/3370	Loss:0.762
Batch: 3370/3370	Loss:0.006
Epoch: 4	Train Loss: 0.401	Val F1: 0.692
Best Epoch: 3	Best Epoch Val F1: 0.716

******************************Epoch: 5******************************
Batch: 1/3370	Loss:0.492
Batch: 338/3370	Loss:0.467
Batch: 675/3370	Loss:0.122
Batch: 1012/3370	Loss:0.287
Batch: 1349/3370	Loss:0.019
Batch: 1686/3370	Loss:0.093
Batch: 2023/3370	Loss:0.060
Batch: 2360/3370	Loss:0.057
Batch: 2697/3370	Loss:0.707
Batch: 3034/3370	Loss:0.433
Batch: 3370/3370	Loss:0.910
Epoch: 5	Train Loss: 0.348	Val F1: 0.704
Best Epoch: 3	Best Epoch Val F1: 0.716

******************************Epoch: 6******************************
Batch: 1/3370	Loss:0.064
Batch: 338/3370	Loss:0.015
Batch: 675/3370	Loss:0.190
Batch: 1012/3370	Loss:0.120
Batch: 1349/3370	Loss:0.086
Batch: 1686/3370	Loss:0.633
Batch: 2023/3370	Loss:0.037
Batch: 2360/3370	Loss:0.319
Batch: 2697/3370	Loss:0.035
Batch: 3034/3370	Loss:1.318
Batch: 3370/3370	Loss:0.002
Epoch: 6	Train Loss: 0.302	Val F1: 0.700
Best Epoch: 3	Best Epoch Val F1: 0.716

******************************Epoch: 7******************************
Batch: 1/3370	Loss:0.156
Batch: 338/3370	Loss:0.257
Batch: 675/3370	Loss:0.401
Batch: 1012/3370	Loss:0.003
Batch: 1349/3370	Loss:0.040
Batch: 1686/3370	Loss:0.805
Batch: 2023/3370	Loss:0.385
Batch: 2360/3370	Loss:1.340
Batch: 2697/3370	Loss:0.433
Batch: 3034/3370	Loss:0.169
Batch: 3370/3370	Loss:0.001
Epoch: 7	Train Loss: 0.265	Val F1: 0.683
Best Epoch: 3	Best Epoch Val F1: 0.716

******************************Epoch: 8******************************
Batch: 1/3370	Loss:1.196
Batch: 338/3370	Loss:0.843
Batch: 675/3370	Loss:0.004
Batch: 1012/3370	Loss:0.040
Batch: 1349/3370	Loss:0.029
Batch: 1686/3370	Loss:0.221
Batch: 2023/3370	Loss:0.345
Batch: 2360/3370	Loss:1.022
Batch: 2697/3370	Loss:0.010
Batch: 3034/3370	Loss:0.102
Batch: 3370/3370	Loss:0.029
Epoch: 8	Train Loss: 0.237	Val F1: 0.681
Best Epoch: 3	Best Epoch Val F1: 0.716

******************************Epoch: 9******************************
Batch: 1/3370	Loss:0.533
Batch: 338/3370	Loss:0.858
Batch: 675/3370	Loss:1.277
Batch: 1012/3370	Loss:0.166
Batch: 1349/3370	Loss:0.227
Batch: 1686/3370	Loss:0.763
Batch: 2023/3370	Loss:0.103
Batch: 2360/3370	Loss:0.117
Batch: 2697/3370	Loss:0.122
Batch: 3034/3370	Loss:0.105
Batch: 3370/3370	Loss:0.051
Epoch: 9	Train Loss: 0.207	Val F1: 0.691
Best Epoch: 3	Best Epoch Val F1: 0.716

******************************Epoch: 10******************************
Batch: 1/3370	Loss:0.172
Batch: 338/3370	Loss:0.287
Batch: 675/3370	Loss:0.319
Batch: 1012/3370	Loss:0.125
Batch: 1349/3370	Loss:0.006
Batch: 1686/3370	Loss:0.163
Batch: 2023/3370	Loss:0.013
Batch: 2360/3370	Loss:0.002
Batch: 2697/3370	Loss:0.379
Batch: 3034/3370	Loss:0.285
Batch: 3370/3370	Loss:0.000
Epoch: 10	Train Loss: 0.185	Val F1: 0.700
Best Epoch: 3	Best Epoch Val F1: 0.716

******************************Epoch: 11******************************
Batch: 1/3370	Loss:0.085
Batch: 338/3370	Loss:0.037
Batch: 675/3370	Loss:0.004
Batch: 1012/3370	Loss:0.021
Batch: 1349/3370	Loss:0.090
Batch: 1686/3370	Loss:0.131
Batch: 2023/3370	Loss:0.510
Batch: 2360/3370	Loss:0.005
Batch: 2697/3370	Loss:0.197
Batch: 3034/3370	Loss:0.350
Batch: 3370/3370	Loss:0.000
Epoch: 11	Train Loss: 0.175	Val F1: 0.694
Best Epoch: 3	Best Epoch Val F1: 0.716

******************************Epoch: 12******************************
Batch: 1/3370	Loss:0.357
Batch: 338/3370	Loss:0.007
Batch: 675/3370	Loss:0.082
Batch: 1012/3370	Loss:0.001
Batch: 1349/3370	Loss:0.026
Batch: 1686/3370	Loss:0.014
Batch: 2023/3370	Loss:0.005
Batch: 2360/3370	Loss:0.000
Batch: 2697/3370	Loss:0.015
Batch: 3034/3370	Loss:0.690
Batch: 3370/3370	Loss:0.001
Epoch: 12	Train Loss: 0.164	Val F1: 0.701
Best Epoch: 3	Best Epoch Val F1: 0.716

******************************Epoch: 13******************************
Batch: 1/3370	Loss:0.047
Batch: 338/3370	Loss:0.004
Batch: 675/3370	Loss:0.076
Batch: 1012/3370	Loss:0.020
Batch: 1349/3370	Loss:0.068
Batch: 1686/3370	Loss:0.526
Batch: 2023/3370	Loss:0.015
Batch: 2360/3370	Loss:0.001
Batch: 2697/3370	Loss:0.089
Batch: 3034/3370	Loss:0.002
Batch: 3370/3370	Loss:0.294
Epoch: 13	Train Loss: 0.152	Val F1: 0.700
Best Epoch: 3	Best Epoch Val F1: 0.716

Saving the best checkpoint....
Inference...
Test F1: 0.732	Test F1_Few: 0.738	Test F1_Zero: 0.725
Starting training with config: {'batch_size': 32, 'epochs': 25, 'l2_reg': 4.0920071924920766e-05, 'lr': 1.949423496750361e-05, 'n_layers_freeze': 2, 'patience': 5}
Let's use 1 GPUs!
Preparing data....
Training data....
# of train examples: 13477
max len: 512, max len wiki: 1
Val data....
# of val examples: 2062
max len: 512, max len wiki: 1
Test data....
# of test examples: 3006
max len: 512, max len wiki: 1
Done

Initializing model....
******************************Epoch: 1******************************
Batch: 1/422	Loss:1.244
Batch: 43/422	Loss:1.100
Batch: 85/422	Loss:1.125
Batch: 127/422	Loss:1.026
Batch: 169/422	Loss:1.087
Batch: 211/422	Loss:1.021
Batch: 253/422	Loss:1.028
Batch: 295/422	Loss:0.948
Batch: 337/422	Loss:0.759
Batch: 379/422	Loss:0.545
Batch: 421/422	Loss:0.775
Batch: 422/422	Loss:0.694
Epoch: 1	Train Loss: 0.942	Val F1: 0.688
Best Epoch: 1	Best Epoch Val F1: 0.688

******************************Epoch: 2******************************
Batch: 1/422	Loss:0.669
Batch: 43/422	Loss:0.718
Batch: 85/422	Loss:0.689
Batch: 127/422	Loss:0.672
Batch: 169/422	Loss:0.634
Batch: 211/422	Loss:0.716
Batch: 253/422	Loss:0.626
Batch: 295/422	Loss:0.741
Batch: 337/422	Loss:0.737
Batch: 379/422	Loss:0.566
Batch: 421/422	Loss:0.448
Batch: 422/422	Loss:0.440
Epoch: 2	Train Loss: 0.607	Val F1: 0.696
Best Epoch: 2	Best Epoch Val F1: 0.696

******************************Epoch: 3******************************
Batch: 1/422	Loss:0.587
Batch: 43/422	Loss:0.522
Batch: 85/422	Loss:0.593
Batch: 127/422	Loss:0.570
Batch: 169/422	Loss:0.374
Batch: 211/422	Loss:0.835
Batch: 253/422	Loss:0.458
Batch: 295/422	Loss:0.665
Batch: 337/422	Loss:0.389
Batch: 379/422	Loss:0.551
Batch: 421/422	Loss:0.352
Batch: 422/422	Loss:0.529
Epoch: 3	Train Loss: 0.502	Val F1: 0.723
Best Epoch: 3	Best Epoch Val F1: 0.723

******************************Epoch: 4******************************
Batch: 1/422	Loss:0.379
Batch: 43/422	Loss:0.451
Batch: 85/422	Loss:0.485
Batch: 127/422	Loss:0.484
Batch: 169/422	Loss:0.559
Batch: 211/422	Loss:0.467
Batch: 253/422	Loss:0.430
Batch: 295/422	Loss:0.312
Batch: 337/422	Loss:0.565
Batch: 379/422	Loss:0.437
Batch: 421/422	Loss:0.387
Batch: 422/422	Loss:0.705
Epoch: 4	Train Loss: 0.427	Val F1: 0.676
Best Epoch: 3	Best Epoch Val F1: 0.723

******************************Epoch: 5******************************
Batch: 1/422	Loss:0.390
Batch: 43/422	Loss:0.356
Batch: 85/422	Loss:0.279
Batch: 127/422	Loss:0.325
Batch: 169/422	Loss:0.472
Batch: 211/422	Loss:0.391
Batch: 253/422	Loss:0.341
Batch: 295/422	Loss:0.359
Batch: 337/422	Loss:0.343
Batch: 379/422	Loss:0.290
Batch: 421/422	Loss:0.350
Batch: 422/422	Loss:0.392
Epoch: 5	Train Loss: 0.380	Val F1: 0.674
Best Epoch: 3	Best Epoch Val F1: 0.723

******************************Epoch: 6******************************
Batch: 1/422	Loss:0.277
Batch: 43/422	Loss:0.218
Batch: 85/422	Loss:0.499
Batch: 127/422	Loss:0.280
Batch: 169/422	Loss:0.370
Batch: 211/422	Loss:0.508
Batch: 253/422	Loss:0.212
Batch: 295/422	Loss:0.292
Batch: 337/422	Loss:0.363
Batch: 379/422	Loss:0.409
Batch: 421/422	Loss:0.286
Batch: 422/422	Loss:0.065
Epoch: 6	Train Loss: 0.336	Val F1: 0.712
Best Epoch: 3	Best Epoch Val F1: 0.723

******************************Epoch: 7******************************
Batch: 1/422	Loss:0.311
Batch: 43/422	Loss:0.220
Batch: 85/422	Loss:0.235
Batch: 127/422	Loss:0.160
Batch: 169/422	Loss:0.779
Batch: 211/422	Loss:0.498
Batch: 253/422	Loss:0.423
Batch: 295/422	Loss:0.246
Batch: 337/422	Loss:0.525
Batch: 379/422	Loss:0.414
Batch: 421/422	Loss:0.363
Batch: 422/422	Loss:0.245
Epoch: 7	Train Loss: 0.299	Val F1: 0.710
Best Epoch: 3	Best Epoch Val F1: 0.723

******************************Epoch: 8******************************
Batch: 1/422	Loss:0.205
Batch: 43/422	Loss:0.325
Batch: 85/422	Loss:0.144
Batch: 127/422	Loss:0.218
Batch: 169/422	Loss:0.204
Batch: 211/422	Loss:0.295
Batch: 253/422	Loss:0.403
Batch: 295/422	Loss:0.235
Batch: 337/422	Loss:0.240
Batch: 379/422	Loss:0.162
Batch: 421/422	Loss:0.335
Batch: 422/422	Loss:0.087
Epoch: 8	Train Loss: 0.269	Val F1: 0.678
Best Epoch: 3	Best Epoch Val F1: 0.723

Saving the best checkpoint....
Inference...
Test F1: 0.743	Test F1_Few: 0.757	Test F1_Zero: 0.729
Starting training with config: {'batch_size': 4, 'epochs': 75, 'l2_reg': 7.418786370091111e-05, 'lr': 7.737933999024603e-06, 'n_layers_freeze': 1, 'patience': 15}
Let's use 1 GPUs!
Preparing data....
Training data....
# of train examples: 13477
max len: 512, max len wiki: 1
Val data....
# of val examples: 2062
max len: 512, max len wiki: 1
Test data....
# of test examples: 3006
max len: 512, max len wiki: 1
Done

Initializing model....
******************************Epoch: 1******************************
Batch: 1/3370	Loss:1.322
Batch: 338/3370	Loss:1.205
Batch: 675/3370	Loss:0.996
Batch: 1012/3370	Loss:0.739
Batch: 1349/3370	Loss:0.702
Batch: 1686/3370	Loss:1.478
Batch: 2023/3370	Loss:0.305
Batch: 2360/3370	Loss:1.473
Batch: 2697/3370	Loss:0.585
Batch: 3034/3370	Loss:0.457
Batch: 3370/3370	Loss:1.524
Epoch: 1	Train Loss: 0.805	Val F1: 0.672
Best Epoch: 1	Best Epoch Val F1: 0.672

******************************Epoch: 2******************************
Batch: 1/3370	Loss:0.603
Batch: 338/3370	Loss:0.909
Batch: 675/3370	Loss:0.468
Batch: 1012/3370	Loss:0.675
Batch: 1349/3370	Loss:0.585
Batch: 1686/3370	Loss:0.389
Batch: 2023/3370	Loss:0.561
Batch: 2360/3370	Loss:0.422
Batch: 2697/3370	Loss:0.584
Batch: 3034/3370	Loss:0.451
Batch: 3370/3370	Loss:0.017
Epoch: 2	Train Loss: 0.596	Val F1: 0.708
Best Epoch: 2	Best Epoch Val F1: 0.708

******************************Epoch: 3******************************
Batch: 1/3370	Loss:0.176
Batch: 338/3370	Loss:0.469
Batch: 675/3370	Loss:0.414
Batch: 1012/3370	Loss:0.832
Batch: 1349/3370	Loss:0.357
Batch: 1686/3370	Loss:0.543
Batch: 2023/3370	Loss:0.489
Batch: 2360/3370	Loss:0.288
Batch: 2697/3370	Loss:0.149
Batch: 3034/3370	Loss:0.142
Batch: 3370/3370	Loss:0.083
Epoch: 3	Train Loss: 0.500	Val F1: 0.705
Best Epoch: 2	Best Epoch Val F1: 0.708

******************************Epoch: 4******************************
Batch: 1/3370	Loss:0.125
Batch: 338/3370	Loss:0.315
Batch: 675/3370	Loss:0.195
Batch: 1012/3370	Loss:0.400
Batch: 1349/3370	Loss:0.221
Batch: 1686/3370	Loss:0.252
Batch: 2023/3370	Loss:0.447
Batch: 2360/3370	Loss:0.396
Batch: 2697/3370	Loss:0.728
Batch: 3034/3370	Loss:0.766
Batch: 3370/3370	Loss:0.008
Epoch: 4	Train Loss: 0.423	Val F1: 0.692
Best Epoch: 2	Best Epoch Val F1: 0.708

******************************Epoch: 5******************************
Batch: 1/3370	Loss:0.519
Batch: 338/3370	Loss:0.458
Batch: 675/3370	Loss:0.343
Batch: 1012/3370	Loss:0.185
Batch: 1349/3370	Loss:0.051
Batch: 1686/3370	Loss:0.144
Batch: 2023/3370	Loss:0.073
Batch: 2360/3370	Loss:0.047
Batch: 2697/3370	Loss:0.873
Batch: 3034/3370	Loss:0.593
Batch: 3370/3370	Loss:0.451
Epoch: 5	Train Loss: 0.372	Val F1: 0.697
Best Epoch: 2	Best Epoch Val F1: 0.708

******************************Epoch: 6******************************
Batch: 1/3370	Loss:0.059
Batch: 338/3370	Loss:0.130
Batch: 675/3370	Loss:0.181
Batch: 1012/3370	Loss:0.172
Batch: 1349/3370	Loss:0.074
Batch: 1686/3370	Loss:0.527
Batch: 2023/3370	Loss:0.027
Batch: 2360/3370	Loss:0.365
Batch: 2697/3370	Loss:0.033
Batch: 3034/3370	Loss:0.559
Batch: 3370/3370	Loss:0.002
Epoch: 6	Train Loss: 0.331	Val F1: 0.709
Best Epoch: 6	Best Epoch Val F1: 0.709

******************************Epoch: 7******************************
Batch: 1/3370	Loss:0.157
Batch: 338/3370	Loss:0.143
Batch: 675/3370	Loss:0.258
Batch: 1012/3370	Loss:0.076
Batch: 1349/3370	Loss:0.041
Batch: 1686/3370	Loss:1.037
Batch: 2023/3370	Loss:0.893
Batch: 2360/3370	Loss:0.527
Batch: 2697/3370	Loss:0.344
Batch: 3034/3370	Loss:0.064
Batch: 3370/3370	Loss:0.010
Epoch: 7	Train Loss: 0.292	Val F1: 0.685
Best Epoch: 6	Best Epoch Val F1: 0.709

******************************Epoch: 8******************************
Batch: 1/3370	Loss:0.299
Batch: 338/3370	Loss:0.650
Batch: 675/3370	Loss:0.012
Batch: 1012/3370	Loss:0.026
Batch: 1349/3370	Loss:0.076
Batch: 1686/3370	Loss:0.013
Batch: 2023/3370	Loss:0.777
Batch: 2360/3370	Loss:0.310
Batch: 2697/3370	Loss:0.037
Batch: 3034/3370	Loss:0.061
Batch: 3370/3370	Loss:0.005
Epoch: 8	Train Loss: 0.263	Val F1: 0.650
Best Epoch: 6	Best Epoch Val F1: 0.709

******************************Epoch: 9******************************
Batch: 1/3370	Loss:1.164
Batch: 338/3370	Loss:0.523
Batch: 675/3370	Loss:1.155
Batch: 1012/3370	Loss:0.381
Batch: 1349/3370	Loss:0.273
Batch: 1686/3370	Loss:0.439
Batch: 2023/3370	Loss:0.087
Batch: 2360/3370	Loss:0.159
Batch: 2697/3370	Loss:0.306
Batch: 3034/3370	Loss:0.125
Batch: 3370/3370	Loss:0.076
Epoch: 9	Train Loss: 0.230	Val F1: 0.701
Best Epoch: 6	Best Epoch Val F1: 0.709

******************************Epoch: 10******************************
Batch: 1/3370	Loss:0.235
Batch: 338/3370	Loss:0.388
Batch: 675/3370	Loss:0.276
Batch: 1012/3370	Loss:0.011
Batch: 1349/3370	Loss:0.022
Batch: 1686/3370	Loss:0.265
Batch: 2023/3370	Loss:0.074
Batch: 2360/3370	Loss:0.006
Batch: 2697/3370	Loss:0.621
Batch: 3034/3370	Loss:0.327
Batch: 3370/3370	Loss:0.006
Epoch: 10	Train Loss: 0.209	Val F1: 0.708
Best Epoch: 6	Best Epoch Val F1: 0.709

******************************Epoch: 11******************************
Batch: 1/3370	Loss:0.042
Batch: 338/3370	Loss:0.008
Batch: 675/3370	Loss:0.023
Batch: 1012/3370	Loss:0.014
Batch: 1349/3370	Loss:0.103
Batch: 1686/3370	Loss:0.085
Batch: 2023/3370	Loss:0.258
Batch: 2360/3370	Loss:0.080
Batch: 2697/3370	Loss:0.417
Batch: 3034/3370	Loss:0.434
Batch: 3370/3370	Loss:0.001
Epoch: 11	Train Loss: 0.190	Val F1: 0.705
Best Epoch: 6	Best Epoch Val F1: 0.709

******************************Epoch: 12******************************
Batch: 1/3370	Loss:0.219
Batch: 338/3370	Loss:0.001
Batch: 675/3370	Loss:0.023
Batch: 1012/3370	Loss:0.010
Batch: 1349/3370	Loss:0.010
Batch: 1686/3370	Loss:0.093
Batch: 2023/3370	Loss:0.012
Batch: 2360/3370	Loss:0.007
Batch: 2697/3370	Loss:0.023
Batch: 3034/3370	Loss:0.712
Batch: 3370/3370	Loss:0.001
Epoch: 12	Train Loss: 0.179	Val F1: 0.695
Best Epoch: 6	Best Epoch Val F1: 0.709

******************************Epoch: 13******************************
Batch: 1/3370	Loss:0.045
Batch: 338/3370	Loss:0.011
Batch: 675/3370	Loss:0.044
Batch: 1012/3370	Loss:0.030
Batch: 1349/3370	Loss:0.056
Batch: 1686/3370	Loss:0.079
Batch: 2023/3370	Loss:0.002
Batch: 2360/3370	Loss:0.075
Batch: 2697/3370	Loss:0.005
Batch: 3034/3370	Loss:0.004
Batch: 3370/3370	Loss:0.839
Epoch: 13	Train Loss: 0.164	Val F1: 0.710
Best Epoch: 13	Best Epoch Val F1: 0.710

******************************Epoch: 14******************************
Batch: 1/3370	Loss:0.261
Batch: 338/3370	Loss:0.001
Batch: 675/3370	Loss:0.001
Batch: 1012/3370	Loss:0.001
Batch: 1349/3370	Loss:0.059
Batch: 1686/3370	Loss:0.151
Batch: 2023/3370	Loss:0.242
Batch: 2360/3370	Loss:0.032
Batch: 2697/3370	Loss:0.003
Batch: 3034/3370	Loss:0.008
Batch: 3370/3370	Loss:5.732
Epoch: 14	Train Loss: 0.158	Val F1: 0.665
Best Epoch: 13	Best Epoch Val F1: 0.710

******************************Epoch: 15******************************
Batch: 1/3370	Loss:0.017
Batch: 338/3370	Loss:0.057
Batch: 675/3370	Loss:0.004
Batch: 1012/3370	Loss:0.615
Batch: 1349/3370	Loss:0.209
Batch: 1686/3370	Loss:0.030
Batch: 2023/3370	Loss:0.332
Batch: 2360/3370	Loss:0.014
Batch: 2697/3370	Loss:0.051
Batch: 3034/3370	Loss:0.239
Batch: 3370/3370	Loss:0.007
Epoch: 15	Train Loss: 0.145	Val F1: 0.676
Best Epoch: 13	Best Epoch Val F1: 0.710

******************************Epoch: 16******************************
Batch: 1/3370	Loss:0.323
Batch: 338/3370	Loss:0.082
Batch: 675/3370	Loss:0.024
Batch: 1012/3370	Loss:0.006
Batch: 1349/3370	Loss:0.080
Batch: 1686/3370	Loss:0.082
Batch: 2023/3370	Loss:1.336
Batch: 2360/3370	Loss:0.072
Batch: 2697/3370	Loss:0.002
Batch: 3034/3370	Loss:0.457
Batch: 3370/3370	Loss:0.003
Epoch: 16	Train Loss: 0.135	Val F1: 0.712
Best Epoch: 16	Best Epoch Val F1: 0.712

******************************Epoch: 17******************************
Batch: 1/3370	Loss:0.009
Batch: 338/3370	Loss:0.002
Batch: 675/3370	Loss:0.008
Batch: 1012/3370	Loss:0.008
Batch: 1349/3370	Loss:0.183
Batch: 1686/3370	Loss:0.127
Batch: 2023/3370	Loss:0.003
Batch: 2360/3370	Loss:0.325
Batch: 2697/3370	Loss:0.513
Batch: 3034/3370	Loss:0.087
Batch: 3370/3370	Loss:0.037
Epoch: 17	Train Loss: 0.131	Val F1: 0.701
Best Epoch: 16	Best Epoch Val F1: 0.712

******************************Epoch: 18******************************
Batch: 1/3370	Loss:0.001
Batch: 338/3370	Loss:0.003
Batch: 675/3370	Loss:0.045
Batch: 1012/3370	Loss:0.023
Batch: 1349/3370	Loss:0.009
Batch: 1686/3370	Loss:0.009
Batch: 2023/3370	Loss:0.203
Batch: 2360/3370	Loss:0.004
Batch: 2697/3370	Loss:0.019
Batch: 3034/3370	Loss:0.057
Batch: 3370/3370	Loss:0.010
Epoch: 18	Train Loss: 0.127	Val F1: 0.701
Best Epoch: 16	Best Epoch Val F1: 0.712

******************************Epoch: 19******************************
Batch: 1/3370	Loss:0.038
Batch: 338/3370	Loss:0.002
Batch: 675/3370	Loss:0.001
Batch: 1012/3370	Loss:0.487
Batch: 1349/3370	Loss:0.386
Batch: 1686/3370	Loss:0.351
Batch: 2023/3370	Loss:0.015
Batch: 2360/3370	Loss:0.007
Batch: 2697/3370	Loss:0.119
Batch: 3034/3370	Loss:0.011
Batch: 3370/3370	Loss:0.468
Epoch: 19	Train Loss: 0.123	Val F1: 0.698
Best Epoch: 16	Best Epoch Val F1: 0.712

******************************Epoch: 20******************************
Batch: 1/3370	Loss:0.074
Batch: 338/3370	Loss:0.122
Batch: 675/3370	Loss:0.001
Batch: 1012/3370	Loss:0.002
Batch: 1349/3370	Loss:0.039
Batch: 1686/3370	Loss:0.012
Batch: 2023/3370	Loss:0.003
Batch: 2360/3370	Loss:0.350
Batch: 2697/3370	Loss:0.029
Batch: 3034/3370	Loss:0.562
Batch: 3370/3370	Loss:0.004
Epoch: 20	Train Loss: 0.112	Val F1: 0.706
Best Epoch: 16	Best Epoch Val F1: 0.712

******************************Epoch: 21******************************
Batch: 1/3370	Loss:0.002
Batch: 338/3370	Loss:0.011
Batch: 675/3370	Loss:0.007
Batch: 1012/3370	Loss:0.001
Batch: 1349/3370	Loss:0.131
Batch: 1686/3370	Loss:0.001
Batch: 2023/3370	Loss:0.010
Batch: 2360/3370	Loss:0.007
Batch: 2697/3370	Loss:0.001
Batch: 3034/3370	Loss:0.348
Batch: 3370/3370	Loss:0.000
Epoch: 21	Train Loss: 0.111	Val F1: 0.700
Best Epoch: 16	Best Epoch Val F1: 0.712

******************************Epoch: 22******************************
Batch: 1/3370	Loss:0.027
Batch: 338/3370	Loss:0.163
Batch: 675/3370	Loss:0.002
Batch: 1012/3370	Loss:0.139
Batch: 1349/3370	Loss:0.039
Batch: 1686/3370	Loss:0.003
Batch: 2023/3370	Loss:0.163
Batch: 2360/3370	Loss:0.087
Batch: 2697/3370	Loss:0.003
Batch: 3034/3370	Loss:0.149
Batch: 3370/3370	Loss:1.837
Epoch: 22	Train Loss: 0.110	Val F1: 0.702
Best Epoch: 16	Best Epoch Val F1: 0.712

******************************Epoch: 23******************************
Batch: 1/3370	Loss:0.941
Batch: 338/3370	Loss:0.001
Batch: 675/3370	Loss:0.001
Batch: 1012/3370	Loss:0.000
Batch: 1349/3370	Loss:0.007
Batch: 1686/3370	Loss:0.267
Batch: 2023/3370	Loss:0.151
Batch: 2360/3370	Loss:0.393
Batch: 2697/3370	Loss:0.278
Batch: 3034/3370	Loss:0.286
Batch: 3370/3370	Loss:0.000
Epoch: 23	Train Loss: 0.102	Val F1: 0.697
Best Epoch: 16	Best Epoch Val F1: 0.712

******************************Epoch: 24******************************
Batch: 1/3370	Loss:0.001
Batch: 338/3370	Loss:0.001
Batch: 675/3370	Loss:0.066
Batch: 1012/3370	Loss:0.020
Batch: 1349/3370	Loss:0.055
Batch: 1686/3370	Loss:0.015
Batch: 2023/3370	Loss:0.247
Batch: 2360/3370	Loss:0.148
Batch: 2697/3370	Loss:0.058
Batch: 3034/3370	Loss:0.478
Batch: 3370/3370	Loss:0.004
Epoch: 24	Train Loss: 0.105	Val F1: 0.701
Best Epoch: 16	Best Epoch Val F1: 0.712

******************************Epoch: 25******************************
Batch: 1/3370	Loss:0.033
Batch: 338/3370	Loss:0.014
Batch: 675/3370	Loss:0.176
Batch: 1012/3370	Loss:0.030
Batch: 1349/3370	Loss:0.018
Batch: 1686/3370	Loss:0.330
Batch: 2023/3370	Loss:0.002
Batch: 2360/3370	Loss:0.001
Batch: 2697/3370	Loss:0.043
Batch: 3034/3370	Loss:0.038
Batch: 3370/3370	Loss:0.001
Epoch: 25	Train Loss: 0.102	Val F1: 0.692
Best Epoch: 16	Best Epoch Val F1: 0.712

******************************Epoch: 26******************************
Batch: 1/3370	Loss:0.001
Batch: 338/3370	Loss:0.131
Batch: 675/3370	Loss:0.338
Batch: 1012/3370	Loss:0.270
Batch: 1349/3370	Loss:0.023
Batch: 1686/3370	Loss:0.003
Batch: 2023/3370	Loss:0.333
Batch: 2360/3370	Loss:0.003
Batch: 2697/3370	Loss:0.000
Batch: 3034/3370	Loss:0.001
Batch: 3370/3370	Loss:0.000
Epoch: 26	Train Loss: 0.101	Val F1: 0.716
Best Epoch: 26	Best Epoch Val F1: 0.716

******************************Epoch: 27******************************
Batch: 1/3370	Loss:0.052
Batch: 338/3370	Loss:0.002
Batch: 675/3370	Loss:0.000
Batch: 1012/3370	Loss:0.077
Batch: 1349/3370	Loss:0.012
Batch: 1686/3370	Loss:0.000
Batch: 2023/3370	Loss:0.076
Batch: 2360/3370	Loss:0.051
Batch: 2697/3370	Loss:0.004
Batch: 3034/3370	Loss:0.020
Batch: 3370/3370	Loss:0.085
Epoch: 27	Train Loss: 0.097	Val F1: 0.707
Best Epoch: 26	Best Epoch Val F1: 0.716

******************************Epoch: 28******************************
Batch: 1/3370	Loss:0.050
Batch: 338/3370	Loss:0.074
Batch: 675/3370	Loss:0.023
Batch: 1012/3370	Loss:0.004
Batch: 1349/3370	Loss:0.000
Batch: 1686/3370	Loss:0.001
Batch: 2023/3370	Loss:0.217
Batch: 2360/3370	Loss:0.013
Batch: 2697/3370	Loss:0.428
Batch: 3034/3370	Loss:0.007
Batch: 3370/3370	Loss:0.000
Epoch: 28	Train Loss: 0.093	Val F1: 0.717
Best Epoch: 28	Best Epoch Val F1: 0.717

******************************Epoch: 29******************************
Batch: 1/3370	Loss:0.000
Batch: 338/3370	Loss:0.000
Batch: 675/3370	Loss:0.000
Batch: 1012/3370	Loss:0.026
Batch: 1349/3370	Loss:0.002
Batch: 1686/3370	Loss:0.000
Batch: 2023/3370	Loss:0.050
Batch: 2360/3370	Loss:0.011
Batch: 2697/3370	Loss:0.000
Batch: 3034/3370	Loss:0.116
Batch: 3370/3370	Loss:0.001
Epoch: 29	Train Loss: 0.098	Val F1: 0.691
Best Epoch: 28	Best Epoch Val F1: 0.717

******************************Epoch: 30******************************
Batch: 1/3370	Loss:0.009
Batch: 338/3370	Loss:0.001
Batch: 675/3370	Loss:0.000
Batch: 1012/3370	Loss:0.012
Batch: 1349/3370	Loss:0.028
Batch: 1686/3370	Loss:0.001
Batch: 2023/3370	Loss:0.001
Batch: 2360/3370	Loss:0.000
Batch: 2697/3370	Loss:0.003
Batch: 3034/3370	Loss:0.001
Batch: 3370/3370	Loss:0.001
Epoch: 30	Train Loss: 0.089	Val F1: 0.692
Best Epoch: 28	Best Epoch Val F1: 0.717

******************************Epoch: 31******************************
Batch: 1/3370	Loss:0.188
Batch: 338/3370	Loss:0.000
Batch: 675/3370	Loss:0.469
Batch: 1012/3370	Loss:0.232
Batch: 1349/3370	Loss:0.004
Batch: 1686/3370	Loss:0.001
Batch: 2023/3370	Loss:0.001
Batch: 2360/3370	Loss:0.000
Batch: 2697/3370	Loss:0.010
Batch: 3034/3370	Loss:0.000
Batch: 3370/3370	Loss:0.939
Epoch: 31	Train Loss: 0.086	Val F1: 0.701
Best Epoch: 28	Best Epoch Val F1: 0.717

******************************Epoch: 32******************************
Batch: 1/3370	Loss:0.001
Batch: 338/3370	Loss:0.013
Batch: 675/3370	Loss:0.024
Batch: 1012/3370	Loss:0.003
Batch: 1349/3370	Loss:0.165
Batch: 1686/3370	Loss:0.000
Batch: 2023/3370	Loss:0.001
Batch: 2360/3370	Loss:0.001
Batch: 2697/3370	Loss:0.001
Batch: 3034/3370	Loss:0.216
Batch: 3370/3370	Loss:0.000
Epoch: 32	Train Loss: 0.088	Val F1: 0.701
Best Epoch: 28	Best Epoch Val F1: 0.717

******************************Epoch: 33******************************
Batch: 1/3370	Loss:0.008
Batch: 338/3370	Loss:0.000
Batch: 675/3370	Loss:0.236
Batch: 1012/3370	Loss:0.004
Batch: 1349/3370	Loss:0.000
Batch: 1686/3370	Loss:0.916
Batch: 2023/3370	Loss:0.000
Batch: 2360/3370	Loss:0.000
Batch: 2697/3370	Loss:0.207
Batch: 3034/3370	Loss:0.019
Batch: 3370/3370	Loss:1.142
Epoch: 33	Train Loss: 0.086	Val F1: 0.706
Best Epoch: 28	Best Epoch Val F1: 0.717

******************************Epoch: 34******************************
Batch: 1/3370	Loss:0.098
Batch: 338/3370	Loss:0.000
Batch: 675/3370	Loss:0.275
Batch: 1012/3370	Loss:0.002
Batch: 1349/3370	Loss:0.000
Batch: 1686/3370	Loss:0.000
Batch: 2023/3370	Loss:0.003
Batch: 2360/3370	Loss:0.000
Batch: 2697/3370	Loss:0.012
Batch: 3034/3370	Loss:0.008
Batch: 3370/3370	Loss:0.003
Epoch: 34	Train Loss: 0.088	Val F1: 0.708
Best Epoch: 28	Best Epoch Val F1: 0.717

******************************Epoch: 35******************************
Batch: 1/3370	Loss:0.107
Batch: 338/3370	Loss:0.175
Batch: 675/3370	Loss:0.001
Batch: 1012/3370	Loss:0.195
Batch: 1349/3370	Loss:0.256
Batch: 1686/3370	Loss:0.000
Batch: 2023/3370	Loss:0.000
Batch: 2360/3370	Loss:0.000
Batch: 2697/3370	Loss:0.001
Batch: 3034/3370	Loss:0.124
Batch: 3370/3370	Loss:2.361
Epoch: 35	Train Loss: 0.083	Val F1: 0.710
Best Epoch: 28	Best Epoch Val F1: 0.717

******************************Epoch: 36******************************
Batch: 1/3370	Loss:0.000
Batch: 338/3370	Loss:0.000
Batch: 675/3370	Loss:0.214
Batch: 1012/3370	Loss:0.037
Batch: 1349/3370	Loss:0.000
Batch: 1686/3370	Loss:0.001
Batch: 2023/3370	Loss:0.000
Batch: 2360/3370	Loss:0.000
Batch: 2697/3370	Loss:0.001
Batch: 3034/3370	Loss:0.071
Batch: 3370/3370	Loss:0.000
Epoch: 36	Train Loss: 0.085	Val F1: 0.696
Best Epoch: 28	Best Epoch Val F1: 0.717

******************************Epoch: 37******************************
Batch: 1/3370	Loss:0.019
Batch: 338/3370	Loss:0.124
Batch: 675/3370	Loss:0.001
Batch: 1012/3370	Loss:0.467
Batch: 1349/3370	Loss:0.000
Batch: 1686/3370	Loss:0.036
Batch: 2023/3370	Loss:0.193
Batch: 2360/3370	Loss:0.002
Batch: 2697/3370	Loss:0.356
Batch: 3034/3370	Loss:0.004
Batch: 3370/3370	Loss:0.000
Epoch: 37	Train Loss: 0.087	Val F1: 0.686
Best Epoch: 28	Best Epoch Val F1: 0.717

******************************Epoch: 38******************************
Batch: 1/3370	Loss:0.208
Batch: 338/3370	Loss:0.002
Batch: 675/3370	Loss:0.364
Batch: 1012/3370	Loss:0.203
Batch: 1349/3370	Loss:0.191
Batch: 1686/3370	Loss:0.001
Batch: 2023/3370	Loss:0.004
Batch: 2360/3370	Loss:0.001
Batch: 2697/3370	Loss:0.222
Batch: 3034/3370	Loss:0.000
Batch: 3370/3370	Loss:0.000
Epoch: 38	Train Loss: 0.081	Val F1: 0.687
Best Epoch: 28	Best Epoch Val F1: 0.717

******************************Epoch: 39******************************
Batch: 1/3370	Loss:0.001
Batch: 338/3370	Loss:0.001
Batch: 675/3370	Loss:0.002
Batch: 1012/3370	Loss:0.009
Batch: 1349/3370	Loss:0.153
Batch: 1686/3370	Loss:0.130
Batch: 2023/3370	Loss:0.228
Batch: 2360/3370	Loss:0.003
Batch: 2697/3370	Loss:0.001
Batch: 3034/3370	Loss:0.000
Batch: 3370/3370	Loss:0.000
Epoch: 39	Train Loss: 0.084	Val F1: 0.700
Best Epoch: 28	Best Epoch Val F1: 0.717

******************************Epoch: 40******************************
Batch: 1/3370	Loss:0.003
Batch: 338/3370	Loss:0.000
Batch: 675/3370	Loss:0.001
Batch: 1012/3370	Loss:0.001
Batch: 1349/3370	Loss:0.180
Batch: 1686/3370	Loss:0.000
Batch: 2023/3370	Loss:0.001
Batch: 2360/3370	Loss:0.209
Batch: 2697/3370	Loss:0.000
Batch: 3034/3370	Loss:0.005
Batch: 3370/3370	Loss:0.002
Epoch: 40	Train Loss: 0.083	Val F1: 0.704
Best Epoch: 28	Best Epoch Val F1: 0.717

******************************Epoch: 41******************************
Batch: 1/3370	Loss:0.264
Batch: 338/3370	Loss:0.000
Batch: 675/3370	Loss:0.223
Batch: 1012/3370	Loss:0.015
Batch: 1349/3370	Loss:0.002
Batch: 1686/3370	Loss:0.002
Batch: 2023/3370	Loss:0.000
Batch: 2360/3370	Loss:0.000
Batch: 2697/3370	Loss:0.001
Batch: 3034/3370	Loss:0.160
Batch: 3370/3370	Loss:0.001
Epoch: 41	Train Loss: 0.084	Val F1: 0.684
Best Epoch: 28	Best Epoch Val F1: 0.717

******************************Epoch: 42******************************
Batch: 1/3370	Loss:0.000
Batch: 338/3370	Loss:0.003
Batch: 675/3370	Loss:0.007
Batch: 1012/3370	Loss:0.002
Batch: 1349/3370	Loss:0.000
Batch: 1686/3370	Loss:0.005
Batch: 2023/3370	Loss:0.007
Batch: 2360/3370	Loss:0.005
Batch: 2697/3370	Loss:0.114
Batch: 3034/3370	Loss:0.028
Batch: 3370/3370	Loss:0.000
Epoch: 42	Train Loss: 0.085	Val F1: 0.704
Best Epoch: 28	Best Epoch Val F1: 0.717

******************************Epoch: 43******************************
Batch: 1/3370	Loss:0.000
Batch: 338/3370	Loss:0.022
Batch: 675/3370	Loss:0.165
Batch: 1012/3370	Loss:0.104
Batch: 1349/3370	Loss:0.255
Batch: 1686/3370	Loss:0.010
Batch: 2023/3370	Loss:0.000
Batch: 2360/3370	Loss:0.058
Batch: 2697/3370	Loss:0.169
Batch: 3034/3370	Loss:0.058
Batch: 3370/3370	Loss:0.000
Epoch: 43	Train Loss: 0.078	Val F1: 0.700
Best Epoch: 28	Best Epoch Val F1: 0.717

Saving the best checkpoint....
Inference...
Test F1: 0.740	Test F1_Few: 0.748	Test F1_Zero: 0.731
Starting training with config: {'batch_size': 32, 'epochs': 50, 'l2_reg': 9.293029026634384e-05, 'lr': 1.432931294534992e-05, 'n_layers_freeze': 2, 'patience': 5}
Let's use 1 GPUs!
Preparing data....
Training data....
# of train examples: 13477
max len: 512, max len wiki: 1
Val data....
# of val examples: 2062
max len: 512, max len wiki: 1
Test data....
# of test examples: 3006
max len: 512, max len wiki: 1
Done

Initializing model....
******************************Epoch: 1******************************
Batch: 1/422	Loss:1.244
Batch: 43/422	Loss:1.094
Batch: 85/422	Loss:1.116
Batch: 127/422	Loss:1.041
Batch: 169/422	Loss:1.112
Batch: 211/422	Loss:1.021
Batch: 253/422	Loss:1.032
Batch: 295/422	Loss:1.061
Batch: 337/422	Loss:0.985
Batch: 379/422	Loss:0.612
Batch: 421/422	Loss:0.832
Batch: 422/422	Loss:0.891
Epoch: 1	Train Loss: 0.975	Val F1: 0.710
Best Epoch: 1	Best Epoch Val F1: 0.710

******************************Epoch: 2******************************
Batch: 1/422	Loss:0.675
Batch: 43/422	Loss:0.791
Batch: 85/422	Loss:0.666
Batch: 127/422	Loss:0.639
Batch: 169/422	Loss:0.569
Batch: 211/422	Loss:0.752
Batch: 253/422	Loss:0.665
Batch: 295/422	Loss:0.616
Batch: 337/422	Loss:0.730
Batch: 379/422	Loss:0.616
Batch: 421/422	Loss:0.477
Batch: 422/422	Loss:0.500
Epoch: 2	Train Loss: 0.628	Val F1: 0.708
Best Epoch: 1	Best Epoch Val F1: 0.710

******************************Epoch: 3******************************
Batch: 1/422	Loss:0.699
Batch: 43/422	Loss:0.479
Batch: 85/422	Loss:0.590
Batch: 127/422	Loss:0.531
Batch: 169/422	Loss:0.457
Batch: 211/422	Loss:0.565
Batch: 253/422	Loss:0.452
Batch: 295/422	Loss:0.651
Batch: 337/422	Loss:0.390
Batch: 379/422	Loss:0.594
Batch: 421/422	Loss:0.392
Batch: 422/422	Loss:0.493
Epoch: 3	Train Loss: 0.519	Val F1: 0.736
Best Epoch: 3	Best Epoch Val F1: 0.736

******************************Epoch: 4******************************
Batch: 1/422	Loss:0.393
Batch: 43/422	Loss:0.483
Batch: 85/422	Loss:0.484
Batch: 127/422	Loss:0.441
Batch: 169/422	Loss:0.616
Batch: 211/422	Loss:0.468
Batch: 253/422	Loss:0.391
Batch: 295/422	Loss:0.267
Batch: 337/422	Loss:0.563
Batch: 379/422	Loss:0.458
Batch: 421/422	Loss:0.272
Batch: 422/422	Loss:1.409
Epoch: 4	Train Loss: 0.446	Val F1: 0.687
Best Epoch: 3	Best Epoch Val F1: 0.736

******************************Epoch: 5******************************
Batch: 1/422	Loss:0.390
Batch: 43/422	Loss:0.274
Batch: 85/422	Loss:0.347
Batch: 127/422	Loss:0.267
Batch: 169/422	Loss:0.443
Batch: 211/422	Loss:0.448
Batch: 253/422	Loss:0.349
Batch: 295/422	Loss:0.354
Batch: 337/422	Loss:0.406
Batch: 379/422	Loss:0.288
Batch: 421/422	Loss:0.444
Batch: 422/422	Loss:0.512
Epoch: 5	Train Loss: 0.396	Val F1: 0.690
Best Epoch: 3	Best Epoch Val F1: 0.736

******************************Epoch: 6******************************
Batch: 1/422	Loss:0.295
Batch: 43/422	Loss:0.268
Batch: 85/422	Loss:0.509
Batch: 127/422	Loss:0.329
Batch: 169/422	Loss:0.404
Batch: 211/422	Loss:0.412
Batch: 253/422	Loss:0.279
Batch: 295/422	Loss:0.324
Batch: 337/422	Loss:0.447
Batch: 379/422	Loss:0.365
Batch: 421/422	Loss:0.295
Batch: 422/422	Loss:0.048
Epoch: 6	Train Loss: 0.355	Val F1: 0.722
Best Epoch: 3	Best Epoch Val F1: 0.736

******************************Epoch: 7******************************
Batch: 1/422	Loss:0.350
Batch: 43/422	Loss:0.300
Batch: 85/422	Loss:0.259
Batch: 127/422	Loss:0.203
Batch: 169/422	Loss:0.682
Batch: 211/422	Loss:0.410
Batch: 253/422	Loss:0.417
Batch: 295/422	Loss:0.301
Batch: 337/422	Loss:0.577
Batch: 379/422	Loss:0.475
Batch: 421/422	Loss:0.427
Batch: 422/422	Loss:0.197
Epoch: 7	Train Loss: 0.321	Val F1: 0.722
Best Epoch: 3	Best Epoch Val F1: 0.736

******************************Epoch: 8******************************
Batch: 1/422	Loss:0.311
Batch: 43/422	Loss:0.365
Batch: 85/422	Loss:0.132
Batch: 127/422	Loss:0.374
Batch: 169/422	Loss:0.330
Batch: 211/422	Loss:0.252
Batch: 253/422	Loss:0.421
Batch: 295/422	Loss:0.255
Batch: 337/422	Loss:0.234
Batch: 379/422	Loss:0.218
Batch: 421/422	Loss:0.317
Batch: 422/422	Loss:0.265
Epoch: 8	Train Loss: 0.289	Val F1: 0.699
Best Epoch: 3	Best Epoch Val F1: 0.736

Saving the best checkpoint....
Inference...
Test F1: 0.747	Test F1_Few: 0.749	Test F1_Zero: 0.744
Starting training with config: {'batch_size': 4, 'epochs': 50, 'l2_reg': 3.05961387708755e-05, 'lr': 2.699740527902376e-05, 'n_layers_freeze': 0, 'patience': 10}
Let's use 1 GPUs!
Preparing data....
Training data....
# of train examples: 13477
max len: 512, max len wiki: 1
Val data....
# of val examples: 2062
max len: 512, max len wiki: 1
Test data....
# of test examples: 3006
max len: 512, max len wiki: 1
Done

Initializing model....
******************************Epoch: 1******************************
Batch: 1/3370	Loss:1.322
Batch: 338/3370	Loss:1.212
Batch: 675/3370	Loss:0.763
Batch: 1012/3370	Loss:0.831
Batch: 1349/3370	Loss:0.729
Batch: 1686/3370	Loss:1.502
Batch: 2023/3370	Loss:0.332
Batch: 2360/3370	Loss:1.213
Batch: 2697/3370	Loss:0.998
Batch: 3034/3370	Loss:0.605
Batch: 3370/3370	Loss:1.940
Epoch: 1	Train Loss: 0.797	Val F1: 0.673
Best Epoch: 1	Best Epoch Val F1: 0.673

******************************Epoch: 2******************************
Batch: 1/3370	Loss:0.545
Batch: 338/3370	Loss:0.919
Batch: 675/3370	Loss:0.558
Batch: 1012/3370	Loss:0.382
Batch: 1349/3370	Loss:0.701
Batch: 1686/3370	Loss:0.244
Batch: 2023/3370	Loss:0.653
Batch: 2360/3370	Loss:0.735
Batch: 2697/3370	Loss:0.717
Batch: 3034/3370	Loss:0.476
Batch: 3370/3370	Loss:0.009
Epoch: 2	Train Loss: 0.613	Val F1: 0.716
Best Epoch: 2	Best Epoch Val F1: 0.716

******************************Epoch: 3******************************
Batch: 1/3370	Loss:0.186
Batch: 338/3370	Loss:0.733
Batch: 675/3370	Loss:0.679
Batch: 1012/3370	Loss:0.669
Batch: 1349/3370	Loss:0.421
Batch: 1686/3370	Loss:1.627
Batch: 2023/3370	Loss:0.390
Batch: 2360/3370	Loss:0.273
Batch: 2697/3370	Loss:0.160
Batch: 3034/3370	Loss:0.257
Batch: 3370/3370	Loss:0.070
Epoch: 3	Train Loss: 0.526	Val F1: 0.691
Best Epoch: 2	Best Epoch Val F1: 0.716

******************************Epoch: 4******************************
Batch: 1/3370	Loss:0.229
Batch: 338/3370	Loss:0.662
Batch: 675/3370	Loss:0.445
Batch: 1012/3370	Loss:0.331
Batch: 1349/3370	Loss:0.259
Batch: 1686/3370	Loss:0.763
Batch: 2023/3370	Loss:0.511
Batch: 2360/3370	Loss:0.438
Batch: 2697/3370	Loss:0.884
Batch: 3034/3370	Loss:0.624
Batch: 3370/3370	Loss:0.003
Epoch: 4	Train Loss: 0.474	Val F1: 0.705
Best Epoch: 2	Best Epoch Val F1: 0.716

******************************Epoch: 5******************************
Batch: 1/3370	Loss:0.640
Batch: 338/3370	Loss:0.902
Batch: 675/3370	Loss:0.153
Batch: 1012/3370	Loss:0.080
Batch: 1349/3370	Loss:0.041
Batch: 1686/3370	Loss:0.278
Batch: 2023/3370	Loss:0.133
Batch: 2360/3370	Loss:0.104
Batch: 2697/3370	Loss:1.169
Batch: 3034/3370	Loss:0.252
Batch: 3370/3370	Loss:0.437
Epoch: 5	Train Loss: 0.425	Val F1: 0.698
Best Epoch: 2	Best Epoch Val F1: 0.716

******************************Epoch: 6******************************
Batch: 1/3370	Loss:0.035
Batch: 338/3370	Loss:0.295
Batch: 675/3370	Loss:0.213
Batch: 1012/3370	Loss:0.220
Batch: 1349/3370	Loss:0.054
Batch: 1686/3370	Loss:0.951
Batch: 2023/3370	Loss:0.027
Batch: 2360/3370	Loss:0.457
Batch: 2697/3370	Loss:0.059
Batch: 3034/3370	Loss:0.991
Batch: 3370/3370	Loss:0.001
Epoch: 6	Train Loss: 0.381	Val F1: 0.674
Best Epoch: 2	Best Epoch Val F1: 0.716

******************************Epoch: 7******************************
Batch: 1/3370	Loss:0.278
Batch: 338/3370	Loss:0.285
Batch: 675/3370	Loss:0.481
Batch: 1012/3370	Loss:0.095
Batch: 1349/3370	Loss:0.202
Batch: 1686/3370	Loss:0.793
Batch: 2023/3370	Loss:0.709
Batch: 2360/3370	Loss:0.539
Batch: 2697/3370	Loss:0.800
Batch: 3034/3370	Loss:0.377
Batch: 3370/3370	Loss:0.006
Epoch: 7	Train Loss: 0.351	Val F1: 0.687
Best Epoch: 2	Best Epoch Val F1: 0.716

******************************Epoch: 8******************************
Batch: 1/3370	Loss:0.654
Batch: 338/3370	Loss:1.421
Batch: 675/3370	Loss:0.010
Batch: 1012/3370	Loss:0.023
Batch: 1349/3370	Loss:0.022
Batch: 1686/3370	Loss:0.147
Batch: 2023/3370	Loss:0.196
Batch: 2360/3370	Loss:0.801
Batch: 2697/3370	Loss:0.042
Batch: 3034/3370	Loss:0.340
Batch: 3370/3370	Loss:0.010
Epoch: 8	Train Loss: 0.310	Val F1: 0.689
Best Epoch: 2	Best Epoch Val F1: 0.716

******************************Epoch: 9******************************
Batch: 1/3370	Loss:0.996
Batch: 338/3370	Loss:0.410
Batch: 675/3370	Loss:0.968
Batch: 1012/3370	Loss:0.314
Batch: 1349/3370	Loss:0.428
Batch: 1686/3370	Loss:0.531
Batch: 2023/3370	Loss:0.067
Batch: 2360/3370	Loss:0.260
Batch: 2697/3370	Loss:0.092
Batch: 3034/3370	Loss:0.228
Batch: 3370/3370	Loss:0.015
Epoch: 9	Train Loss: 0.283	Val F1: 0.708
Best Epoch: 2	Best Epoch Val F1: 0.716

******************************Epoch: 10******************************
Batch: 1/3370	Loss:0.276
Batch: 338/3370	Loss:0.822
Batch: 675/3370	Loss:0.799
Batch: 1012/3370	Loss:0.429
Batch: 1349/3370	Loss:0.015
Batch: 1686/3370	Loss:0.515
Batch: 2023/3370	Loss:0.017
Batch: 2360/3370	Loss:0.027
Batch: 2697/3370	Loss:0.647
Batch: 3034/3370	Loss:0.409
Batch: 3370/3370	Loss:0.018
Epoch: 10	Train Loss: 0.259	Val F1: 0.706
Best Epoch: 2	Best Epoch Val F1: 0.716

******************************Epoch: 11******************************
Batch: 1/3370	Loss:0.031
Batch: 338/3370	Loss:0.147
Batch: 675/3370	Loss:0.033
Batch: 1012/3370	Loss:0.043
Batch: 1349/3370	Loss:0.129
Batch: 1686/3370	Loss:0.019
Batch: 2023/3370	Loss:0.496
Batch: 2360/3370	Loss:0.159
Batch: 2697/3370	Loss:0.025
Batch: 3034/3370	Loss:0.369
Batch: 3370/3370	Loss:0.006
Epoch: 11	Train Loss: 0.230	Val F1: 0.686
Best Epoch: 2	Best Epoch Val F1: 0.716

******************************Epoch: 12******************************
Batch: 1/3370	Loss:0.254
Batch: 338/3370	Loss:0.005
Batch: 675/3370	Loss:0.180
Batch: 1012/3370	Loss:0.020
Batch: 1349/3370	Loss:0.134
Batch: 1686/3370	Loss:0.024
Batch: 2023/3370	Loss:0.023
Batch: 2360/3370	Loss:0.014
Batch: 2697/3370	Loss:0.461
Batch: 3034/3370	Loss:0.102
Batch: 3370/3370	Loss:0.006
Epoch: 12	Train Loss: 0.220	Val F1: 0.688
Best Epoch: 2	Best Epoch Val F1: 0.716

Saving the best checkpoint....
Inference...
Test F1: 0.732	Test F1_Few: 0.734	Test F1_Zero: 0.729
Starting training with config: {'batch_size': 4, 'epochs': 50, 'l2_reg': 3.3340998837865895e-05, 'lr': 1.661104818711433e-05, 'n_layers_freeze': 4, 'patience': 5}
Let's use 1 GPUs!
Preparing data....
Training data....
# of train examples: 13477
max len: 512, max len wiki: 1
Val data....
# of val examples: 2062
max len: 512, max len wiki: 1
Test data....
# of test examples: 3006
max len: 512, max len wiki: 1
Done

Initializing model....
******************************Epoch: 1******************************
Batch: 1/3370	Loss:1.322
Batch: 338/3370	Loss:1.202
Batch: 675/3370	Loss:0.836
Batch: 1012/3370	Loss:0.612
Batch: 1349/3370	Loss:0.729
Batch: 1686/3370	Loss:1.630
Batch: 2023/3370	Loss:0.252
Batch: 2360/3370	Loss:1.260
Batch: 2697/3370	Loss:0.653
Batch: 3034/3370	Loss:0.503
Batch: 3370/3370	Loss:1.505
Epoch: 1	Train Loss: 0.752	Val F1: 0.670
Best Epoch: 1	Best Epoch Val F1: 0.670

******************************Epoch: 2******************************
Batch: 1/3370	Loss:0.620
Batch: 338/3370	Loss:1.206
Batch: 675/3370	Loss:0.475
Batch: 1012/3370	Loss:0.566
Batch: 1349/3370	Loss:0.480
Batch: 1686/3370	Loss:0.285
Batch: 2023/3370	Loss:0.505
Batch: 2360/3370	Loss:0.487
Batch: 2697/3370	Loss:0.726
Batch: 3034/3370	Loss:0.473
Batch: 3370/3370	Loss:0.021
Epoch: 2	Train Loss: 0.591	Val F1: 0.696
Best Epoch: 2	Best Epoch Val F1: 0.696

******************************Epoch: 3******************************
Batch: 1/3370	Loss:0.129
Batch: 338/3370	Loss:0.555
Batch: 675/3370	Loss:1.017
Batch: 1012/3370	Loss:0.629
Batch: 1349/3370	Loss:0.342
Batch: 1686/3370	Loss:1.217
Batch: 2023/3370	Loss:0.593
Batch: 2360/3370	Loss:0.295
Batch: 2697/3370	Loss:0.125
Batch: 3034/3370	Loss:0.129
Batch: 3370/3370	Loss:0.258
Epoch: 3	Train Loss: 0.505	Val F1: 0.703
Best Epoch: 3	Best Epoch Val F1: 0.703

******************************Epoch: 4******************************
Batch: 1/3370	Loss:0.162
Batch: 338/3370	Loss:0.536
Batch: 675/3370	Loss:0.116
Batch: 1012/3370	Loss:0.647
Batch: 1349/3370	Loss:0.159
Batch: 1686/3370	Loss:0.247
Batch: 2023/3370	Loss:0.587
Batch: 2360/3370	Loss:0.211
Batch: 2697/3370	Loss:0.647
Batch: 3034/3370	Loss:0.702
Batch: 3370/3370	Loss:0.003
Epoch: 4	Train Loss: 0.432	Val F1: 0.692
Best Epoch: 3	Best Epoch Val F1: 0.703

******************************Epoch: 5******************************
Batch: 1/3370	Loss:0.539
Batch: 338/3370	Loss:0.498
Batch: 675/3370	Loss:0.413
Batch: 1012/3370	Loss:0.217
Batch: 1349/3370	Loss:0.023
Batch: 1686/3370	Loss:0.050
Batch: 2023/3370	Loss:0.055
Batch: 2360/3370	Loss:0.069
Batch: 2697/3370	Loss:0.600
Batch: 3034/3370	Loss:0.639
Batch: 3370/3370	Loss:0.331
Epoch: 5	Train Loss: 0.381	Val F1: 0.691
Best Epoch: 3	Best Epoch Val F1: 0.703

******************************Epoch: 6******************************
Batch: 1/3370	Loss:0.041
Batch: 338/3370	Loss:0.204
Batch: 675/3370	Loss:0.181
Batch: 1012/3370	Loss:0.124
Batch: 1349/3370	Loss:0.111
Batch: 1686/3370	Loss:0.364
Batch: 2023/3370	Loss:0.033
Batch: 2360/3370	Loss:0.570
Batch: 2697/3370	Loss:0.080
Batch: 3034/3370	Loss:0.703
Batch: 3370/3370	Loss:0.001
Epoch: 6	Train Loss: 0.339	Val F1: 0.709
Best Epoch: 6	Best Epoch Val F1: 0.709

******************************Epoch: 7******************************
Batch: 1/3370	Loss:0.141
Batch: 338/3370	Loss:0.174
Batch: 675/3370	Loss:0.171
Batch: 1012/3370	Loss:0.028
Batch: 1349/3370	Loss:0.069
Batch: 1686/3370	Loss:1.066
Batch: 2023/3370	Loss:0.406
Batch: 2360/3370	Loss:0.529
Batch: 2697/3370	Loss:0.208
Batch: 3034/3370	Loss:0.117
Batch: 3370/3370	Loss:0.005
Epoch: 7	Train Loss: 0.304	Val F1: 0.703
Best Epoch: 6	Best Epoch Val F1: 0.709

******************************Epoch: 8******************************
Batch: 1/3370	Loss:0.209
Batch: 338/3370	Loss:0.526
Batch: 675/3370	Loss:0.012
Batch: 1012/3370	Loss:0.069
Batch: 1349/3370	Loss:0.053
Batch: 1686/3370	Loss:0.107
Batch: 2023/3370	Loss:0.386
Batch: 2360/3370	Loss:0.284
Batch: 2697/3370	Loss:0.007
Batch: 3034/3370	Loss:0.021
Batch: 3370/3370	Loss:0.001
Epoch: 8	Train Loss: 0.274	Val F1: 0.671
Best Epoch: 6	Best Epoch Val F1: 0.709

******************************Epoch: 9******************************
Batch: 1/3370	Loss:0.876
Batch: 338/3370	Loss:0.351
Batch: 675/3370	Loss:0.362
Batch: 1012/3370	Loss:0.457
Batch: 1349/3370	Loss:0.176
Batch: 1686/3370	Loss:0.548
Batch: 2023/3370	Loss:0.078
Batch: 2360/3370	Loss:0.589
Batch: 2697/3370	Loss:0.484
Batch: 3034/3370	Loss:0.063
Batch: 3370/3370	Loss:0.307
Epoch: 9	Train Loss: 0.247	Val F1: 0.711
Best Epoch: 9	Best Epoch Val F1: 0.711

******************************Epoch: 10******************************
Batch: 1/3370	Loss:0.281
Batch: 338/3370	Loss:0.616
Batch: 675/3370	Loss:0.549
Batch: 1012/3370	Loss:0.195
Batch: 1349/3370	Loss:0.013
Batch: 1686/3370	Loss:0.146
Batch: 2023/3370	Loss:0.049
Batch: 2360/3370	Loss:0.006
Batch: 2697/3370	Loss:0.970
Batch: 3034/3370	Loss:0.127
Batch: 3370/3370	Loss:0.074
Epoch: 10	Train Loss: 0.224	Val F1: 0.705
Best Epoch: 9	Best Epoch Val F1: 0.711

******************************Epoch: 11******************************
Batch: 1/3370	Loss:0.061
Batch: 338/3370	Loss:0.145
Batch: 675/3370	Loss:0.019
Batch: 1012/3370	Loss:0.042
Batch: 1349/3370	Loss:0.070
Batch: 1686/3370	Loss:0.025
Batch: 2023/3370	Loss:1.026
Batch: 2360/3370	Loss:0.098
Batch: 2697/3370	Loss:0.022
Batch: 3034/3370	Loss:0.165
Batch: 3370/3370	Loss:0.001
Epoch: 11	Train Loss: 0.205	Val F1: 0.708
Best Epoch: 9	Best Epoch Val F1: 0.711

******************************Epoch: 12******************************
Batch: 1/3370	Loss:0.380
Batch: 338/3370	Loss:0.008
Batch: 675/3370	Loss:0.092
Batch: 1012/3370	Loss:0.083
Batch: 1349/3370	Loss:0.027
Batch: 1686/3370	Loss:0.185
Batch: 2023/3370	Loss:0.010
Batch: 2360/3370	Loss:0.045
Batch: 2697/3370	Loss:0.002
Batch: 3034/3370	Loss:0.731
Batch: 3370/3370	Loss:0.000
Epoch: 12	Train Loss: 0.197	Val F1: 0.717
Best Epoch: 12	Best Epoch Val F1: 0.717

******************************Epoch: 13******************************
Batch: 1/3370	Loss:0.099
Batch: 338/3370	Loss:0.025
Batch: 675/3370	Loss:0.058
Batch: 1012/3370	Loss:0.002
Batch: 1349/3370	Loss:0.144
Batch: 1686/3370	Loss:0.077
Batch: 2023/3370	Loss:0.001
Batch: 2360/3370	Loss:0.175
Batch: 2697/3370	Loss:0.024
Batch: 3034/3370	Loss:0.004
Batch: 3370/3370	Loss:0.110
Epoch: 13	Train Loss: 0.179	Val F1: 0.709
Best Epoch: 12	Best Epoch Val F1: 0.717

******************************Epoch: 14******************************
Batch: 1/3370	Loss:0.279
Batch: 338/3370	Loss:0.005
Batch: 675/3370	Loss:0.003
Batch: 1012/3370	Loss:0.004
Batch: 1349/3370	Loss:0.222
Batch: 1686/3370	Loss:0.333
Batch: 2023/3370	Loss:0.162
Batch: 2360/3370	Loss:0.039
Batch: 2697/3370	Loss:0.002
Batch: 3034/3370	Loss:0.021
Batch: 3370/3370	Loss:3.741
Epoch: 14	Train Loss: 0.172	Val F1: 0.689
Best Epoch: 12	Best Epoch Val F1: 0.717

******************************Epoch: 15******************************
Batch: 1/3370	Loss:0.009
Batch: 338/3370	Loss:0.043
Batch: 675/3370	Loss:0.004
Batch: 1012/3370	Loss:0.152
Batch: 1349/3370	Loss:0.121
Batch: 1686/3370	Loss:0.000
Batch: 2023/3370	Loss:0.069
Batch: 2360/3370	Loss:0.004
Batch: 2697/3370	Loss:0.149
Batch: 3034/3370	Loss:0.254
Batch: 3370/3370	Loss:0.259
Epoch: 15	Train Loss: 0.156	Val F1: 0.678
Best Epoch: 12	Best Epoch Val F1: 0.717

******************************Epoch: 16******************************
Batch: 1/3370	Loss:0.130
Batch: 338/3370	Loss:0.096
Batch: 675/3370	Loss:0.102
Batch: 1012/3370	Loss:0.031
Batch: 1349/3370	Loss:0.001
Batch: 1686/3370	Loss:0.003
Batch: 2023/3370	Loss:0.338
Batch: 2360/3370	Loss:0.077
Batch: 2697/3370	Loss:0.008
Batch: 3034/3370	Loss:0.380
Batch: 3370/3370	Loss:0.025
Epoch: 16	Train Loss: 0.152	Val F1: 0.701
Best Epoch: 12	Best Epoch Val F1: 0.717

******************************Epoch: 17******************************
Batch: 1/3370	Loss:0.023
Batch: 338/3370	Loss:0.002
Batch: 675/3370	Loss:0.178
Batch: 1012/3370	Loss:0.005
Batch: 1349/3370	Loss:0.002
Batch: 1686/3370	Loss:0.056
Batch: 2023/3370	Loss:0.361
Batch: 2360/3370	Loss:0.475
Batch: 2697/3370	Loss:0.181
Batch: 3034/3370	Loss:0.003
Batch: 3370/3370	Loss:0.002
Epoch: 17	Train Loss: 0.146	Val F1: 0.706
Best Epoch: 12	Best Epoch Val F1: 0.717

Saving the best checkpoint....
Inference...
Test F1: 0.726	Test F1_Few: 0.737	Test F1_Zero: 0.714
Starting training with config: {'batch_size': 32, 'epochs': 25, 'l2_reg': 9.745956282617216e-05, 'lr': 2.8522042260823542e-05, 'n_layers_freeze': 0, 'patience': 15}
Let's use 1 GPUs!
Preparing data....
Training data....
# of train examples: 13477
max len: 512, max len wiki: 1
Val data....
# of val examples: 2062
max len: 512, max len wiki: 1
Test data....
# of test examples: 3006
max len: 512, max len wiki: 1
Done

Initializing model....
******************************Epoch: 1******************************
Batch: 1/422	Loss:1.244
Batch: 43/422	Loss:1.093
Batch: 85/422	Loss:1.155
Batch: 127/422	Loss:1.055
Batch: 169/422	Loss:1.093
Batch: 211/422	Loss:0.957
Batch: 253/422	Loss:0.674
Batch: 295/422	Loss:0.665
Batch: 337/422	Loss:0.823
Batch: 379/422	Loss:0.598
Batch: 421/422	Loss:0.785
Batch: 422/422	Loss:0.865
Epoch: 1	Train Loss: 0.884	Val F1: 0.714
Best Epoch: 1	Best Epoch Val F1: 0.714

******************************Epoch: 2******************************
Batch: 1/422	Loss:0.507
Batch: 43/422	Loss:0.698
Batch: 85/422	Loss:0.643
Batch: 127/422	Loss:0.685
Batch: 169/422	Loss:0.536
Batch: 211/422	Loss:0.736
Batch: 253/422	Loss:0.502
Batch: 295/422	Loss:0.553
Batch: 337/422	Loss:0.704
Batch: 379/422	Loss:0.512
Batch: 421/422	Loss:0.429
Batch: 422/422	Loss:0.339
Epoch: 2	Train Loss: 0.560	Val F1: 0.706
Best Epoch: 1	Best Epoch Val F1: 0.714

******************************Epoch: 3******************************
Batch: 1/422	Loss:0.411
Batch: 43/422	Loss:0.465
Batch: 85/422	Loss:0.526
Batch: 127/422	Loss:0.473
Batch: 169/422	Loss:0.455
Batch: 211/422	Loss:0.697
Batch: 253/422	Loss:0.446
Batch: 295/422	Loss:0.710
Batch: 337/422	Loss:0.301
Batch: 379/422	Loss:0.572
Batch: 421/422	Loss:0.474
Batch: 422/422	Loss:0.280
Epoch: 3	Train Loss: 0.454	Val F1: 0.704
Best Epoch: 1	Best Epoch Val F1: 0.714

******************************Epoch: 4******************************
Batch: 1/422	Loss:0.308
Batch: 43/422	Loss:0.391
Batch: 85/422	Loss:0.373
Batch: 127/422	Loss:0.358
Batch: 169/422	Loss:0.420
Batch: 211/422	Loss:0.394
Batch: 253/422	Loss:0.343
Batch: 295/422	Loss:0.277
Batch: 337/422	Loss:0.475
Batch: 379/422	Loss:0.427
Batch: 421/422	Loss:0.251
Batch: 422/422	Loss:0.621
Epoch: 4	Train Loss: 0.388	Val F1: 0.692
Best Epoch: 1	Best Epoch Val F1: 0.714

******************************Epoch: 5******************************
Batch: 1/422	Loss:0.282
Batch: 43/422	Loss:0.251
Batch: 85/422	Loss:0.206
Batch: 127/422	Loss:0.207
Batch: 169/422	Loss:0.512
Batch: 211/422	Loss:0.314
Batch: 253/422	Loss:0.191
Batch: 295/422	Loss:0.366
Batch: 337/422	Loss:0.285
Batch: 379/422	Loss:0.262
Batch: 421/422	Loss:0.364
Batch: 422/422	Loss:0.336
Epoch: 5	Train Loss: 0.336	Val F1: 0.674
Best Epoch: 1	Best Epoch Val F1: 0.714

******************************Epoch: 6******************************
Batch: 1/422	Loss:0.352
Batch: 43/422	Loss:0.206
Batch: 85/422	Loss:0.452
Batch: 127/422	Loss:0.429
Batch: 169/422	Loss:0.290
Batch: 211/422	Loss:0.372
Batch: 253/422	Loss:0.217
Batch: 295/422	Loss:0.277
Batch: 337/422	Loss:0.283
Batch: 379/422	Loss:0.254
Batch: 421/422	Loss:0.271
Batch: 422/422	Loss:0.043
Epoch: 6	Train Loss: 0.291	Val F1: 0.715
Best Epoch: 6	Best Epoch Val F1: 0.715

******************************Epoch: 7******************************
Batch: 1/422	Loss:0.250
Batch: 43/422	Loss:0.255
Batch: 85/422	Loss:0.237
Batch: 127/422	Loss:0.167
Batch: 169/422	Loss:0.498
Batch: 211/422	Loss:0.351
Batch: 253/422	Loss:0.246
Batch: 295/422	Loss:0.378
Batch: 337/422	Loss:0.290
Batch: 379/422	Loss:0.540
Batch: 421/422	Loss:0.316
Batch: 422/422	Loss:0.208
Epoch: 7	Train Loss: 0.252	Val F1: 0.717
Best Epoch: 7	Best Epoch Val F1: 0.717

******************************Epoch: 8******************************
Batch: 1/422	Loss:0.165
Batch: 43/422	Loss:0.270
Batch: 85/422	Loss:0.072
Batch: 127/422	Loss:0.274
Batch: 169/422	Loss:0.194
Batch: 211/422	Loss:0.145
Batch: 253/422	Loss:0.258
Batch: 295/422	Loss:0.165
Batch: 337/422	Loss:0.177
Batch: 379/422	Loss:0.132
Batch: 421/422	Loss:0.427
Batch: 422/422	Loss:0.204
Epoch: 8	Train Loss: 0.220	Val F1: 0.710
Best Epoch: 7	Best Epoch Val F1: 0.717

******************************Epoch: 9******************************
Batch: 1/422	Loss:0.351
Batch: 43/422	Loss:0.220
Batch: 85/422	Loss:0.175
Batch: 127/422	Loss:0.316
Batch: 169/422	Loss:0.143
Batch: 211/422	Loss:0.173
Batch: 253/422	Loss:0.256
Batch: 295/422	Loss:0.173
Batch: 337/422	Loss:0.207
Batch: 379/422	Loss:0.192
Batch: 421/422	Loss:0.147
Batch: 422/422	Loss:0.083
Epoch: 9	Train Loss: 0.190	Val F1: 0.717
Best Epoch: 9	Best Epoch Val F1: 0.717

******************************Epoch: 10******************************
Batch: 1/422	Loss:0.177
Batch: 43/422	Loss:0.257
Batch: 85/422	Loss:0.060
Batch: 127/422	Loss:0.018
Batch: 169/422	Loss:0.092
Batch: 211/422	Loss:0.169
Batch: 253/422	Loss:0.172
Batch: 295/422	Loss:0.045
Batch: 337/422	Loss:0.024
Batch: 379/422	Loss:0.380
Batch: 421/422	Loss:0.116
Batch: 422/422	Loss:0.021
Epoch: 10	Train Loss: 0.172	Val F1: 0.728
Best Epoch: 10	Best Epoch Val F1: 0.728

******************************Epoch: 11******************************
Batch: 1/422	Loss:0.127
Batch: 43/422	Loss:0.299
Batch: 85/422	Loss:0.086
Batch: 127/422	Loss:0.187
Batch: 169/422	Loss:0.177
Batch: 211/422	Loss:0.076
Batch: 253/422	Loss:0.340
Batch: 295/422	Loss:0.055
Batch: 337/422	Loss:0.270
Batch: 379/422	Loss:0.064
Batch: 421/422	Loss:0.201
Batch: 422/422	Loss:0.009
Epoch: 11	Train Loss: 0.154	Val F1: 0.720
Best Epoch: 10	Best Epoch Val F1: 0.728

******************************Epoch: 12******************************
Batch: 1/422	Loss:0.156
Batch: 43/422	Loss:0.039
Batch: 85/422	Loss:0.171
Batch: 127/422	Loss:0.179
Batch: 169/422	Loss:0.105
Batch: 211/422	Loss:0.133
Batch: 253/422	Loss:0.151
Batch: 295/422	Loss:0.139
Batch: 337/422	Loss:0.046
Batch: 379/422	Loss:0.170
Batch: 421/422	Loss:0.141
Batch: 422/422	Loss:0.001
Epoch: 12	Train Loss: 0.145	Val F1: 0.720
Best Epoch: 10	Best Epoch Val F1: 0.728

******************************Epoch: 13******************************
Batch: 1/422	Loss:0.056
Batch: 43/422	Loss:0.247
Batch: 85/422	Loss:0.103
Batch: 127/422	Loss:0.085
Batch: 169/422	Loss:0.096
Batch: 211/422	Loss:0.069
Batch: 253/422	Loss:0.132
Batch: 295/422	Loss:0.199
Batch: 337/422	Loss:0.283
Batch: 379/422	Loss:0.290
Batch: 421/422	Loss:0.109
Batch: 422/422	Loss:0.078
Epoch: 13	Train Loss: 0.145	Val F1: 0.715
Best Epoch: 10	Best Epoch Val F1: 0.728

******************************Epoch: 14******************************
Batch: 1/422	Loss:0.116
Batch: 43/422	Loss:0.123
Batch: 85/422	Loss:0.023
Batch: 127/422	Loss:0.081
Batch: 169/422	Loss:0.135
Batch: 211/422	Loss:0.071
Batch: 253/422	Loss:0.070
Batch: 295/422	Loss:0.043
Batch: 337/422	Loss:0.101
Batch: 379/422	Loss:0.223
Batch: 421/422	Loss:0.182
Batch: 422/422	Loss:0.385
Epoch: 14	Train Loss: 0.135	Val F1: 0.714
Best Epoch: 10	Best Epoch Val F1: 0.728

******************************Epoch: 15******************************
Batch: 1/422	Loss:0.081
Batch: 43/422	Loss:0.058
Batch: 85/422	Loss:0.057
Batch: 127/422	Loss:0.265
Batch: 169/422	Loss:0.202
Batch: 211/422	Loss:0.039
Batch: 253/422	Loss:0.305
Batch: 295/422	Loss:0.127
Batch: 337/422	Loss:0.132
Batch: 379/422	Loss:0.062
Batch: 421/422	Loss:0.181
Batch: 422/422	Loss:0.000
Epoch: 15	Train Loss: 0.127	Val F1: 0.718
Best Epoch: 10	Best Epoch Val F1: 0.728

******************************Epoch: 16******************************
Batch: 1/422	Loss:0.066
Batch: 43/422	Loss:0.123
Batch: 85/422	Loss:0.106
Batch: 127/422	Loss:0.038
Batch: 169/422	Loss:0.261
Batch: 211/422	Loss:0.036
Batch: 253/422	Loss:0.150
Batch: 295/422	Loss:0.047
Batch: 337/422	Loss:0.066
Batch: 379/422	Loss:0.162
Batch: 421/422	Loss:0.149
Batch: 422/422	Loss:0.104
Epoch: 16	Train Loss: 0.111	Val F1: 0.722
Best Epoch: 10	Best Epoch Val F1: 0.728

******************************Epoch: 17******************************
Batch: 1/422	Loss:0.074
Batch: 43/422	Loss:0.112
Batch: 85/422	Loss:0.050
Batch: 127/422	Loss:0.231
Batch: 169/422	Loss:0.054
Batch: 211/422	Loss:0.036
Batch: 253/422	Loss:0.149
Batch: 295/422	Loss:0.062
Batch: 337/422	Loss:0.120
Batch: 379/422	Loss:0.124
Batch: 421/422	Loss:0.056
Batch: 422/422	Loss:0.004
Epoch: 17	Train Loss: 0.109	Val F1: 0.703
Best Epoch: 10	Best Epoch Val F1: 0.728

******************************Epoch: 18******************************
Batch: 1/422	Loss:0.147
Batch: 43/422	Loss:0.043
Batch: 85/422	Loss:0.176
Batch: 127/422	Loss:0.119
Batch: 169/422	Loss:0.169
Batch: 211/422	Loss:0.125
Batch: 253/422	Loss:0.155
Batch: 295/422	Loss:0.089
Batch: 337/422	Loss:0.071
Batch: 379/422	Loss:0.078
Batch: 421/422	Loss:0.327
Batch: 422/422	Loss:0.271
Epoch: 18	Train Loss: 0.103	Val F1: 0.716
Best Epoch: 10	Best Epoch Val F1: 0.728

******************************Epoch: 19******************************
Batch: 1/422	Loss:0.064
Batch: 43/422	Loss:0.094
Batch: 85/422	Loss:0.129
Batch: 127/422	Loss:0.106
Batch: 169/422	Loss:0.095
Batch: 211/422	Loss:0.070
Batch: 253/422	Loss:0.076
Batch: 295/422	Loss:0.051
Batch: 337/422	Loss:0.166
Batch: 379/422	Loss:0.078
Batch: 421/422	Loss:0.089
Batch: 422/422	Loss:0.030
Epoch: 19	Train Loss: 0.105	Val F1: 0.699
Best Epoch: 10	Best Epoch Val F1: 0.728

******************************Epoch: 20******************************
Batch: 1/422	Loss:0.038
Batch: 43/422	Loss:0.171
Batch: 85/422	Loss:0.082
Batch: 127/422	Loss:0.005
Batch: 169/422	Loss:0.107
Batch: 211/422	Loss:0.082
Batch: 253/422	Loss:0.129
Batch: 295/422	Loss:0.178
Batch: 337/422	Loss:0.233
Batch: 379/422	Loss:0.085
Batch: 421/422	Loss:0.079
Batch: 422/422	Loss:0.818
Epoch: 20	Train Loss: 0.102	Val F1: 0.698
Best Epoch: 10	Best Epoch Val F1: 0.728

******************************Epoch: 21******************************
