Create sweep with ID: zvtezstn
Sweep URL: https://wandb.ai/michaelzhao-harvard-university/wiki-larger-new/sweeps/zvtezstn
Starting training with config: {'batch_size': 32, 'epochs': 75, 'l2_reg': 7.105692132632347e-05, 'lr': 3.534725187038329e-05, 'n_layers_freeze': 4, 'n_layers_freeze_wiki': 0, 'patience': 15}
Let's use 1 GPUs!
Preparing data....
Training data....
# of train examples: 13477
max len: 512, max len wiki: 1
Val data....
# of val examples: 2062
max len: 512, max len wiki: 1
Test data....
# of test examples: 3006
max len: 512, max len wiki: 1
Done

Initializing model....
****************************** Epoch: 1 ******************************
Starting training with config: {'batch_size': 64, 'epochs': 25, 'l2_reg': 7.590763719485767e-05, 'lr': 2.929685156879613e-05, 'n_layers_freeze': 4, 'n_layers_freeze_wiki': 0, 'patience': 5}
Let's use 1 GPUs!
Preparing data....
Training data....
# of train examples: 13477
max len: 512, max len wiki: 1
Val data....
# of val examples: 2062
max len: 512, max len wiki: 1
Test data....
# of test examples: 3006
max len: 512, max len wiki: 1
Done

Initializing model....
****************************** Epoch: 1 ******************************
Starting training with config: {'batch_size': 16, 'epochs': 25, 'l2_reg': 8.82979411602809e-05, 'lr': 1.6700496045404343e-05, 'n_layers_freeze': 2, 'n_layers_freeze_wiki': 2, 'patience': 15}
Let's use 1 GPUs!
Preparing data....
Training data....
# of train examples: 13477
max len: 512, max len wiki: 1
Val data....
# of val examples: 2062
max len: 512, max len wiki: 1
Test data....
# of test examples: 3006
max len: 512, max len wiki: 1
Done

Initializing model....
****************************** Epoch: 1 ******************************
Starting training with config: {'batch_size': 64, 'epochs': 50, 'l2_reg': 2.7370629586426413e-05, 'lr': 4.877563838181653e-05, 'n_layers_freeze': 0, 'n_layers_freeze_wiki': 2, 'patience': 5}
Let's use 1 GPUs!
Preparing data....
Training data....
# of train examples: 13477
max len: 512, max len wiki: 1
Val data....
# of val examples: 2062
max len: 512, max len wiki: 1
Test data....
# of test examples: 3006
max len: 512, max len wiki: 1
Done

Initializing model....
****************************** Epoch: 1 ******************************
Starting training with config: {'batch_size': 64, 'epochs': 75, 'l2_reg': 2.051130824106522e-05, 'lr': 8.08871706066116e-06, 'n_layers_freeze': 0, 'n_layers_freeze_wiki': 1, 'patience': 5}
Let's use 1 GPUs!
Preparing data....
Training data....
# of train examples: 13477
max len: 512, max len wiki: 1
Val data....
# of val examples: 2062
max len: 512, max len wiki: 1
Test data....
# of test examples: 3006
max len: 512, max len wiki: 1
Done

Initializing model....
Starting training with config: {'batch_size': 8, 'epochs': 25, 'l2_reg': 7.606923412427817e-05, 'lr': 7.034579604450906e-06, 'n_layers_freeze': 0, 'n_layers_freeze_wiki': 3, 'patience': 15}
Let's use 1 GPUs!
Preparing data....
Training data....
# of train examples: 13477
max len: 512, max len wiki: 1
Val data....
# of val examples: 2062
max len: 512, max len wiki: 1
Test data....
# of test examples: 3006
max len: 512, max len wiki: 1
Done

Initializing model....
